{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PersonAttrubutes_Inceptionv3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bikash-bhoi/EIP4/blob/master/Assignment%205/PersonAttrubutes_Inceptionv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "outputId": "73dc3e04-67e0-4308-cf82-326532b8fc0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  hvc_annotations.csv  \u001b[01;34mresized\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXawbLrqusfM",
        "colab_type": "code",
        "outputId": "de203067-367f-4f91-f048-a3b623dcbe26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assignment5_Inceptionv3_model_best.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e1d15b1e-ec3b-437a-8099-4b578c7d2481"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow.contrib.eager as tfe\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "outputId": "a1e5b8a4-7ba4-463c-b012-95d2bd349db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>imagequality</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>carryingbag</th>\n",
              "      <th>footwear</th>\n",
              "      <th>emotion</th>\n",
              "      <th>bodypose</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>over-weight</td>\n",
              "      <td>None</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Angry/Serious</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Daily/Office/Work Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>Good</td>\n",
              "      <td>35-45</td>\n",
              "      <td>slightly-overweight</td>\n",
              "      <td>None</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender imagequality    age  ...        emotion        bodypose     image_path\n",
              "0    male      Average  35-45  ...        Neutral  Front-Frontish  resized/1.jpg\n",
              "1  female      Average  35-45  ...  Angry/Serious  Front-Frontish  resized/2.jpg\n",
              "2    male         Good  45-55  ...        Neutral  Front-Frontish  resized/3.jpg\n",
              "3    male         Good  45-55  ...        Neutral  Front-Frontish  resized/4.jpg\n",
              "4  female         Good  35-45  ...        Neutral  Front-Frontish  resized/5.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xWOu2-Hkw-8",
        "colab_type": "code",
        "outputId": "a7091996-ac12-42e1-dd7c-d41025d54a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13573, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "outputId": "0bf4a238-9fd6-4577-f902-ec3ac46a7089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>image_path</th>\n",
              "      <td>resized/1.jpg</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_female</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_male</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Average</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Good</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_15-25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_25-35</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_35-45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_45-55</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_55+</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_over-weight</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_underweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_None</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Normal</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Happy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Sad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Back</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Side</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  0  ...              4\n",
              "image_path                            resized/1.jpg  ...  resized/5.jpg\n",
              "gender_female                                     0  ...              1\n",
              "gender_male                                       1  ...              0\n",
              "imagequality_Average                              1  ...              0\n",
              "imagequality_Bad                                  0  ...              0\n",
              "imagequality_Good                                 0  ...              1\n",
              "age_15-25                                         0  ...              0\n",
              "age_25-35                                         0  ...              0\n",
              "age_35-45                                         1  ...              1\n",
              "age_45-55                                         0  ...              0\n",
              "age_55+                                           0  ...              0\n",
              "weight_normal-healthy                             1  ...              0\n",
              "weight_over-weight                                0  ...              0\n",
              "weight_slightly-overweight                        0  ...              1\n",
              "weight_underweight                                0  ...              0\n",
              "carryingbag_Daily/Office/Work Bag                 0  ...              0\n",
              "carryingbag_Grocery/Home/Plastic Bag              1  ...              0\n",
              "carryingbag_None                                  0  ...              1\n",
              "footwear_CantSee                                  0  ...              1\n",
              "footwear_Fancy                                    0  ...              0\n",
              "footwear_Normal                                   1  ...              0\n",
              "emotion_Angry/Serious                             0  ...              0\n",
              "emotion_Happy                                     0  ...              0\n",
              "emotion_Neutral                                   1  ...              1\n",
              "emotion_Sad                                       0  ...              0\n",
              "bodypose_Back                                     0  ...              0\n",
              "bodypose_Front-Frontish                           1  ...              1\n",
              "bodypose_Side                                     0  ...              0\n",
              "\n",
              "[28 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    def __init__(self, df, batch_size=32, shuffle=True, augmentation=None):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        \n",
        "        images = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "\n",
        "        images = images.astype('float32') / 255\n",
        "        images_mean = np.mean(images, axis=0)\n",
        "        images -= images_mean\n",
        "\n",
        "        if self.augmentation is not None:\n",
        "            images = self.augmentation.flow(images, shuffle=False).next()\n",
        "        \n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        \n",
        "        return images, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd8vvNYwlXAi",
        "colab_type": "code",
        "outputId": "a8722601-5964-465d-d139-163d55ec3755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "items=one_hot_df.iloc[slice(3, 5, None)]\n",
        "image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "print(image.shape)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image[0])\n",
        "#one_hot_df.iloc[1]\n",
        "\n",
        "'''\n",
        "print(image[0].min(), image[0].max(), image[0].mean(), image[0].std())\n",
        "\n",
        "image = image.astype('float32') / 255\n",
        "print(image[0].min(), image[0].max(), image[0].mean(), image[0].std())\n",
        "image_mean = np.mean(image, axis=0)\n",
        "print('im_mean',image_mean.min(), image_mean.max(), image_mean.mean(), image_mean.std())\n",
        "#print(image_mean)\n",
        "image -= image_mean\n",
        "\n",
        "print(image[0].min(), image[0].max(), image[0].mean(), image[0].std())\n",
        "#plt.imshow(image[0])\n",
        "'''"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 224, 224, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nprint(image[0].min(), image[0].max(), image[0].mean(), image[0].std())\\n\\nimage = image.astype('float32') / 255\\nprint(image[0].min(), image[0].max(), image[0].mean(), image[0].std())\\nimage_mean = np.mean(image, axis=0)\\nprint('im_mean',image_mean.min(), image_mean.max(), image_mean.mean(), image_mean.std())\\n#print(image_mean)\\nimage -= image_mean\\n\\nprint(image[0].min(), image[0].max(), image[0].mean(), image[0].std())\\n#plt.imshow(image[0])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncPxf7lmr+vDjPIUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "outputId": "4e9e6b10-130e-4417-8a84-8dc02177c29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.2)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10858, 28), (2715, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "\n",
        "  \"\"\"\n",
        "  p : the probability that random erasing is performed\n",
        "  s_l, s_h : minimum / maximum proportion of erased area against input image\n",
        "  r_1, r_2 : minimum / maximum aspect ratio of erased area\n",
        "  v_l, v_h : minimum / maximum value for erased area\n",
        "  pixel_level : pixel-level randomization for erased area\n",
        "  \"\"\"\n",
        "\n",
        "  def eraser(input_img):\n",
        "    img_h, img_w, img_c = input_img.shape\n",
        "    p_1 = np.random.rand()\n",
        "\n",
        "    if p_1 > p:\n",
        "        return input_img\n",
        "\n",
        "    while True:\n",
        "        s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "        r = np.random.uniform(r_1, r_2)\n",
        "        w = int(np.sqrt(s / r))\n",
        "        h = int(np.sqrt(s * r))\n",
        "        left = np.random.randint(0, img_w)\n",
        "        top = np.random.randint(0, img_h)\n",
        "\n",
        "        if left + w <= img_w and top + h <= img_h:\n",
        "            break\n",
        "\n",
        "    if pixel_level:\n",
        "        c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "    else:\n",
        "        c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "    input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "    return input_img\n",
        "\n",
        "  return eraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEJjreEKHXx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=2,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.05,\n",
        "        # set range for random shear\n",
        "        shear_range=0.1,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.05,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.1,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        #Cutout Implementation\n",
        "        preprocessing_function=get_random_eraser(p=0.1,v_l=0, v_h=0.5, s_l=0.008, s_h=0.05, pixel_level=False),\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=32,augmentation=aug)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAwIhWavl-bb",
        "colab_type": "code",
        "outputId": "e830b489-5be4-4efc-a99a-ad40fcdbcbd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "in_shape=train_gen.__getitem__(16)[0][1].shape\n",
        "in_shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "outputId": "9b94bf82-8e23-4519-cfc8-6b7116f5718f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 5,\n",
              " 'bag': 3,\n",
              " 'emotion': 4,\n",
              " 'footwear': 3,\n",
              " 'gender': 2,\n",
              " 'image_quality': 3,\n",
              " 'pose': 3,\n",
              " 'weight': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgK-BmUD5d_c",
        "colab_type": "code",
        "outputId": "2c8300cf-01b7-4c07-d73b-c231017d1595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "backbone = InceptionV3(\n",
        "    weights=None, \n",
        "    include_top=False, \n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        ")\n",
        "\n",
        "neck = backbone.output\n",
        "neck = Flatten(name=\"flatten\")(neck)\n",
        "neck = Dense(512, activation=\"relu\")(neck)\n",
        "\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    neck = Dropout(0.2)(in_layer)\n",
        "    neck = Dense(256,activation='relu')(neck)\n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_tower(neck))\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs=backbone.input, \n",
        "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPG9C2eA1zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQIrjiSHJdbT",
        "colab_type": "code",
        "outputId": "21e375ad-24fa-4479-e10c-a44ebce223f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()\n",
        "\n",
        "# Review model\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 51200)        0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          26214912    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 256)          131328      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 256)          131328      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 256)          131328      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 256)          131328      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 256)          131328      dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 256)          131328      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 256)          131328      dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Dense)           (None, 2)            514         dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "image_quality_output (Dense)    (None, 3)            771         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "age_output (Dense)              (None, 5)            1285        dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "weight_output (Dense)           (None, 4)            1028        dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bag_output (Dense)              (None, 3)            771         dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "footwear_output (Dense)         (None, 3)            771         dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "pose_output (Dense)             (None, 3)            771         dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "emotion_output (Dense)          (None, 4)            1028        dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 49,075,259\n",
            "Trainable params: 49,040,827\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrzs6dYLS4S6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CyclicLR(keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self,base_lr, max_lr, step_size, base_m, max_m, cyclical_momentum):\n",
        " \n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.base_m = base_m\n",
        "        self.max_m = max_m\n",
        "        self.cyclical_momentum = cyclical_momentum\n",
        "        self.step_size = step_size\n",
        "        \n",
        "        self.clr_iterations = 0.\n",
        "        self.cm_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "        \n",
        "    def clr(self):\n",
        "        \n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        \n",
        "        if cycle == 2:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)          \n",
        "            return self.base_lr-(self.base_lr-self.base_lr/100)*np.maximum(0,(1-x))\n",
        "        \n",
        "        else:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0,(1-x))\n",
        "    \n",
        "    def cm(self):\n",
        "        \n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        \n",
        "        if cycle == 2:\n",
        "            \n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1) \n",
        "            return self.max_m\n",
        "        \n",
        "        else:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "            return self.max_m - (self.max_m-self.base_m)*np.maximum(0,(1-x))\n",
        "        \n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "            \n",
        "        if self.cyclical_momentum == True:\n",
        "            if self.clr_iterations == 0:\n",
        "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
        "            else:\n",
        "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
        "            \n",
        "            \n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        \n",
        "        if self.cyclical_momentum == True:\n",
        "            self.history.setdefault('momentum', []).append(K.get_value(self.model.optimizer.momentum))\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "        \n",
        "        if self.cyclical_momentum == True:\n",
        "            K.set_value(self.model.optimizer.momentum, self.cm())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNLL-xNnD3ng",
        "colab_type": "code",
        "outputId": "689e5487-213d-407a-b7c5-5d6726eaf5fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "\n",
        "losses = {\n",
        "\t\"gender_output\": \"binary_crossentropy\",\n",
        "\t\"image_quality_output\": \"categorical_crossentropy\",\n",
        "\t\"age_output\": \"categorical_crossentropy\",\n",
        "\t\"weight_output\": \"categorical_crossentropy\",\n",
        "  \"bag_output\": \"categorical_crossentropy\",\n",
        "  \"pose_output\": \"categorical_crossentropy\",\n",
        "  \"footwear_output\": \"categorical_crossentropy\",\n",
        "  \"emotion_output\": \"categorical_crossentropy\"\n",
        "\n",
        "}\n",
        " #loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0}\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=losses, \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfART1-ljXtO",
        "colab_type": "code",
        "outputId": "cab7ddef-0a87-4a7b-f0be-de78916f7f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#### Range Test: https://github.com/psklight/keras_one_cycle_clr\n",
        "!git init\n",
        "!git clone https://github.com/psklight/keras_one_cycle_clr.git\n",
        "from keras_one_cycle_clr.keras_one_cycle_clr import LrRangeTest"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "Cloning into 'keras_one_cycle_clr'...\n",
            "remote: Enumerating objects: 160, done.\u001b[K\n",
            "remote: Counting objects: 100% (160/160), done.\u001b[K\n",
            "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
            "remote: Total 160 (delta 32), reused 147 (delta 26), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (160/160), 5.93 MiB | 11.06 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-pebnMDoBRS",
        "colab_type": "code",
        "outputId": "6356765b-dc3f-464d-aa92-0e1814507c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wd_list=[i/100 for i in range(85,95) if i%2==1]\n",
        "wd_list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.85, 0.87, 0.89, 0.91, 0.93]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BocH6UY5jK32",
        "colab_type": "code",
        "outputId": "fcb79b13-cf4a-4b9c-926b-7965b09990ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size=64\n",
        "lrrf_cb = LrRangeTest(lr_range = (1e-6, 1),\n",
        "                 wd_list = [5e-4],  # grid search for weight decay\n",
        "                 steps=100,\n",
        "                 batches_per_step=5,\n",
        "                 threshold_multiplier=5.0,\n",
        "                 validation_data=None,\n",
        "                 batches_per_val = 5,\n",
        "                 verbose=True)\n",
        "n_epoch = 1\n",
        "model.fit_generator(generator=train_gen, verbose=1,\n",
        "          epochs=n_epoch,\n",
        "          validation_data=None,\n",
        "          callbacks=[lrrf_cb])\n",
        "lrrf_cb.plot()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Epoch 1/1\n",
            "  5/339 [..............................] - ETA: 28:16 - loss: 9.6570 - gender_output_loss: 0.7925 - image_quality_output_loss: 1.1996 - age_output_loss: 1.6276 - weight_output_loss: 1.4215 - bag_output_loss: 1.1823 - footwear_output_loss: 1.2304 - pose_output_loss: 1.1291 - emotion_output_loss: 1.0740 - gender_output_acc: 0.5250 - image_quality_output_acc: 0.4813 - age_output_acc: 0.3500 - weight_output_acc: 0.5125 - bag_output_acc: 0.4562 - footwear_output_acc: 0.3812 - pose_output_acc: 0.4938 - emotion_output_acc: 0.7312wd=5.00e-04 , lr=1.00e-06 , loss=nan\n",
            " 10/339 [..............................] - ETA: 15:01 - loss: 9.5765 - gender_output_loss: 0.7916 - image_quality_output_loss: 1.1311 - age_output_loss: 1.7072 - weight_output_loss: 1.3181 - bag_output_loss: 1.2074 - footwear_output_loss: 1.2254 - pose_output_loss: 1.0997 - emotion_output_loss: 1.0961 - gender_output_acc: 0.5219 - image_quality_output_acc: 0.4813 - age_output_acc: 0.3156 - weight_output_acc: 0.5312 - bag_output_acc: 0.5219 - footwear_output_acc: 0.4156 - pose_output_acc: 0.4906 - emotion_output_acc: 0.7188wd=5.00e-04 , lr=1.15e-06 , loss=9.66e+00\n",
            " 15/339 [>.............................] - ETA: 10:34 - loss: 9.6094 - gender_output_loss: 0.7840 - image_quality_output_loss: 1.1550 - age_output_loss: 1.7416 - weight_output_loss: 1.2856 - bag_output_loss: 1.1960 - footwear_output_loss: 1.1881 - pose_output_loss: 1.0751 - emotion_output_loss: 1.1839 - gender_output_acc: 0.4979 - image_quality_output_acc: 0.4813 - age_output_acc: 0.2896 - weight_output_acc: 0.5125 - bag_output_acc: 0.4875 - footwear_output_acc: 0.4521 - pose_output_acc: 0.5208 - emotion_output_acc: 0.6875wd=5.00e-04 , lr=1.32e-06 , loss=9.50e+00\n",
            " 20/339 [>.............................] - ETA: 8:20 - loss: 9.5897 - gender_output_loss: 0.8344 - image_quality_output_loss: 1.1543 - age_output_loss: 1.7272 - weight_output_loss: 1.2444 - bag_output_loss: 1.1881 - footwear_output_loss: 1.1963 - pose_output_loss: 1.0888 - emotion_output_loss: 1.1562 - gender_output_acc: 0.5172 - image_quality_output_acc: 0.4813 - age_output_acc: 0.3344 - weight_output_acc: 0.5359 - bag_output_acc: 0.5031 - footwear_output_acc: 0.4328 - pose_output_acc: 0.5547 - emotion_output_acc: 0.6875wd=5.00e-04 , lr=1.52e-06 , loss=9.68e+00\n",
            " 25/339 [=>............................] - ETA: 6:59 - loss: 9.6552 - gender_output_loss: 0.8580 - image_quality_output_loss: 1.1690 - age_output_loss: 1.7186 - weight_output_loss: 1.2229 - bag_output_loss: 1.1788 - footwear_output_loss: 1.1997 - pose_output_loss: 1.0710 - emotion_output_loss: 1.2372 - gender_output_acc: 0.5162 - image_quality_output_acc: 0.4763 - age_output_acc: 0.3525 - weight_output_acc: 0.5587 - bag_output_acc: 0.5100 - footwear_output_acc: 0.4300 - pose_output_acc: 0.5687 - emotion_output_acc: 0.6725wd=5.00e-04 , lr=1.75e-06 , loss=9.53e+00\n",
            " 30/339 [=>............................] - ETA: 6:10 - loss: 9.6406 - gender_output_loss: 0.8581 - image_quality_output_loss: 1.1783 - age_output_loss: 1.7490 - weight_output_loss: 1.2228 - bag_output_loss: 1.1564 - footwear_output_loss: 1.1988 - pose_output_loss: 1.0518 - emotion_output_loss: 1.2255 - gender_output_acc: 0.5156 - image_quality_output_acc: 0.4917 - age_output_acc: 0.3552 - weight_output_acc: 0.5719 - bag_output_acc: 0.5031 - footwear_output_acc: 0.4156 - pose_output_acc: 0.5927 - emotion_output_acc: 0.6750wd=5.00e-04 , lr=2.01e-06 , loss=9.92e+00\n",
            " 35/339 [==>...........................] - ETA: 5:36 - loss: 9.6560 - gender_output_loss: 0.8556 - image_quality_output_loss: 1.2069 - age_output_loss: 1.7609 - weight_output_loss: 1.2198 - bag_output_loss: 1.1614 - footwear_output_loss: 1.1975 - pose_output_loss: 1.0561 - emotion_output_loss: 1.1979 - gender_output_acc: 0.5205 - image_quality_output_acc: 0.4973 - age_output_acc: 0.3500 - weight_output_acc: 0.5795 - bag_output_acc: 0.5116 - footwear_output_acc: 0.4205 - pose_output_acc: 0.5920 - emotion_output_acc: 0.6786wd=5.00e-04 , lr=2.31e-06 , loss=9.57e+00\n",
            " 40/339 [==>...........................] - ETA: 5:10 - loss: 9.5512 - gender_output_loss: 0.8448 - image_quality_output_loss: 1.1938 - age_output_loss: 1.7472 - weight_output_loss: 1.2032 - bag_output_loss: 1.1569 - footwear_output_loss: 1.1729 - pose_output_loss: 1.0445 - emotion_output_loss: 1.1880 - gender_output_acc: 0.5203 - image_quality_output_acc: 0.5047 - age_output_acc: 0.3539 - weight_output_acc: 0.5898 - bag_output_acc: 0.5086 - footwear_output_acc: 0.4344 - pose_output_acc: 0.5961 - emotion_output_acc: 0.6789wd=5.00e-04 , lr=2.66e-06 , loss=9.75e+00\n",
            " 45/339 [==>...........................] - ETA: 4:49 - loss: 9.4678 - gender_output_loss: 0.8303 - image_quality_output_loss: 1.1786 - age_output_loss: 1.7323 - weight_output_loss: 1.1909 - bag_output_loss: 1.1480 - footwear_output_loss: 1.1679 - pose_output_loss: 1.0481 - emotion_output_loss: 1.1717 - gender_output_acc: 0.5264 - image_quality_output_acc: 0.5049 - age_output_acc: 0.3556 - weight_output_acc: 0.5931 - bag_output_acc: 0.5097 - footwear_output_acc: 0.4389 - pose_output_acc: 0.5965 - emotion_output_acc: 0.6778wd=5.00e-04 , lr=3.05e-06 , loss=8.82e+00\n",
            " 50/339 [===>..........................] - ETA: 4:31 - loss: 9.3678 - gender_output_loss: 0.8135 - image_quality_output_loss: 1.1718 - age_output_loss: 1.7091 - weight_output_loss: 1.1864 - bag_output_loss: 1.1378 - footwear_output_loss: 1.1557 - pose_output_loss: 1.0392 - emotion_output_loss: 1.1544 - gender_output_acc: 0.5350 - image_quality_output_acc: 0.5031 - age_output_acc: 0.3569 - weight_output_acc: 0.5931 - bag_output_acc: 0.5081 - footwear_output_acc: 0.4400 - pose_output_acc: 0.5981 - emotion_output_acc: 0.6794wd=5.00e-04 , lr=3.51e-06 , loss=8.80e+00\n",
            " 55/339 [===>..........................] - ETA: 4:16 - loss: 9.2726 - gender_output_loss: 0.8074 - image_quality_output_loss: 1.1667 - age_output_loss: 1.6932 - weight_output_loss: 1.1701 - bag_output_loss: 1.1252 - footwear_output_loss: 1.1410 - pose_output_loss: 1.0369 - emotion_output_loss: 1.1321 - gender_output_acc: 0.5347 - image_quality_output_acc: 0.5085 - age_output_acc: 0.3528 - weight_output_acc: 0.5949 - bag_output_acc: 0.5102 - footwear_output_acc: 0.4455 - pose_output_acc: 0.5966 - emotion_output_acc: 0.6847wd=5.00e-04 , lr=4.04e-06 , loss=8.47e+00\n",
            " 60/339 [====>.........................] - ETA: 4:04 - loss: 9.1844 - gender_output_loss: 0.7995 - image_quality_output_loss: 1.1558 - age_output_loss: 1.6720 - weight_output_loss: 1.1549 - bag_output_loss: 1.1136 - footwear_output_loss: 1.1321 - pose_output_loss: 1.0299 - emotion_output_loss: 1.1267 - gender_output_acc: 0.5354 - image_quality_output_acc: 0.5089 - age_output_acc: 0.3578 - weight_output_acc: 0.5984 - bag_output_acc: 0.5062 - footwear_output_acc: 0.4505 - pose_output_acc: 0.5974 - emotion_output_acc: 0.6828wd=5.00e-04 , lr=4.64e-06 , loss=8.32e+00\n",
            " 65/339 [====>.........................] - ETA: 3:53 - loss: 9.1172 - gender_output_loss: 0.7937 - image_quality_output_loss: 1.1452 - age_output_loss: 1.6593 - weight_output_loss: 1.1472 - bag_output_loss: 1.1039 - footwear_output_loss: 1.1248 - pose_output_loss: 1.0281 - emotion_output_loss: 1.1150 - gender_output_acc: 0.5327 - image_quality_output_acc: 0.5111 - age_output_acc: 0.3572 - weight_output_acc: 0.6005 - bag_output_acc: 0.5010 - footwear_output_acc: 0.4538 - pose_output_acc: 0.5938 - emotion_output_acc: 0.6837wd=5.00e-04 , lr=5.34e-06 , loss=8.21e+00\n",
            " 70/339 [=====>........................] - ETA: 3:43 - loss: 9.0485 - gender_output_loss: 0.7885 - image_quality_output_loss: 1.1350 - age_output_loss: 1.6422 - weight_output_loss: 1.1467 - bag_output_loss: 1.0951 - footwear_output_loss: 1.1196 - pose_output_loss: 1.0263 - emotion_output_loss: 1.0951 - gender_output_acc: 0.5281 - image_quality_output_acc: 0.5134 - age_output_acc: 0.3625 - weight_output_acc: 0.5973 - bag_output_acc: 0.5040 - footwear_output_acc: 0.4509 - pose_output_acc: 0.5915 - emotion_output_acc: 0.6888wd=5.00e-04 , lr=6.14e-06 , loss=8.31e+00\n",
            " 75/339 [=====>........................] - ETA: 3:34 - loss: 8.9907 - gender_output_loss: 0.7825 - image_quality_output_loss: 1.1264 - age_output_loss: 1.6307 - weight_output_loss: 1.1383 - bag_output_loss: 1.0869 - footwear_output_loss: 1.1137 - pose_output_loss: 1.0204 - emotion_output_loss: 1.0918 - gender_output_acc: 0.5242 - image_quality_output_acc: 0.5129 - age_output_acc: 0.3650 - weight_output_acc: 0.6008 - bag_output_acc: 0.5071 - footwear_output_acc: 0.4479 - pose_output_acc: 0.5938 - emotion_output_acc: 0.6879wd=5.00e-04 , lr=7.05e-06 , loss=8.16e+00\n",
            " 80/339 [======>.......................] - ETA: 3:26 - loss: 8.9511 - gender_output_loss: 0.7792 - image_quality_output_loss: 1.1161 - age_output_loss: 1.6217 - weight_output_loss: 1.1333 - bag_output_loss: 1.0780 - footwear_output_loss: 1.1117 - pose_output_loss: 1.0195 - emotion_output_loss: 1.0915 - gender_output_acc: 0.5184 - image_quality_output_acc: 0.5168 - age_output_acc: 0.3645 - weight_output_acc: 0.6000 - bag_output_acc: 0.5086 - footwear_output_acc: 0.4430 - pose_output_acc: 0.5914 - emotion_output_acc: 0.6852wd=5.00e-04 , lr=8.11e-06 , loss=8.18e+00\n",
            " 85/339 [======>.......................] - ETA: 3:18 - loss: 8.8874 - gender_output_loss: 0.7746 - image_quality_output_loss: 1.1130 - age_output_loss: 1.6107 - weight_output_loss: 1.1235 - bag_output_loss: 1.0725 - footwear_output_loss: 1.1049 - pose_output_loss: 1.0161 - emotion_output_loss: 1.0721 - gender_output_acc: 0.5206 - image_quality_output_acc: 0.5154 - age_output_acc: 0.3680 - weight_output_acc: 0.6048 - bag_output_acc: 0.5077 - footwear_output_acc: 0.4474 - pose_output_acc: 0.5915 - emotion_output_acc: 0.6912wd=5.00e-04 , lr=9.33e-06 , loss=8.36e+00\n",
            " 90/339 [======>.......................] - ETA: 3:11 - loss: 8.8408 - gender_output_loss: 0.7694 - image_quality_output_loss: 1.1106 - age_output_loss: 1.6028 - weight_output_loss: 1.1179 - bag_output_loss: 1.0637 - footwear_output_loss: 1.0977 - pose_output_loss: 1.0164 - emotion_output_loss: 1.0624 - gender_output_acc: 0.5212 - image_quality_output_acc: 0.5135 - age_output_acc: 0.3670 - weight_output_acc: 0.6056 - bag_output_acc: 0.5104 - footwear_output_acc: 0.4535 - pose_output_acc: 0.5889 - emotion_output_acc: 0.6934wd=5.00e-04 , lr=1.07e-05 , loss=7.87e+00\n",
            " 95/339 [=======>......................] - ETA: 3:04 - loss: 8.8090 - gender_output_loss: 0.7660 - image_quality_output_loss: 1.1078 - age_output_loss: 1.5968 - weight_output_loss: 1.1116 - bag_output_loss: 1.0597 - footwear_output_loss: 1.0986 - pose_output_loss: 1.0113 - emotion_output_loss: 1.0571 - gender_output_acc: 0.5204 - image_quality_output_acc: 0.5132 - age_output_acc: 0.3681 - weight_output_acc: 0.6089 - bag_output_acc: 0.5135 - footwear_output_acc: 0.4526 - pose_output_acc: 0.5931 - emotion_output_acc: 0.6947wd=5.00e-04 , lr=1.23e-05 , loss=8.05e+00\n",
            "100/339 [=======>......................] - ETA: 2:58 - loss: 8.7616 - gender_output_loss: 0.7630 - image_quality_output_loss: 1.1028 - age_output_loss: 1.5895 - weight_output_loss: 1.1038 - bag_output_loss: 1.0519 - footwear_output_loss: 1.0906 - pose_output_loss: 1.0097 - emotion_output_loss: 1.0503 - gender_output_acc: 0.5194 - image_quality_output_acc: 0.5150 - age_output_acc: 0.3653 - weight_output_acc: 0.6109 - bag_output_acc: 0.5184 - footwear_output_acc: 0.4603 - pose_output_acc: 0.5925 - emotion_output_acc: 0.6969wd=5.00e-04 , lr=1.42e-05 , loss=8.24e+00\n",
            "105/339 [========>.....................] - ETA: 2:52 - loss: 8.7215 - gender_output_loss: 0.7611 - image_quality_output_loss: 1.0956 - age_output_loss: 1.5843 - weight_output_loss: 1.0944 - bag_output_loss: 1.0447 - footwear_output_loss: 1.0865 - pose_output_loss: 1.0088 - emotion_output_loss: 1.0460 - gender_output_acc: 0.5158 - image_quality_output_acc: 0.5196 - age_output_acc: 0.3643 - weight_output_acc: 0.6164 - bag_output_acc: 0.5226 - footwear_output_acc: 0.4628 - pose_output_acc: 0.5935 - emotion_output_acc: 0.6976wd=5.00e-04 , lr=1.63e-05 , loss=7.86e+00\n",
            "110/339 [========>.....................] - ETA: 2:47 - loss: 8.6877 - gender_output_loss: 0.7580 - image_quality_output_loss: 1.0927 - age_output_loss: 1.5755 - weight_output_loss: 1.0907 - bag_output_loss: 1.0407 - footwear_output_loss: 1.0833 - pose_output_loss: 1.0063 - emotion_output_loss: 1.0405 - gender_output_acc: 0.5170 - image_quality_output_acc: 0.5202 - age_output_acc: 0.3690 - weight_output_acc: 0.6159 - bag_output_acc: 0.5239 - footwear_output_acc: 0.4642 - pose_output_acc: 0.5935 - emotion_output_acc: 0.6994wd=5.00e-04 , lr=1.87e-05 , loss=7.92e+00\n",
            "115/339 [=========>....................] - ETA: 2:41 - loss: 8.6544 - gender_output_loss: 0.7550 - image_quality_output_loss: 1.0878 - age_output_loss: 1.5724 - weight_output_loss: 1.0857 - bag_output_loss: 1.0350 - footwear_output_loss: 1.0824 - pose_output_loss: 1.0020 - emotion_output_loss: 1.0342 - gender_output_acc: 0.5193 - image_quality_output_acc: 0.5226 - age_output_acc: 0.3696 - weight_output_acc: 0.6166 - bag_output_acc: 0.5258 - footwear_output_acc: 0.4644 - pose_output_acc: 0.5954 - emotion_output_acc: 0.7005wd=5.00e-04 , lr=2.15e-05 , loss=7.98e+00\n",
            "120/339 [=========>....................] - ETA: 2:36 - loss: 8.6242 - gender_output_loss: 0.7517 - image_quality_output_loss: 1.0819 - age_output_loss: 1.5659 - weight_output_loss: 1.0816 - bag_output_loss: 1.0316 - footwear_output_loss: 1.0800 - pose_output_loss: 0.9992 - emotion_output_loss: 1.0324 - gender_output_acc: 0.5224 - image_quality_output_acc: 0.5260 - age_output_acc: 0.3719 - weight_output_acc: 0.6169 - bag_output_acc: 0.5276 - footwear_output_acc: 0.4648 - pose_output_acc: 0.5956 - emotion_output_acc: 0.7003wd=5.00e-04 , lr=2.48e-05 , loss=7.92e+00\n",
            "125/339 [==========>...................] - ETA: 2:31 - loss: 8.5981 - gender_output_loss: 0.7493 - image_quality_output_loss: 1.0770 - age_output_loss: 1.5608 - weight_output_loss: 1.0775 - bag_output_loss: 1.0263 - footwear_output_loss: 1.0799 - pose_output_loss: 1.0001 - emotion_output_loss: 1.0270 - gender_output_acc: 0.5260 - image_quality_output_acc: 0.5282 - age_output_acc: 0.3733 - weight_output_acc: 0.6185 - bag_output_acc: 0.5302 - footwear_output_acc: 0.4657 - pose_output_acc: 0.5945 - emotion_output_acc: 0.7020wd=5.00e-04 , lr=2.85e-05 , loss=7.93e+00\n",
            "130/339 [==========>...................] - ETA: 2:27 - loss: 8.5768 - gender_output_loss: 0.7472 - image_quality_output_loss: 1.0773 - age_output_loss: 1.5565 - weight_output_loss: 1.0761 - bag_output_loss: 1.0206 - footwear_output_loss: 1.0794 - pose_output_loss: 0.9982 - emotion_output_loss: 1.0215 - gender_output_acc: 0.5252 - image_quality_output_acc: 0.5262 - age_output_acc: 0.3740 - weight_output_acc: 0.6166 - bag_output_acc: 0.5315 - footwear_output_acc: 0.4663 - pose_output_acc: 0.5957 - emotion_output_acc: 0.7034wd=5.00e-04 , lr=3.27e-05 , loss=7.97e+00\n",
            "135/339 [==========>...................] - ETA: 2:22 - loss: 8.5555 - gender_output_loss: 0.7451 - image_quality_output_loss: 1.0723 - age_output_loss: 1.5522 - weight_output_loss: 1.0777 - bag_output_loss: 1.0157 - footwear_output_loss: 1.0784 - pose_output_loss: 0.9971 - emotion_output_loss: 1.0171 - gender_output_acc: 0.5248 - image_quality_output_acc: 0.5287 - age_output_acc: 0.3766 - weight_output_acc: 0.6137 - bag_output_acc: 0.5340 - footwear_output_acc: 0.4637 - pose_output_acc: 0.5954 - emotion_output_acc: 0.7039wd=5.00e-04 , lr=3.76e-05 , loss=8.05e+00\n",
            "140/339 [===========>..................] - ETA: 2:18 - loss: 8.5391 - gender_output_loss: 0.7432 - image_quality_output_loss: 1.0690 - age_output_loss: 1.5506 - weight_output_loss: 1.0762 - bag_output_loss: 1.0127 - footwear_output_loss: 1.0758 - pose_output_loss: 0.9963 - emotion_output_loss: 1.0153 - gender_output_acc: 0.5246 - image_quality_output_acc: 0.5304 - age_output_acc: 0.3779 - weight_output_acc: 0.6141 - bag_output_acc: 0.5357 - footwear_output_acc: 0.4665 - pose_output_acc: 0.5951 - emotion_output_acc: 0.7029wd=5.00e-04 , lr=4.33e-05 , loss=8.00e+00\n",
            "145/339 [===========>..................] - ETA: 2:14 - loss: 8.5235 - gender_output_loss: 0.7414 - image_quality_output_loss: 1.0664 - age_output_loss: 1.5470 - weight_output_loss: 1.0773 - bag_output_loss: 1.0099 - footwear_output_loss: 1.0746 - pose_output_loss: 0.9957 - emotion_output_loss: 1.0112 - gender_output_acc: 0.5248 - image_quality_output_acc: 0.5304 - age_output_acc: 0.3787 - weight_output_acc: 0.6129 - bag_output_acc: 0.5358 - footwear_output_acc: 0.4677 - pose_output_acc: 0.5950 - emotion_output_acc: 0.7041wd=5.00e-04 , lr=4.98e-05 , loss=8.10e+00\n",
            "150/339 [============>.................] - ETA: 2:10 - loss: 8.5134 - gender_output_loss: 0.7395 - image_quality_output_loss: 1.0648 - age_output_loss: 1.5473 - weight_output_loss: 1.0761 - bag_output_loss: 1.0080 - footwear_output_loss: 1.0724 - pose_output_loss: 0.9939 - emotion_output_loss: 1.0114 - gender_output_acc: 0.5265 - image_quality_output_acc: 0.5304 - age_output_acc: 0.3758 - weight_output_acc: 0.6112 - bag_output_acc: 0.5365 - footwear_output_acc: 0.4688 - pose_output_acc: 0.5958 - emotion_output_acc: 0.7027wd=5.00e-04 , lr=5.72e-05 , loss=8.09e+00\n",
            "155/339 [============>.................] - ETA: 2:05 - loss: 8.5023 - gender_output_loss: 0.7378 - image_quality_output_loss: 1.0620 - age_output_loss: 1.5448 - weight_output_loss: 1.0763 - bag_output_loss: 1.0052 - footwear_output_loss: 1.0722 - pose_output_loss: 0.9923 - emotion_output_loss: 1.0116 - gender_output_acc: 0.5272 - image_quality_output_acc: 0.5304 - age_output_acc: 0.3762 - weight_output_acc: 0.6107 - bag_output_acc: 0.5375 - footwear_output_acc: 0.4681 - pose_output_acc: 0.5964 - emotion_output_acc: 0.7016wd=5.00e-04 , lr=6.58e-05 , loss=8.22e+00\n",
            "160/339 [=============>................] - ETA: 2:01 - loss: 8.4905 - gender_output_loss: 0.7360 - image_quality_output_loss: 1.0596 - age_output_loss: 1.5433 - weight_output_loss: 1.0770 - bag_output_loss: 1.0027 - footwear_output_loss: 1.0714 - pose_output_loss: 0.9914 - emotion_output_loss: 1.0090 - gender_output_acc: 0.5283 - image_quality_output_acc: 0.5311 - age_output_acc: 0.3758 - weight_output_acc: 0.6104 - bag_output_acc: 0.5389 - footwear_output_acc: 0.4678 - pose_output_acc: 0.5961 - emotion_output_acc: 0.7023wd=5.00e-04 , lr=7.56e-05 , loss=8.17e+00\n",
            "165/339 [=============>................] - ETA: 1:58 - loss: 8.4758 - gender_output_loss: 0.7361 - image_quality_output_loss: 1.0595 - age_output_loss: 1.5399 - weight_output_loss: 1.0736 - bag_output_loss: 1.0018 - footwear_output_loss: 1.0705 - pose_output_loss: 0.9875 - emotion_output_loss: 1.0069 - gender_output_acc: 0.5278 - image_quality_output_acc: 0.5316 - age_output_acc: 0.3767 - weight_output_acc: 0.6114 - bag_output_acc: 0.5384 - footwear_output_acc: 0.4693 - pose_output_acc: 0.5981 - emotion_output_acc: 0.7030wd=5.00e-04 , lr=8.70e-05 , loss=8.12e+00\n",
            "170/339 [==============>...............] - ETA: 1:54 - loss: 8.4614 - gender_output_loss: 0.7349 - image_quality_output_loss: 1.0559 - age_output_loss: 1.5368 - weight_output_loss: 1.0710 - bag_output_loss: 0.9996 - footwear_output_loss: 1.0690 - pose_output_loss: 0.9893 - emotion_output_loss: 1.0049 - gender_output_acc: 0.5279 - image_quality_output_acc: 0.5336 - age_output_acc: 0.3774 - weight_output_acc: 0.6127 - bag_output_acc: 0.5382 - footwear_output_acc: 0.4715 - pose_output_acc: 0.5972 - emotion_output_acc: 0.7031wd=5.00e-04 , lr=1.00e-04 , loss=8.01e+00\n",
            "175/339 [==============>...............] - ETA: 1:50 - loss: 8.4488 - gender_output_loss: 0.7339 - image_quality_output_loss: 1.0546 - age_output_loss: 1.5333 - weight_output_loss: 1.0705 - bag_output_loss: 0.9978 - footwear_output_loss: 1.0681 - pose_output_loss: 0.9900 - emotion_output_loss: 1.0006 - gender_output_acc: 0.5255 - image_quality_output_acc: 0.5337 - age_output_acc: 0.3779 - weight_output_acc: 0.6123 - bag_output_acc: 0.5375 - footwear_output_acc: 0.4709 - pose_output_acc: 0.5959 - emotion_output_acc: 0.7043wd=5.00e-04 , lr=1.15e-04 , loss=7.99e+00\n",
            "180/339 [==============>...............] - ETA: 1:46 - loss: 8.4346 - gender_output_loss: 0.7327 - image_quality_output_loss: 1.0545 - age_output_loss: 1.5309 - weight_output_loss: 1.0690 - bag_output_loss: 0.9960 - footwear_output_loss: 1.0673 - pose_output_loss: 0.9889 - emotion_output_loss: 0.9952 - gender_output_acc: 0.5266 - image_quality_output_acc: 0.5328 - age_output_acc: 0.3774 - weight_output_acc: 0.6128 - bag_output_acc: 0.5389 - footwear_output_acc: 0.4710 - pose_output_acc: 0.5962 - emotion_output_acc: 0.7063wd=5.00e-04 , lr=1.32e-04 , loss=8.02e+00\n",
            "185/339 [===============>..............] - ETA: 1:42 - loss: 8.4180 - gender_output_loss: 0.7313 - image_quality_output_loss: 1.0529 - age_output_loss: 1.5293 - weight_output_loss: 1.0655 - bag_output_loss: 0.9917 - footwear_output_loss: 1.0662 - pose_output_loss: 0.9877 - emotion_output_loss: 0.9934 - gender_output_acc: 0.5287 - image_quality_output_acc: 0.5340 - age_output_acc: 0.3775 - weight_output_acc: 0.6152 - bag_output_acc: 0.5412 - footwear_output_acc: 0.4723 - pose_output_acc: 0.5968 - emotion_output_acc: 0.7069wd=5.00e-04 , lr=1.52e-04 , loss=7.94e+00\n",
            "190/339 [===============>..............] - ETA: 1:39 - loss: 8.4054 - gender_output_loss: 0.7301 - image_quality_output_loss: 1.0505 - age_output_loss: 1.5277 - weight_output_loss: 1.0633 - bag_output_loss: 0.9913 - footwear_output_loss: 1.0650 - pose_output_loss: 0.9866 - emotion_output_loss: 0.9908 - gender_output_acc: 0.5299 - image_quality_output_acc: 0.5355 - age_output_acc: 0.3773 - weight_output_acc: 0.6158 - bag_output_acc: 0.5411 - footwear_output_acc: 0.4725 - pose_output_acc: 0.5974 - emotion_output_acc: 0.7081wd=5.00e-04 , lr=1.75e-04 , loss=7.82e+00\n",
            "195/339 [================>.............] - ETA: 1:35 - loss: 8.3953 - gender_output_loss: 0.7292 - image_quality_output_loss: 1.0498 - age_output_loss: 1.5237 - weight_output_loss: 1.0630 - bag_output_loss: 0.9904 - footwear_output_loss: 1.0646 - pose_output_loss: 0.9869 - emotion_output_loss: 0.9876 - gender_output_acc: 0.5300 - image_quality_output_acc: 0.5354 - age_output_acc: 0.3811 - weight_output_acc: 0.6149 - bag_output_acc: 0.5405 - footwear_output_acc: 0.4723 - pose_output_acc: 0.5970 - emotion_output_acc: 0.7091wd=5.00e-04 , lr=2.01e-04 , loss=7.94e+00\n",
            "200/339 [================>.............] - ETA: 1:31 - loss: 8.3851 - gender_output_loss: 0.7280 - image_quality_output_loss: 1.0472 - age_output_loss: 1.5219 - weight_output_loss: 1.0623 - bag_output_loss: 0.9882 - footwear_output_loss: 1.0630 - pose_output_loss: 0.9877 - emotion_output_loss: 0.9869 - gender_output_acc: 0.5317 - image_quality_output_acc: 0.5370 - age_output_acc: 0.3814 - weight_output_acc: 0.6167 - bag_output_acc: 0.5437 - footwear_output_acc: 0.4727 - pose_output_acc: 0.5964 - emotion_output_acc: 0.7089wd=5.00e-04 , lr=2.31e-04 , loss=8.01e+00\n",
            "205/339 [=================>............] - ETA: 1:28 - loss: 8.3792 - gender_output_loss: 0.7269 - image_quality_output_loss: 1.0460 - age_output_loss: 1.5195 - weight_output_loss: 1.0611 - bag_output_loss: 0.9878 - footwear_output_loss: 1.0631 - pose_output_loss: 0.9865 - emotion_output_loss: 0.9883 - gender_output_acc: 0.5323 - image_quality_output_acc: 0.5378 - age_output_acc: 0.3817 - weight_output_acc: 0.6178 - bag_output_acc: 0.5430 - footwear_output_acc: 0.4730 - pose_output_acc: 0.5970 - emotion_output_acc: 0.7075wd=5.00e-04 , lr=2.66e-04 , loss=7.99e+00\n",
            "210/339 [=================>............] - ETA: 1:24 - loss: 8.3699 - gender_output_loss: 0.7254 - image_quality_output_loss: 1.0454 - age_output_loss: 1.5186 - weight_output_loss: 1.0602 - bag_output_loss: 0.9872 - footwear_output_loss: 1.0614 - pose_output_loss: 0.9857 - emotion_output_loss: 0.9861 - gender_output_acc: 0.5342 - image_quality_output_acc: 0.5366 - age_output_acc: 0.3805 - weight_output_acc: 0.6185 - bag_output_acc: 0.5432 - footwear_output_acc: 0.4754 - pose_output_acc: 0.5964 - emotion_output_acc: 0.7077wd=5.00e-04 , lr=3.05e-04 , loss=8.14e+00\n",
            "215/339 [==================>...........] - ETA: 1:21 - loss: 8.3609 - gender_output_loss: 0.7241 - image_quality_output_loss: 1.0445 - age_output_loss: 1.5161 - weight_output_loss: 1.0590 - bag_output_loss: 0.9853 - footwear_output_loss: 1.0607 - pose_output_loss: 0.9839 - emotion_output_loss: 0.9873 - gender_output_acc: 0.5349 - image_quality_output_acc: 0.5374 - age_output_acc: 0.3812 - weight_output_acc: 0.6190 - bag_output_acc: 0.5437 - footwear_output_acc: 0.4757 - pose_output_acc: 0.5972 - emotion_output_acc: 0.7067wd=5.00e-04 , lr=3.51e-04 , loss=7.99e+00\n",
            "220/339 [==================>...........] - ETA: 1:17 - loss: 8.3545 - gender_output_loss: 0.7233 - image_quality_output_loss: 1.0439 - age_output_loss: 1.5146 - weight_output_loss: 1.0585 - bag_output_loss: 0.9844 - footwear_output_loss: 1.0595 - pose_output_loss: 0.9831 - emotion_output_loss: 0.9872 - gender_output_acc: 0.5361 - image_quality_output_acc: 0.5372 - age_output_acc: 0.3810 - weight_output_acc: 0.6197 - bag_output_acc: 0.5446 - footwear_output_acc: 0.4760 - pose_output_acc: 0.5970 - emotion_output_acc: 0.7063wd=5.00e-04 , lr=4.04e-04 , loss=7.98e+00\n",
            "225/339 [==================>...........] - ETA: 1:14 - loss: 8.3428 - gender_output_loss: 0.7221 - image_quality_output_loss: 1.0411 - age_output_loss: 1.5141 - weight_output_loss: 1.0576 - bag_output_loss: 0.9827 - footwear_output_loss: 1.0587 - pose_output_loss: 0.9807 - emotion_output_loss: 0.9857 - gender_output_acc: 0.5372 - image_quality_output_acc: 0.5393 - age_output_acc: 0.3796 - weight_output_acc: 0.6207 - bag_output_acc: 0.5447 - footwear_output_acc: 0.4768 - pose_output_acc: 0.5982 - emotion_output_acc: 0.7063wd=5.00e-04 , lr=4.64e-04 , loss=8.08e+00\n",
            "230/339 [===================>..........] - ETA: 1:10 - loss: 8.3378 - gender_output_loss: 0.7215 - image_quality_output_loss: 1.0404 - age_output_loss: 1.5114 - weight_output_loss: 1.0577 - bag_output_loss: 0.9828 - footwear_output_loss: 1.0588 - pose_output_loss: 0.9791 - emotion_output_loss: 0.9862 - gender_output_acc: 0.5379 - image_quality_output_acc: 0.5393 - age_output_acc: 0.3804 - weight_output_acc: 0.6201 - bag_output_acc: 0.5444 - footwear_output_acc: 0.4766 - pose_output_acc: 0.5989 - emotion_output_acc: 0.7060wd=5.00e-04 , lr=5.34e-04 , loss=7.83e+00\n",
            "235/339 [===================>..........] - ETA: 1:07 - loss: 8.3313 - gender_output_loss: 0.7205 - image_quality_output_loss: 1.0389 - age_output_loss: 1.5106 - weight_output_loss: 1.0570 - bag_output_loss: 0.9829 - footwear_output_loss: 1.0576 - pose_output_loss: 0.9795 - emotion_output_loss: 0.9843 - gender_output_acc: 0.5388 - image_quality_output_acc: 0.5402 - age_output_acc: 0.3797 - weight_output_acc: 0.6199 - bag_output_acc: 0.5444 - footwear_output_acc: 0.4783 - pose_output_acc: 0.5984 - emotion_output_acc: 0.7063wd=5.00e-04 , lr=6.14e-04 , loss=8.11e+00\n",
            "240/339 [====================>.........] - ETA: 1:03 - loss: 8.3276 - gender_output_loss: 0.7196 - image_quality_output_loss: 1.0383 - age_output_loss: 1.5086 - weight_output_loss: 1.0578 - bag_output_loss: 0.9816 - footwear_output_loss: 1.0581 - pose_output_loss: 0.9784 - emotion_output_loss: 0.9851 - gender_output_acc: 0.5405 - image_quality_output_acc: 0.5400 - age_output_acc: 0.3801 - weight_output_acc: 0.6190 - bag_output_acc: 0.5444 - footwear_output_acc: 0.4780 - pose_output_acc: 0.5991 - emotion_output_acc: 0.7055wd=5.00e-04 , lr=7.05e-04 , loss=8.03e+00\n",
            "245/339 [====================>.........] - ETA: 1:00 - loss: 8.3192 - gender_output_loss: 0.7194 - image_quality_output_loss: 1.0368 - age_output_loss: 1.5071 - weight_output_loss: 1.0565 - bag_output_loss: 0.9802 - footwear_output_loss: 1.0564 - pose_output_loss: 0.9783 - emotion_output_loss: 0.9845 - gender_output_acc: 0.5401 - image_quality_output_acc: 0.5413 - age_output_acc: 0.3805 - weight_output_acc: 0.6189 - bag_output_acc: 0.5450 - footwear_output_acc: 0.4792 - pose_output_acc: 0.5990 - emotion_output_acc: 0.7054wd=5.00e-04 , lr=8.11e-04 , loss=8.15e+00\n",
            "250/339 [=====================>........] - ETA: 57s - loss: 8.3124 - gender_output_loss: 0.7189 - image_quality_output_loss: 1.0359 - age_output_loss: 1.5057 - weight_output_loss: 1.0571 - bag_output_loss: 0.9792 - footwear_output_loss: 1.0557 - pose_output_loss: 0.9760 - emotion_output_loss: 0.9839 - gender_output_acc: 0.5396 - image_quality_output_acc: 0.5420 - age_output_acc: 0.3805 - weight_output_acc: 0.6186 - bag_output_acc: 0.5457 - footwear_output_acc: 0.4801 - pose_output_acc: 0.6001 - emotion_output_acc: 0.7051wd=5.00e-04 , lr=9.33e-04 , loss=7.92e+00\n",
            "255/339 [=====================>........] - ETA: 53s - loss: 8.3094 - gender_output_loss: 0.7179 - image_quality_output_loss: 1.0359 - age_output_loss: 1.5067 - weight_output_loss: 1.0554 - bag_output_loss: 0.9784 - footwear_output_loss: 1.0552 - pose_output_loss: 0.9755 - emotion_output_loss: 0.9844 - gender_output_acc: 0.5412 - image_quality_output_acc: 0.5413 - age_output_acc: 0.3786 - weight_output_acc: 0.6196 - bag_output_acc: 0.5466 - footwear_output_acc: 0.4801 - pose_output_acc: 0.6006 - emotion_output_acc: 0.7044wd=5.00e-04 , lr=1.07e-03 , loss=7.98e+00\n",
            "260/339 [======================>.......] - ETA: 50s - loss: 8.3019 - gender_output_loss: 0.7171 - image_quality_output_loss: 1.0351 - age_output_loss: 1.5057 - weight_output_loss: 1.0532 - bag_output_loss: 0.9764 - footwear_output_loss: 1.0549 - pose_output_loss: 0.9753 - emotion_output_loss: 0.9842 - gender_output_acc: 0.5425 - image_quality_output_acc: 0.5412 - age_output_acc: 0.3784 - weight_output_acc: 0.6214 - bag_output_acc: 0.5478 - footwear_output_acc: 0.4790 - pose_output_acc: 0.6005 - emotion_output_acc: 0.7044wd=5.00e-04 , lr=1.23e-03 , loss=8.16e+00\n",
            "265/339 [======================>.......] - ETA: 47s - loss: 8.2992 - gender_output_loss: 0.7163 - image_quality_output_loss: 1.0343 - age_output_loss: 1.5042 - weight_output_loss: 1.0530 - bag_output_loss: 0.9775 - footwear_output_loss: 1.0545 - pose_output_loss: 0.9752 - emotion_output_loss: 0.9843 - gender_output_acc: 0.5427 - image_quality_output_acc: 0.5410 - age_output_acc: 0.3775 - weight_output_acc: 0.6215 - bag_output_acc: 0.5471 - footwear_output_acc: 0.4797 - pose_output_acc: 0.6005 - emotion_output_acc: 0.7041wd=5.00e-04 , lr=1.42e-03 , loss=7.92e+00\n",
            "270/339 [======================>.......] - ETA: 43s - loss: 8.2914 - gender_output_loss: 0.7158 - image_quality_output_loss: 1.0344 - age_output_loss: 1.5022 - weight_output_loss: 1.0506 - bag_output_loss: 0.9768 - footwear_output_loss: 1.0547 - pose_output_loss: 0.9731 - emotion_output_loss: 0.9838 - gender_output_acc: 0.5433 - image_quality_output_acc: 0.5404 - age_output_acc: 0.3781 - weight_output_acc: 0.6222 - bag_output_acc: 0.5472 - footwear_output_acc: 0.4784 - pose_output_acc: 0.6021 - emotion_output_acc: 0.7039wd=5.00e-04 , lr=1.63e-03 , loss=8.16e+00\n",
            "275/339 [=======================>......] - ETA: 40s - loss: 8.2878 - gender_output_loss: 0.7153 - image_quality_output_loss: 1.0331 - age_output_loss: 1.5021 - weight_output_loss: 1.0502 - bag_output_loss: 0.9769 - footwear_output_loss: 1.0546 - pose_output_loss: 0.9727 - emotion_output_loss: 0.9829 - gender_output_acc: 0.5439 - image_quality_output_acc: 0.5409 - age_output_acc: 0.3780 - weight_output_acc: 0.6226 - bag_output_acc: 0.5469 - footwear_output_acc: 0.4778 - pose_output_acc: 0.6018 - emotion_output_acc: 0.7039wd=5.00e-04 , lr=1.87e-03 , loss=7.88e+00\n",
            "280/339 [=======================>......] - ETA: 37s - loss: 8.2833 - gender_output_loss: 0.7148 - image_quality_output_loss: 1.0328 - age_output_loss: 1.5005 - weight_output_loss: 1.0487 - bag_output_loss: 0.9774 - footwear_output_loss: 1.0546 - pose_output_loss: 0.9735 - emotion_output_loss: 0.9809 - gender_output_acc: 0.5443 - image_quality_output_acc: 0.5401 - age_output_acc: 0.3782 - weight_output_acc: 0.6230 - bag_output_acc: 0.5451 - footwear_output_acc: 0.4780 - pose_output_acc: 0.6012 - emotion_output_acc: 0.7047wd=5.00e-04 , lr=2.15e-03 , loss=8.09e+00\n",
            "285/339 [========================>.....] - ETA: 34s - loss: 8.2811 - gender_output_loss: 0.7141 - image_quality_output_loss: 1.0328 - age_output_loss: 1.5002 - weight_output_loss: 1.0487 - bag_output_loss: 0.9769 - footwear_output_loss: 1.0537 - pose_output_loss: 0.9727 - emotion_output_loss: 0.9820 - gender_output_acc: 0.5453 - image_quality_output_acc: 0.5396 - age_output_acc: 0.3773 - weight_output_acc: 0.6224 - bag_output_acc: 0.5452 - footwear_output_acc: 0.4788 - pose_output_acc: 0.6016 - emotion_output_acc: 0.7036wd=5.00e-04 , lr=2.48e-03 , loss=8.04e+00\n",
            "290/339 [========================>.....] - ETA: 30s - loss: 8.2779 - gender_output_loss: 0.7138 - image_quality_output_loss: 1.0322 - age_output_loss: 1.5002 - weight_output_loss: 1.0491 - bag_output_loss: 0.9758 - footwear_output_loss: 1.0529 - pose_output_loss: 0.9729 - emotion_output_loss: 0.9809 - gender_output_acc: 0.5448 - image_quality_output_acc: 0.5392 - age_output_acc: 0.3772 - weight_output_acc: 0.6216 - bag_output_acc: 0.5462 - footwear_output_acc: 0.4797 - pose_output_acc: 0.6013 - emotion_output_acc: 0.7036wd=5.00e-04 , lr=2.85e-03 , loss=8.16e+00\n",
            "295/339 [=========================>....] - ETA: 27s - loss: 8.2706 - gender_output_loss: 0.7129 - image_quality_output_loss: 1.0312 - age_output_loss: 1.4994 - weight_output_loss: 1.0488 - bag_output_loss: 0.9739 - footwear_output_loss: 1.0517 - pose_output_loss: 0.9723 - emotion_output_loss: 0.9803 - gender_output_acc: 0.5470 - image_quality_output_acc: 0.5398 - age_output_acc: 0.3770 - weight_output_acc: 0.6221 - bag_output_acc: 0.5472 - footwear_output_acc: 0.4811 - pose_output_acc: 0.6017 - emotion_output_acc: 0.7036wd=5.00e-04 , lr=3.27e-03 , loss=8.09e+00\n",
            "300/339 [=========================>....] - ETA: 24s - loss: 8.2647 - gender_output_loss: 0.7123 - image_quality_output_loss: 1.0311 - age_output_loss: 1.4980 - weight_output_loss: 1.0481 - bag_output_loss: 0.9734 - footwear_output_loss: 1.0507 - pose_output_loss: 0.9732 - emotion_output_loss: 0.9779 - gender_output_acc: 0.5479 - image_quality_output_acc: 0.5394 - age_output_acc: 0.3785 - weight_output_acc: 0.6223 - bag_output_acc: 0.5477 - footwear_output_acc: 0.4821 - pose_output_acc: 0.6011 - emotion_output_acc: 0.7046wd=5.00e-04 , lr=3.76e-03 , loss=7.85e+00\n",
            "305/339 [=========================>....] - ETA: 21s - loss: 8.2561 - gender_output_loss: 0.7116 - image_quality_output_loss: 1.0311 - age_output_loss: 1.4960 - weight_output_loss: 1.0438 - bag_output_loss: 0.9732 - footwear_output_loss: 1.0500 - pose_output_loss: 0.9723 - emotion_output_loss: 0.9781 - gender_output_acc: 0.5488 - image_quality_output_acc: 0.5390 - age_output_acc: 0.3794 - weight_output_acc: 0.6245 - bag_output_acc: 0.5477 - footwear_output_acc: 0.4824 - pose_output_acc: 0.6016 - emotion_output_acc: 0.7045wd=5.00e-04 , lr=4.33e-03 , loss=7.92e+00\n",
            "310/339 [==========================>...] - ETA: 18s - loss: 8.2536 - gender_output_loss: 0.7114 - image_quality_output_loss: 1.0312 - age_output_loss: 1.4955 - weight_output_loss: 1.0430 - bag_output_loss: 0.9724 - footwear_output_loss: 1.0498 - pose_output_loss: 0.9712 - emotion_output_loss: 0.9789 - gender_output_acc: 0.5485 - image_quality_output_acc: 0.5381 - age_output_acc: 0.3795 - weight_output_acc: 0.6242 - bag_output_acc: 0.5479 - footwear_output_acc: 0.4817 - pose_output_acc: 0.6025 - emotion_output_acc: 0.7037wd=5.00e-04 , lr=4.98e-03 , loss=7.74e+00\n",
            "315/339 [==========================>...] - ETA: 15s - loss: 8.2494 - gender_output_loss: 0.7112 - image_quality_output_loss: 1.0314 - age_output_loss: 1.4943 - weight_output_loss: 1.0418 - bag_output_loss: 0.9722 - footwear_output_loss: 1.0497 - pose_output_loss: 0.9703 - emotion_output_loss: 0.9786 - gender_output_acc: 0.5483 - image_quality_output_acc: 0.5378 - age_output_acc: 0.3801 - weight_output_acc: 0.6248 - bag_output_acc: 0.5473 - footwear_output_acc: 0.4809 - pose_output_acc: 0.6033 - emotion_output_acc: 0.7037wd=5.00e-04 , lr=5.72e-03 , loss=8.10e+00\n",
            "320/339 [===========================>..] - ETA: 11s - loss: 8.2401 - gender_output_loss: 0.7106 - image_quality_output_loss: 1.0303 - age_output_loss: 1.4934 - weight_output_loss: 1.0399 - bag_output_loss: 0.9711 - footwear_output_loss: 1.0487 - pose_output_loss: 0.9692 - emotion_output_loss: 0.9769 - gender_output_acc: 0.5495 - image_quality_output_acc: 0.5387 - age_output_acc: 0.3799 - weight_output_acc: 0.6258 - bag_output_acc: 0.5484 - footwear_output_acc: 0.4817 - pose_output_acc: 0.6038 - emotion_output_acc: 0.7044wd=5.00e-04 , lr=6.58e-03 , loss=7.99e+00\n",
            "325/339 [===========================>..] - ETA: 8s - loss: 8.2340 - gender_output_loss: 0.7104 - image_quality_output_loss: 1.0295 - age_output_loss: 1.4929 - weight_output_loss: 1.0379 - bag_output_loss: 0.9705 - footwear_output_loss: 1.0485 - pose_output_loss: 0.9685 - emotion_output_loss: 0.9759 - gender_output_acc: 0.5496 - image_quality_output_acc: 0.5392 - age_output_acc: 0.3804 - weight_output_acc: 0.6269 - bag_output_acc: 0.5477 - footwear_output_acc: 0.4813 - pose_output_acc: 0.6042 - emotion_output_acc: 0.7043wd=5.00e-04 , lr=7.56e-03 , loss=7.65e+00\n",
            "330/339 [============================>.] - ETA: 5s - loss: 8.2288 - gender_output_loss: 0.7098 - image_quality_output_loss: 1.0286 - age_output_loss: 1.4922 - weight_output_loss: 1.0374 - bag_output_loss: 0.9694 - footwear_output_loss: 1.0478 - pose_output_loss: 0.9680 - emotion_output_loss: 0.9757 - gender_output_acc: 0.5504 - image_quality_output_acc: 0.5399 - age_output_acc: 0.3805 - weight_output_acc: 0.6266 - bag_output_acc: 0.5484 - footwear_output_acc: 0.4818 - pose_output_acc: 0.6045 - emotion_output_acc: 0.7044wd=5.00e-04 , lr=8.70e-03 , loss=7.84e+00\n",
            "335/339 [============================>.] - ETA: 2s - loss: 8.2243 - gender_output_loss: 0.7093 - image_quality_output_loss: 1.0277 - age_output_loss: 1.4918 - weight_output_loss: 1.0370 - bag_output_loss: 0.9692 - footwear_output_loss: 1.0477 - pose_output_loss: 0.9678 - emotion_output_loss: 0.9737 - gender_output_acc: 0.5505 - image_quality_output_acc: 0.5403 - age_output_acc: 0.3804 - weight_output_acc: 0.6266 - bag_output_acc: 0.5482 - footwear_output_acc: 0.4815 - pose_output_acc: 0.6045 - emotion_output_acc: 0.7053wd=5.00e-04 , lr=1.00e-02 , loss=7.89e+00\n",
            "339/339 [==============================] - 211s 623ms/step - loss: 8.2208 - gender_output_loss: 0.7090 - image_quality_output_loss: 1.0266 - age_output_loss: 1.4914 - weight_output_loss: 1.0381 - bag_output_loss: 0.9688 - footwear_output_loss: 1.0472 - pose_output_loss: 0.9663 - emotion_output_loss: 0.9733 - gender_output_acc: 0.5504 - image_quality_output_acc: 0.5411 - age_output_acc: 0.3799 - weight_output_acc: 0.6258 - bag_output_acc: 0.5484 - footwear_output_acc: 0.4820 - pose_output_acc: 0.6054 - emotion_output_acc: 0.7053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAELCAYAAADDZxFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCFgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AR_V4h4kpZY",
        "colab_type": "code",
        "outputId": "0a089c50-4292-41d7-c624-294dacd86804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "max_lr = 0.001\n",
        "base_lr = max_lr/100\n",
        "max_m = 0.98\n",
        "base_m = 0.85\n",
        "\n",
        "cyclical_momentum = True\n",
        "augment = True\n",
        "cycles = 8\n",
        "\n",
        "iterations = round(len(train_df)/batch_size*epochs)\n",
        "iterations = list(range(0,iterations+1))\n",
        "step_size = len(iterations)/(cycles)\n",
        "\n",
        "\n",
        "clr =  CyclicLR(base_lr=base_lr,\n",
        "                max_lr=max_lr,\n",
        "                step_size=step_size,\n",
        "                max_m=max_m,\n",
        "                base_m=base_m,\n",
        "                cyclical_momentum=cyclical_momentum)\n",
        "\n",
        "import os\n",
        "from keras import backend as K\n",
        "# Prepare model model saving directory.\n",
        "save_dir = '/content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/'\n",
        "model_name = 'assignment5_Inceptionv3_model_best.h5' \n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "print(filepath)\n",
        "\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             #monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "callbacks = [clr, checkpoint]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVGh9H-ExDOu",
        "colab_type": "code",
        "outputId": "04eddc89-35c8-435e-bc4b-61128f2288da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run training, with or without data augmentation.\n",
        "model.fit_generator(\n",
        "          generator=train_gen,\n",
        "          validation_data=valid_gen,\n",
        "          use_multiprocessing=True,\n",
        "          epochs=200,\n",
        "          workers=1,\n",
        "          #shuffle=True,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/200\n",
            "338/339 [============================>.] - ETA: 0s - loss: 8.2968 - gender_output_loss: 0.7258 - image_quality_output_loss: 1.0385 - age_output_loss: 1.4995 - weight_output_loss: 1.0634 - bag_output_loss: 0.9537 - footwear_output_loss: 1.0640 - pose_output_loss: 0.9693 - emotion_output_loss: 0.9826 - gender_output_acc: 0.5277 - image_quality_output_acc: 0.5199 - age_output_acc: 0.3672 - weight_output_acc: 0.6023 - bag_output_acc: 0.5389 - footwear_output_acc: 0.4568 - pose_output_acc: 0.6054 - emotion_output_acc: 0.6898\n",
            "339/339 [==============================] - 188s 553ms/step - loss: 8.2971 - gender_output_loss: 0.7257 - image_quality_output_loss: 1.0381 - age_output_loss: 1.4994 - weight_output_loss: 1.0642 - bag_output_loss: 0.9534 - footwear_output_loss: 1.0643 - pose_output_loss: 0.9697 - emotion_output_loss: 0.9823 - gender_output_acc: 0.5277 - image_quality_output_acc: 0.5200 - age_output_acc: 0.3669 - weight_output_acc: 0.6019 - bag_output_acc: 0.5393 - footwear_output_acc: 0.4563 - pose_output_acc: 0.6050 - emotion_output_acc: 0.6900 - val_loss: 8.4800 - val_gender_output_loss: 0.7081 - val_image_quality_output_loss: 1.0324 - val_age_output_loss: 1.5518 - val_weight_output_loss: 1.0864 - val_bag_output_loss: 0.9829 - val_footwear_output_loss: 1.0676 - val_pose_output_loss: 1.0082 - val_emotion_output_loss: 1.0426 - val_gender_output_acc: 0.5298 - val_image_quality_output_acc: 0.5346 - val_age_output_acc: 0.3341 - val_weight_output_acc: 0.6458 - val_bag_output_acc: 0.5476 - val_footwear_output_acc: 0.4710 - val_pose_output_acc: 0.5867 - val_emotion_output_acc: 0.6711\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 8.47998, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 2/200\n",
            "339/339 [==============================] - 166s 490ms/step - loss: 7.9471 - gender_output_loss: 0.6872 - image_quality_output_loss: 0.9959 - age_output_loss: 1.4439 - weight_output_loss: 1.0074 - bag_output_loss: 0.9247 - footwear_output_loss: 1.0150 - pose_output_loss: 0.9409 - emotion_output_loss: 0.9321 - gender_output_acc: 0.5607 - image_quality_output_acc: 0.5472 - age_output_acc: 0.3853 - weight_output_acc: 0.6287 - bag_output_acc: 0.5535 - footwear_output_acc: 0.4904 - pose_output_acc: 0.6158 - emotion_output_acc: 0.7117 - val_loss: 7.9010 - val_gender_output_loss: 0.6823 - val_image_quality_output_loss: 0.9845 - val_age_output_loss: 1.4398 - val_weight_output_loss: 0.9937 - val_bag_output_loss: 0.9326 - val_footwear_output_loss: 1.0062 - val_pose_output_loss: 0.9298 - val_emotion_output_loss: 0.9321 - val_gender_output_acc: 0.5584 - val_image_quality_output_acc: 0.5435 - val_age_output_acc: 0.3925 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5450 - val_footwear_output_acc: 0.5000 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00002: val_loss improved from 8.47998 to 7.90102, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 3/200\n",
            "339/339 [==============================] - 165s 488ms/step - loss: 7.8942 - gender_output_loss: 0.6817 - image_quality_output_loss: 0.9901 - age_output_loss: 1.4330 - weight_output_loss: 1.0010 - bag_output_loss: 0.9216 - footwear_output_loss: 1.0053 - pose_output_loss: 0.9358 - emotion_output_loss: 0.9257 - gender_output_acc: 0.5662 - image_quality_output_acc: 0.5489 - age_output_acc: 0.3950 - weight_output_acc: 0.6316 - bag_output_acc: 0.5595 - footwear_output_acc: 0.5052 - pose_output_acc: 0.6158 - emotion_output_acc: 0.7137 - val_loss: 7.8222 - val_gender_output_loss: 0.6757 - val_image_quality_output_loss: 0.9781 - val_age_output_loss: 1.4293 - val_weight_output_loss: 0.9744 - val_bag_output_loss: 0.9293 - val_footwear_output_loss: 0.9789 - val_pose_output_loss: 0.9261 - val_emotion_output_loss: 0.9304 - val_gender_output_acc: 0.5863 - val_image_quality_output_acc: 0.5618 - val_age_output_acc: 0.3962 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5446 - val_footwear_output_acc: 0.5290 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00003: val_loss improved from 7.90102 to 7.82221, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 4/200\n",
            "339/339 [==============================] - 167s 492ms/step - loss: 7.8572 - gender_output_loss: 0.6787 - image_quality_output_loss: 0.9872 - age_output_loss: 1.4307 - weight_output_loss: 0.9970 - bag_output_loss: 0.9166 - footwear_output_loss: 0.9909 - pose_output_loss: 0.9362 - emotion_output_loss: 0.9198 - gender_output_acc: 0.5716 - image_quality_output_acc: 0.5499 - age_output_acc: 0.3924 - weight_output_acc: 0.6313 - bag_output_acc: 0.5578 - footwear_output_acc: 0.5177 - pose_output_acc: 0.6156 - emotion_output_acc: 0.7139 - val_loss: 7.8169 - val_gender_output_loss: 0.6771 - val_image_quality_output_loss: 0.9797 - val_age_output_loss: 1.4329 - val_weight_output_loss: 0.9887 - val_bag_output_loss: 0.9234 - val_footwear_output_loss: 0.9639 - val_pose_output_loss: 0.9248 - val_emotion_output_loss: 0.9265 - val_gender_output_acc: 0.5711 - val_image_quality_output_acc: 0.5554 - val_age_output_acc: 0.3962 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5610 - val_footwear_output_acc: 0.5312 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00004: val_loss improved from 7.82221 to 7.81693, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 5/200\n",
            "339/339 [==============================] - 166s 490ms/step - loss: 7.8546 - gender_output_loss: 0.6775 - image_quality_output_loss: 0.9898 - age_output_loss: 1.4248 - weight_output_loss: 0.9993 - bag_output_loss: 0.9191 - footwear_output_loss: 0.9872 - pose_output_loss: 0.9370 - emotion_output_loss: 0.9199 - gender_output_acc: 0.5713 - image_quality_output_acc: 0.5509 - age_output_acc: 0.3945 - weight_output_acc: 0.6324 - bag_output_acc: 0.5603 - footwear_output_acc: 0.5285 - pose_output_acc: 0.6157 - emotion_output_acc: 0.7139 - val_loss: 7.7792 - val_gender_output_loss: 0.6721 - val_image_quality_output_loss: 0.9793 - val_age_output_loss: 1.4228 - val_weight_output_loss: 0.9777 - val_bag_output_loss: 0.9184 - val_footwear_output_loss: 0.9521 - val_pose_output_loss: 0.9187 - val_emotion_output_loss: 0.9380 - val_gender_output_acc: 0.5789 - val_image_quality_output_acc: 0.5595 - val_age_output_acc: 0.3955 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.5610 - val_footwear_output_acc: 0.5499 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00005: val_loss improved from 7.81693 to 7.77917, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 6/200\n",
            "339/339 [==============================] - 166s 490ms/step - loss: 7.8194 - gender_output_loss: 0.6729 - image_quality_output_loss: 0.9895 - age_output_loss: 1.4229 - weight_output_loss: 0.9987 - bag_output_loss: 0.9169 - footwear_output_loss: 0.9663 - pose_output_loss: 0.9340 - emotion_output_loss: 0.9182 - gender_output_acc: 0.5761 - image_quality_output_acc: 0.5495 - age_output_acc: 0.3951 - weight_output_acc: 0.6320 - bag_output_acc: 0.5632 - footwear_output_acc: 0.5477 - pose_output_acc: 0.6158 - emotion_output_acc: 0.7137 - val_loss: 7.7826 - val_gender_output_loss: 0.6645 - val_image_quality_output_loss: 0.9812 - val_age_output_loss: 1.4229 - val_weight_output_loss: 0.9798 - val_bag_output_loss: 0.9287 - val_footwear_output_loss: 0.9487 - val_pose_output_loss: 0.9198 - val_emotion_output_loss: 0.9370 - val_gender_output_acc: 0.5744 - val_image_quality_output_acc: 0.5618 - val_age_output_acc: 0.3914 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5406 - val_footwear_output_acc: 0.5673 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 7.77917\n",
            "Epoch 7/200\n",
            "339/339 [==============================] - 168s 495ms/step - loss: 7.7923 - gender_output_loss: 0.6659 - image_quality_output_loss: 0.9886 - age_output_loss: 1.4204 - weight_output_loss: 0.9937 - bag_output_loss: 0.9158 - footwear_output_loss: 0.9559 - pose_output_loss: 0.9335 - emotion_output_loss: 0.9185 - gender_output_acc: 0.5889 - image_quality_output_acc: 0.5500 - age_output_acc: 0.3986 - weight_output_acc: 0.6317 - bag_output_acc: 0.5611 - footwear_output_acc: 0.5526 - pose_output_acc: 0.6158 - emotion_output_acc: 0.7135 - val_loss: 7.7121 - val_gender_output_loss: 0.6587 - val_image_quality_output_loss: 0.9739 - val_age_output_loss: 1.4216 - val_weight_output_loss: 0.9672 - val_bag_output_loss: 0.9240 - val_footwear_output_loss: 0.9163 - val_pose_output_loss: 0.9170 - val_emotion_output_loss: 0.9334 - val_gender_output_acc: 0.5964 - val_image_quality_output_acc: 0.5618 - val_age_output_acc: 0.3761 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5536 - val_footwear_output_acc: 0.5859 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00007: val_loss improved from 7.77917 to 7.71208, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 8/200\n",
            "339/339 [==============================] - 167s 493ms/step - loss: 7.7611 - gender_output_loss: 0.6603 - image_quality_output_loss: 0.9860 - age_output_loss: 1.4155 - weight_output_loss: 0.9920 - bag_output_loss: 0.9114 - footwear_output_loss: 0.9476 - pose_output_loss: 0.9315 - emotion_output_loss: 0.9167 - gender_output_acc: 0.6032 - image_quality_output_acc: 0.5500 - age_output_acc: 0.3956 - weight_output_acc: 0.6317 - bag_output_acc: 0.5588 - footwear_output_acc: 0.5619 - pose_output_acc: 0.6154 - emotion_output_acc: 0.7139 - val_loss: 7.7242 - val_gender_output_loss: 0.6597 - val_image_quality_output_loss: 0.9748 - val_age_output_loss: 1.4216 - val_weight_output_loss: 0.9658 - val_bag_output_loss: 0.9150 - val_footwear_output_loss: 0.9294 - val_pose_output_loss: 0.9213 - val_emotion_output_loss: 0.9366 - val_gender_output_acc: 0.6016 - val_image_quality_output_acc: 0.5618 - val_age_output_acc: 0.3962 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5621 - val_footwear_output_acc: 0.5707 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 7.71208\n",
            "Epoch 9/200\n",
            "339/339 [==============================] - 167s 494ms/step - loss: 7.7391 - gender_output_loss: 0.6554 - image_quality_output_loss: 0.9851 - age_output_loss: 1.4157 - weight_output_loss: 0.9922 - bag_output_loss: 0.9096 - footwear_output_loss: 0.9412 - pose_output_loss: 0.9263 - emotion_output_loss: 0.9137 - gender_output_acc: 0.6093 - image_quality_output_acc: 0.5506 - age_output_acc: 0.3956 - weight_output_acc: 0.6325 - bag_output_acc: 0.5609 - footwear_output_acc: 0.5652 - pose_output_acc: 0.6157 - emotion_output_acc: 0.7136 - val_loss: 7.6896 - val_gender_output_loss: 0.6507 - val_image_quality_output_loss: 0.9760 - val_age_output_loss: 1.4165 - val_weight_output_loss: 0.9716 - val_bag_output_loss: 0.9151 - val_footwear_output_loss: 0.9114 - val_pose_output_loss: 0.9179 - val_emotion_output_loss: 0.9304 - val_gender_output_acc: 0.6064 - val_image_quality_output_acc: 0.5614 - val_age_output_acc: 0.3929 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5618 - val_footwear_output_acc: 0.5785 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00009: val_loss improved from 7.71208 to 7.68956, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 10/200\n",
            "339/339 [==============================] - 168s 497ms/step - loss: 7.7252 - gender_output_loss: 0.6509 - image_quality_output_loss: 0.9862 - age_output_loss: 1.4102 - weight_output_loss: 0.9881 - bag_output_loss: 0.9095 - footwear_output_loss: 0.9396 - pose_output_loss: 0.9269 - emotion_output_loss: 0.9137 - gender_output_acc: 0.6159 - image_quality_output_acc: 0.5501 - age_output_acc: 0.3959 - weight_output_acc: 0.6315 - bag_output_acc: 0.5651 - footwear_output_acc: 0.5624 - pose_output_acc: 0.6156 - emotion_output_acc: 0.7135 - val_loss: 7.7104 - val_gender_output_loss: 0.6454 - val_image_quality_output_loss: 0.9794 - val_age_output_loss: 1.4176 - val_weight_output_loss: 0.9648 - val_bag_output_loss: 0.9162 - val_footwear_output_loss: 0.9490 - val_pose_output_loss: 0.9093 - val_emotion_output_loss: 0.9284 - val_gender_output_acc: 0.6116 - val_image_quality_output_acc: 0.5610 - val_age_output_acc: 0.3929 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5621 - val_footwear_output_acc: 0.5469 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 7.68956\n",
            "Epoch 11/200\n",
            "339/339 [==============================] - 169s 498ms/step - loss: 7.7071 - gender_output_loss: 0.6444 - image_quality_output_loss: 0.9844 - age_output_loss: 1.4094 - weight_output_loss: 0.9901 - bag_output_loss: 0.9076 - footwear_output_loss: 0.9349 - pose_output_loss: 0.9251 - emotion_output_loss: 0.9112 - gender_output_acc: 0.6249 - image_quality_output_acc: 0.5494 - age_output_acc: 0.3996 - weight_output_acc: 0.6318 - bag_output_acc: 0.5658 - footwear_output_acc: 0.5726 - pose_output_acc: 0.6156 - emotion_output_acc: 0.7137 - val_loss: 7.6656 - val_gender_output_loss: 0.6321 - val_image_quality_output_loss: 0.9753 - val_age_output_loss: 1.4140 - val_weight_output_loss: 0.9740 - val_bag_output_loss: 0.9152 - val_footwear_output_loss: 0.9157 - val_pose_output_loss: 0.9105 - val_emotion_output_loss: 0.9289 - val_gender_output_acc: 0.6365 - val_image_quality_output_acc: 0.5614 - val_age_output_acc: 0.3910 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5666 - val_footwear_output_acc: 0.5848 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00011: val_loss improved from 7.68956 to 7.66559, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 12/200\n",
            "339/339 [==============================] - 167s 494ms/step - loss: 7.6802 - gender_output_loss: 0.6382 - image_quality_output_loss: 0.9853 - age_output_loss: 1.4097 - weight_output_loss: 0.9870 - bag_output_loss: 0.9019 - footwear_output_loss: 0.9264 - pose_output_loss: 0.9230 - emotion_output_loss: 0.9086 - gender_output_acc: 0.6318 - image_quality_output_acc: 0.5508 - age_output_acc: 0.3949 - weight_output_acc: 0.6319 - bag_output_acc: 0.5688 - footwear_output_acc: 0.5768 - pose_output_acc: 0.6154 - emotion_output_acc: 0.7135 - val_loss: 7.6330 - val_gender_output_loss: 0.6295 - val_image_quality_output_loss: 0.9743 - val_age_output_loss: 1.4181 - val_weight_output_loss: 0.9762 - val_bag_output_loss: 0.9122 - val_footwear_output_loss: 0.8977 - val_pose_output_loss: 0.9014 - val_emotion_output_loss: 0.9237 - val_gender_output_acc: 0.6414 - val_image_quality_output_acc: 0.5588 - val_age_output_acc: 0.3899 - val_weight_output_acc: 0.6484 - val_bag_output_acc: 0.5785 - val_footwear_output_acc: 0.5871 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00012: val_loss improved from 7.66559 to 7.63300, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 13/200\n",
            "339/339 [==============================] - 168s 494ms/step - loss: 7.6484 - gender_output_loss: 0.6310 - image_quality_output_loss: 0.9832 - age_output_loss: 1.4080 - weight_output_loss: 0.9837 - bag_output_loss: 0.8981 - footwear_output_loss: 0.9205 - pose_output_loss: 0.9177 - emotion_output_loss: 0.9063 - gender_output_acc: 0.6471 - image_quality_output_acc: 0.5495 - age_output_acc: 0.3970 - weight_output_acc: 0.6321 - bag_output_acc: 0.5694 - footwear_output_acc: 0.5762 - pose_output_acc: 0.6157 - emotion_output_acc: 0.7135 - val_loss: 7.6259 - val_gender_output_loss: 0.6288 - val_image_quality_output_loss: 0.9709 - val_age_output_loss: 1.4177 - val_weight_output_loss: 0.9705 - val_bag_output_loss: 0.9074 - val_footwear_output_loss: 0.9017 - val_pose_output_loss: 0.9039 - val_emotion_output_loss: 0.9250 - val_gender_output_acc: 0.6436 - val_image_quality_output_acc: 0.5610 - val_age_output_acc: 0.3873 - val_weight_output_acc: 0.6484 - val_bag_output_acc: 0.5718 - val_footwear_output_acc: 0.5889 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00013: val_loss improved from 7.63300 to 7.62593, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 14/200\n",
            "339/339 [==============================] - 167s 493ms/step - loss: 7.6288 - gender_output_loss: 0.6209 - image_quality_output_loss: 0.9831 - age_output_loss: 1.4070 - weight_output_loss: 0.9841 - bag_output_loss: 0.8964 - footwear_output_loss: 0.9172 - pose_output_loss: 0.9143 - emotion_output_loss: 0.9058 - gender_output_acc: 0.6468 - image_quality_output_acc: 0.5504 - age_output_acc: 0.3948 - weight_output_acc: 0.6316 - bag_output_acc: 0.5723 - footwear_output_acc: 0.5805 - pose_output_acc: 0.6159 - emotion_output_acc: 0.7138 - val_loss: 7.5462 - val_gender_output_loss: 0.6085 - val_image_quality_output_loss: 0.9708 - val_age_output_loss: 1.4057 - val_weight_output_loss: 0.9579 - val_bag_output_loss: 0.8949 - val_footwear_output_loss: 0.8900 - val_pose_output_loss: 0.8944 - val_emotion_output_loss: 0.9240 - val_gender_output_acc: 0.6629 - val_image_quality_output_acc: 0.5584 - val_age_output_acc: 0.3962 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5889 - val_footwear_output_acc: 0.5882 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00014: val_loss improved from 7.62593 to 7.54617, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 15/200\n",
            "339/339 [==============================] - 168s 496ms/step - loss: 7.5980 - gender_output_loss: 0.6141 - image_quality_output_loss: 0.9818 - age_output_loss: 1.4041 - weight_output_loss: 0.9832 - bag_output_loss: 0.8915 - footwear_output_loss: 0.9117 - pose_output_loss: 0.9090 - emotion_output_loss: 0.9026 - gender_output_acc: 0.6611 - image_quality_output_acc: 0.5503 - age_output_acc: 0.3944 - weight_output_acc: 0.6311 - bag_output_acc: 0.5809 - footwear_output_acc: 0.5845 - pose_output_acc: 0.6161 - emotion_output_acc: 0.7136 - val_loss: 7.6589 - val_gender_output_loss: 0.6250 - val_image_quality_output_loss: 0.9757 - val_age_output_loss: 1.4240 - val_weight_output_loss: 0.9815 - val_bag_output_loss: 0.9063 - val_footwear_output_loss: 0.9211 - val_pose_output_loss: 0.8999 - val_emotion_output_loss: 0.9254 - val_gender_output_acc: 0.6455 - val_image_quality_output_acc: 0.5618 - val_age_output_acc: 0.3962 - val_weight_output_acc: 0.6488 - val_bag_output_acc: 0.5807 - val_footwear_output_acc: 0.5833 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 7.54617\n",
            "Epoch 16/200\n",
            "339/339 [==============================] - 170s 501ms/step - loss: 7.5730 - gender_output_loss: 0.6097 - image_quality_output_loss: 0.9807 - age_output_loss: 1.4016 - weight_output_loss: 0.9810 - bag_output_loss: 0.8873 - footwear_output_loss: 0.9064 - pose_output_loss: 0.9042 - emotion_output_loss: 0.9021 - gender_output_acc: 0.6681 - image_quality_output_acc: 0.5508 - age_output_acc: 0.3961 - weight_output_acc: 0.6319 - bag_output_acc: 0.5806 - footwear_output_acc: 0.5866 - pose_output_acc: 0.6158 - emotion_output_acc: 0.7137 - val_loss: 7.5205 - val_gender_output_loss: 0.5981 - val_image_quality_output_loss: 0.9748 - val_age_output_loss: 1.4061 - val_weight_output_loss: 0.9587 - val_bag_output_loss: 0.9012 - val_footwear_output_loss: 0.8843 - val_pose_output_loss: 0.8722 - val_emotion_output_loss: 0.9253 - val_gender_output_acc: 0.6745 - val_image_quality_output_acc: 0.5610 - val_age_output_acc: 0.3981 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5718 - val_footwear_output_acc: 0.5904 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00016: val_loss improved from 7.54617 to 7.52047, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 17/200\n",
            "339/339 [==============================] - 169s 498ms/step - loss: 7.5575 - gender_output_loss: 0.6048 - image_quality_output_loss: 0.9788 - age_output_loss: 1.4031 - weight_output_loss: 0.9810 - bag_output_loss: 0.8867 - footwear_output_loss: 0.9064 - pose_output_loss: 0.8954 - emotion_output_loss: 0.9012 - gender_output_acc: 0.6651 - image_quality_output_acc: 0.5508 - age_output_acc: 0.3952 - weight_output_acc: 0.6316 - bag_output_acc: 0.5808 - footwear_output_acc: 0.5875 - pose_output_acc: 0.6162 - emotion_output_acc: 0.7137 - val_loss: 7.5523 - val_gender_output_loss: 0.6057 - val_image_quality_output_loss: 0.9711 - val_age_output_loss: 1.4218 - val_weight_output_loss: 0.9610 - val_bag_output_loss: 0.8957 - val_footwear_output_loss: 0.9009 - val_pose_output_loss: 0.8747 - val_emotion_output_loss: 0.9213 - val_gender_output_acc: 0.6726 - val_image_quality_output_acc: 0.5614 - val_age_output_acc: 0.3891 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5770 - val_footwear_output_acc: 0.5878 - val_pose_output_acc: 0.6246 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 7.52047\n",
            "Epoch 18/200\n",
            "339/339 [==============================] - 170s 501ms/step - loss: 7.4958 - gender_output_loss: 0.5934 - image_quality_output_loss: 0.9785 - age_output_loss: 1.3974 - weight_output_loss: 0.9763 - bag_output_loss: 0.8825 - footwear_output_loss: 0.8964 - pose_output_loss: 0.8733 - emotion_output_loss: 0.8979 - gender_output_acc: 0.6760 - image_quality_output_acc: 0.5502 - age_output_acc: 0.3998 - weight_output_acc: 0.6319 - bag_output_acc: 0.5799 - footwear_output_acc: 0.5930 - pose_output_acc: 0.6191 - emotion_output_acc: 0.7136 - val_loss: 7.4713 - val_gender_output_loss: 0.5844 - val_image_quality_output_loss: 0.9744 - val_age_output_loss: 1.4184 - val_weight_output_loss: 0.9647 - val_bag_output_loss: 0.8999 - val_footwear_output_loss: 0.8782 - val_pose_output_loss: 0.8346 - val_emotion_output_loss: 0.9168 - val_gender_output_acc: 0.6882 - val_image_quality_output_acc: 0.5629 - val_age_output_acc: 0.3984 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.5848 - val_footwear_output_acc: 0.5941 - val_pose_output_acc: 0.6365 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00018: val_loss improved from 7.52047 to 7.47135, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 19/200\n",
            "339/339 [==============================] - 169s 498ms/step - loss: 7.4730 - gender_output_loss: 0.5898 - image_quality_output_loss: 0.9798 - age_output_loss: 1.3978 - weight_output_loss: 0.9778 - bag_output_loss: 0.8792 - footwear_output_loss: 0.8927 - pose_output_loss: 0.8614 - emotion_output_loss: 0.8945 - gender_output_acc: 0.6760 - image_quality_output_acc: 0.5508 - age_output_acc: 0.4020 - weight_output_acc: 0.6324 - bag_output_acc: 0.5934 - footwear_output_acc: 0.5963 - pose_output_acc: 0.6261 - emotion_output_acc: 0.7137 - val_loss: 7.4191 - val_gender_output_loss: 0.5798 - val_image_quality_output_loss: 0.9691 - val_age_output_loss: 1.4010 - val_weight_output_loss: 0.9548 - val_bag_output_loss: 0.8886 - val_footwear_output_loss: 0.8849 - val_pose_output_loss: 0.8220 - val_emotion_output_loss: 0.9189 - val_gender_output_acc: 0.6905 - val_image_quality_output_acc: 0.5588 - val_age_output_acc: 0.3899 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5833 - val_footwear_output_acc: 0.5882 - val_pose_output_acc: 0.6432 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00019: val_loss improved from 7.47135 to 7.41914, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 20/200\n",
            "339/339 [==============================] - 169s 498ms/step - loss: 7.4367 - gender_output_loss: 0.5785 - image_quality_output_loss: 0.9759 - age_output_loss: 1.3970 - weight_output_loss: 0.9754 - bag_output_loss: 0.8772 - footwear_output_loss: 0.8912 - pose_output_loss: 0.8464 - emotion_output_loss: 0.8951 - gender_output_acc: 0.6907 - image_quality_output_acc: 0.5501 - age_output_acc: 0.3976 - weight_output_acc: 0.6315 - bag_output_acc: 0.5886 - footwear_output_acc: 0.5951 - pose_output_acc: 0.6298 - emotion_output_acc: 0.7136 - val_loss: 7.4419 - val_gender_output_loss: 0.5766 - val_image_quality_output_loss: 0.9691 - val_age_output_loss: 1.4047 - val_weight_output_loss: 0.9592 - val_bag_output_loss: 0.8933 - val_footwear_output_loss: 0.8953 - val_pose_output_loss: 0.8229 - val_emotion_output_loss: 0.9209 - val_gender_output_acc: 0.6894 - val_image_quality_output_acc: 0.5603 - val_age_output_acc: 0.3992 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5833 - val_footwear_output_acc: 0.5923 - val_pose_output_acc: 0.6536 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 7.41914\n",
            "Epoch 21/200\n",
            "339/339 [==============================] - 170s 500ms/step - loss: 7.4047 - gender_output_loss: 0.5777 - image_quality_output_loss: 0.9750 - age_output_loss: 1.3967 - weight_output_loss: 0.9739 - bag_output_loss: 0.8766 - footwear_output_loss: 0.8831 - pose_output_loss: 0.8283 - emotion_output_loss: 0.8934 - gender_output_acc: 0.6922 - image_quality_output_acc: 0.5519 - age_output_acc: 0.3978 - weight_output_acc: 0.6329 - bag_output_acc: 0.5932 - footwear_output_acc: 0.6025 - pose_output_acc: 0.6392 - emotion_output_acc: 0.7139 - val_loss: 7.3193 - val_gender_output_loss: 0.5547 - val_image_quality_output_loss: 0.9688 - val_age_output_loss: 1.4062 - val_weight_output_loss: 0.9511 - val_bag_output_loss: 0.8860 - val_footwear_output_loss: 0.8681 - val_pose_output_loss: 0.7717 - val_emotion_output_loss: 0.9128 - val_gender_output_acc: 0.7087 - val_image_quality_output_acc: 0.5632 - val_age_output_acc: 0.4025 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5911 - val_footwear_output_acc: 0.6008 - val_pose_output_acc: 0.6849 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00021: val_loss improved from 7.41914 to 7.31933, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 22/200\n",
            "339/339 [==============================] - 169s 499ms/step - loss: 7.3571 - gender_output_loss: 0.5639 - image_quality_output_loss: 0.9736 - age_output_loss: 1.3932 - weight_output_loss: 0.9719 - bag_output_loss: 0.8722 - footwear_output_loss: 0.8775 - pose_output_loss: 0.8125 - emotion_output_loss: 0.8923 - gender_output_acc: 0.7034 - image_quality_output_acc: 0.5506 - age_output_acc: 0.3990 - weight_output_acc: 0.6329 - bag_output_acc: 0.5917 - footwear_output_acc: 0.6002 - pose_output_acc: 0.6468 - emotion_output_acc: 0.7136 - val_loss: 7.3120 - val_gender_output_loss: 0.5600 - val_image_quality_output_loss: 0.9698 - val_age_output_loss: 1.4017 - val_weight_output_loss: 0.9542 - val_bag_output_loss: 0.8916 - val_footwear_output_loss: 0.8678 - val_pose_output_loss: 0.7579 - val_emotion_output_loss: 0.9091 - val_gender_output_acc: 0.7083 - val_image_quality_output_acc: 0.5610 - val_age_output_acc: 0.3966 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.5863 - val_footwear_output_acc: 0.6045 - val_pose_output_acc: 0.6890 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00022: val_loss improved from 7.31933 to 7.31203, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 23/200\n",
            "339/339 [==============================] - 169s 500ms/step - loss: 7.3063 - gender_output_loss: 0.5515 - image_quality_output_loss: 0.9726 - age_output_loss: 1.3891 - weight_output_loss: 0.9704 - bag_output_loss: 0.8709 - footwear_output_loss: 0.8733 - pose_output_loss: 0.7914 - emotion_output_loss: 0.8870 - gender_output_acc: 0.7181 - image_quality_output_acc: 0.5514 - age_output_acc: 0.3981 - weight_output_acc: 0.6322 - bag_output_acc: 0.5918 - footwear_output_acc: 0.6087 - pose_output_acc: 0.6549 - emotion_output_acc: 0.7136 - val_loss: 7.2794 - val_gender_output_loss: 0.5482 - val_image_quality_output_loss: 0.9703 - val_age_output_loss: 1.3984 - val_weight_output_loss: 0.9569 - val_bag_output_loss: 0.8884 - val_footwear_output_loss: 0.8661 - val_pose_output_loss: 0.7430 - val_emotion_output_loss: 0.9081 - val_gender_output_acc: 0.7180 - val_image_quality_output_acc: 0.5569 - val_age_output_acc: 0.4018 - val_weight_output_acc: 0.6469 - val_bag_output_acc: 0.6023 - val_footwear_output_acc: 0.6120 - val_pose_output_acc: 0.6868 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00023: val_loss improved from 7.31203 to 7.27938, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 24/200\n",
            "339/339 [==============================] - 169s 498ms/step - loss: 7.2738 - gender_output_loss: 0.5453 - image_quality_output_loss: 0.9705 - age_output_loss: 1.3877 - weight_output_loss: 0.9705 - bag_output_loss: 0.8701 - footwear_output_loss: 0.8684 - pose_output_loss: 0.7781 - emotion_output_loss: 0.8832 - gender_output_acc: 0.7169 - image_quality_output_acc: 0.5521 - age_output_acc: 0.3984 - weight_output_acc: 0.6327 - bag_output_acc: 0.6005 - footwear_output_acc: 0.6065 - pose_output_acc: 0.6653 - emotion_output_acc: 0.7138 - val_loss: 7.1970 - val_gender_output_loss: 0.5375 - val_image_quality_output_loss: 0.9608 - val_age_output_loss: 1.3981 - val_weight_output_loss: 0.9458 - val_bag_output_loss: 0.8784 - val_footwear_output_loss: 0.8618 - val_pose_output_loss: 0.7125 - val_emotion_output_loss: 0.9021 - val_gender_output_acc: 0.7191 - val_image_quality_output_acc: 0.5632 - val_age_output_acc: 0.3895 - val_weight_output_acc: 0.6499 - val_bag_output_acc: 0.5990 - val_footwear_output_acc: 0.6004 - val_pose_output_acc: 0.7068 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00024: val_loss improved from 7.27938 to 7.19699, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 25/200\n",
            "339/339 [==============================] - 169s 498ms/step - loss: 7.2143 - gender_output_loss: 0.5309 - image_quality_output_loss: 0.9684 - age_output_loss: 1.3845 - weight_output_loss: 0.9669 - bag_output_loss: 0.8649 - footwear_output_loss: 0.8630 - pose_output_loss: 0.7536 - emotion_output_loss: 0.8823 - gender_output_acc: 0.7246 - image_quality_output_acc: 0.5524 - age_output_acc: 0.4002 - weight_output_acc: 0.6313 - bag_output_acc: 0.6003 - footwear_output_acc: 0.6054 - pose_output_acc: 0.6759 - emotion_output_acc: 0.7137 - val_loss: 7.1857 - val_gender_output_loss: 0.5180 - val_image_quality_output_loss: 0.9610 - val_age_output_loss: 1.3964 - val_weight_output_loss: 0.9491 - val_bag_output_loss: 0.8768 - val_footwear_output_loss: 0.8593 - val_pose_output_loss: 0.7183 - val_emotion_output_loss: 0.9068 - val_gender_output_acc: 0.7333 - val_image_quality_output_acc: 0.5599 - val_age_output_acc: 0.4018 - val_weight_output_acc: 0.6507 - val_bag_output_acc: 0.6008 - val_footwear_output_acc: 0.6038 - val_pose_output_acc: 0.7035 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00025: val_loss improved from 7.19699 to 7.18565, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 26/200\n",
            "339/339 [==============================] - 169s 499ms/step - loss: 7.1628 - gender_output_loss: 0.5198 - image_quality_output_loss: 0.9647 - age_output_loss: 1.3809 - weight_output_loss: 0.9632 - bag_output_loss: 0.8590 - footwear_output_loss: 0.8479 - pose_output_loss: 0.7492 - emotion_output_loss: 0.8781 - gender_output_acc: 0.7386 - image_quality_output_acc: 0.5546 - age_output_acc: 0.4013 - weight_output_acc: 0.6314 - bag_output_acc: 0.6051 - footwear_output_acc: 0.6158 - pose_output_acc: 0.6774 - emotion_output_acc: 0.7139 - val_loss: 7.1355 - val_gender_output_loss: 0.5143 - val_image_quality_output_loss: 0.9583 - val_age_output_loss: 1.3969 - val_weight_output_loss: 0.9463 - val_bag_output_loss: 0.8728 - val_footwear_output_loss: 0.8550 - val_pose_output_loss: 0.6892 - val_emotion_output_loss: 0.9028 - val_gender_output_acc: 0.7411 - val_image_quality_output_acc: 0.5621 - val_age_output_acc: 0.4014 - val_weight_output_acc: 0.6510 - val_bag_output_acc: 0.5997 - val_footwear_output_acc: 0.6045 - val_pose_output_acc: 0.7139 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00026: val_loss improved from 7.18565 to 7.13554, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 27/200\n",
            "339/339 [==============================] - 168s 497ms/step - loss: 7.1466 - gender_output_loss: 0.5162 - image_quality_output_loss: 0.9638 - age_output_loss: 1.3809 - weight_output_loss: 0.9635 - bag_output_loss: 0.8574 - footwear_output_loss: 0.8520 - pose_output_loss: 0.7352 - emotion_output_loss: 0.8777 - gender_output_acc: 0.7386 - image_quality_output_acc: 0.5539 - age_output_acc: 0.4064 - weight_output_acc: 0.6338 - bag_output_acc: 0.6043 - footwear_output_acc: 0.6128 - pose_output_acc: 0.6873 - emotion_output_acc: 0.7138 - val_loss: 7.1349 - val_gender_output_loss: 0.5136 - val_image_quality_output_loss: 0.9568 - val_age_output_loss: 1.3947 - val_weight_output_loss: 0.9469 - val_bag_output_loss: 0.8765 - val_footwear_output_loss: 0.8507 - val_pose_output_loss: 0.6924 - val_emotion_output_loss: 0.9033 - val_gender_output_acc: 0.7418 - val_image_quality_output_acc: 0.5625 - val_age_output_acc: 0.4003 - val_weight_output_acc: 0.6477 - val_bag_output_acc: 0.5971 - val_footwear_output_acc: 0.6120 - val_pose_output_acc: 0.7128 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00027: val_loss improved from 7.13554 to 7.13488, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 28/200\n",
            "339/339 [==============================] - 169s 499ms/step - loss: 7.1411 - gender_output_loss: 0.5177 - image_quality_output_loss: 0.9634 - age_output_loss: 1.3800 - weight_output_loss: 0.9633 - bag_output_loss: 0.8591 - footwear_output_loss: 0.8425 - pose_output_loss: 0.7358 - emotion_output_loss: 0.8794 - gender_output_acc: 0.7404 - image_quality_output_acc: 0.5537 - age_output_acc: 0.4039 - weight_output_acc: 0.6331 - bag_output_acc: 0.6071 - footwear_output_acc: 0.6162 - pose_output_acc: 0.6834 - emotion_output_acc: 0.7135 - val_loss: 7.1202 - val_gender_output_loss: 0.5062 - val_image_quality_output_loss: 0.9570 - val_age_output_loss: 1.3942 - val_weight_output_loss: 0.9470 - val_bag_output_loss: 0.8750 - val_footwear_output_loss: 0.8495 - val_pose_output_loss: 0.6885 - val_emotion_output_loss: 0.9029 - val_gender_output_acc: 0.7459 - val_image_quality_output_acc: 0.5592 - val_age_output_acc: 0.4022 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.6001 - val_footwear_output_acc: 0.6086 - val_pose_output_acc: 0.7106 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00028: val_loss improved from 7.13488 to 7.12023, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 29/200\n",
            "339/339 [==============================] - 169s 498ms/step - loss: 7.1371 - gender_output_loss: 0.5161 - image_quality_output_loss: 0.9615 - age_output_loss: 1.3822 - weight_output_loss: 0.9646 - bag_output_loss: 0.8562 - footwear_output_loss: 0.8447 - pose_output_loss: 0.7351 - emotion_output_loss: 0.8767 - gender_output_acc: 0.7373 - image_quality_output_acc: 0.5540 - age_output_acc: 0.4004 - weight_output_acc: 0.6333 - bag_output_acc: 0.6100 - footwear_output_acc: 0.6161 - pose_output_acc: 0.6871 - emotion_output_acc: 0.7138 - val_loss: 7.1252 - val_gender_output_loss: 0.5121 - val_image_quality_output_loss: 0.9550 - val_age_output_loss: 1.3948 - val_weight_output_loss: 0.9469 - val_bag_output_loss: 0.8752 - val_footwear_output_loss: 0.8510 - val_pose_output_loss: 0.6882 - val_emotion_output_loss: 0.9020 - val_gender_output_acc: 0.7429 - val_image_quality_output_acc: 0.5629 - val_age_output_acc: 0.3958 - val_weight_output_acc: 0.6499 - val_bag_output_acc: 0.6004 - val_footwear_output_acc: 0.6053 - val_pose_output_acc: 0.7143 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 7.12023\n",
            "Epoch 30/200\n",
            "339/339 [==============================] - 172s 509ms/step - loss: 7.1237 - gender_output_loss: 0.5135 - image_quality_output_loss: 0.9620 - age_output_loss: 1.3804 - weight_output_loss: 0.9625 - bag_output_loss: 0.8544 - footwear_output_loss: 0.8428 - pose_output_loss: 0.7322 - emotion_output_loss: 0.8760 - gender_output_acc: 0.7406 - image_quality_output_acc: 0.5548 - age_output_acc: 0.4027 - weight_output_acc: 0.6333 - bag_output_acc: 0.6132 - footwear_output_acc: 0.6162 - pose_output_acc: 0.6843 - emotion_output_acc: 0.7140 - val_loss: 7.1016 - val_gender_output_loss: 0.4994 - val_image_quality_output_loss: 0.9555 - val_age_output_loss: 1.3930 - val_weight_output_loss: 0.9444 - val_bag_output_loss: 0.8711 - val_footwear_output_loss: 0.8491 - val_pose_output_loss: 0.6850 - val_emotion_output_loss: 0.9039 - val_gender_output_acc: 0.7515 - val_image_quality_output_acc: 0.5565 - val_age_output_acc: 0.4018 - val_weight_output_acc: 0.6499 - val_bag_output_acc: 0.5978 - val_footwear_output_acc: 0.6101 - val_pose_output_acc: 0.7135 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00030: val_loss improved from 7.12023 to 7.10156, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 31/200\n",
            "339/339 [==============================] - 171s 505ms/step - loss: 7.1131 - gender_output_loss: 0.5087 - image_quality_output_loss: 0.9610 - age_output_loss: 1.3769 - weight_output_loss: 0.9622 - bag_output_loss: 0.8554 - footwear_output_loss: 0.8414 - pose_output_loss: 0.7323 - emotion_output_loss: 0.8752 - gender_output_acc: 0.7447 - image_quality_output_acc: 0.5568 - age_output_acc: 0.4029 - weight_output_acc: 0.6336 - bag_output_acc: 0.6070 - footwear_output_acc: 0.6195 - pose_output_acc: 0.6878 - emotion_output_acc: 0.7137 - val_loss: 7.1098 - val_gender_output_loss: 0.5044 - val_image_quality_output_loss: 0.9545 - val_age_output_loss: 1.3933 - val_weight_output_loss: 0.9465 - val_bag_output_loss: 0.8748 - val_footwear_output_loss: 0.8473 - val_pose_output_loss: 0.6862 - val_emotion_output_loss: 0.9028 - val_gender_output_acc: 0.7511 - val_image_quality_output_acc: 0.5618 - val_age_output_acc: 0.3966 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.5986 - val_footwear_output_acc: 0.6090 - val_pose_output_acc: 0.7135 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 7.10156\n",
            "Epoch 32/200\n",
            "339/339 [==============================] - 171s 505ms/step - loss: 7.1122 - gender_output_loss: 0.5085 - image_quality_output_loss: 0.9608 - age_output_loss: 1.3788 - weight_output_loss: 0.9633 - bag_output_loss: 0.8598 - footwear_output_loss: 0.8435 - pose_output_loss: 0.7256 - emotion_output_loss: 0.8717 - gender_output_acc: 0.7479 - image_quality_output_acc: 0.5535 - age_output_acc: 0.3982 - weight_output_acc: 0.6332 - bag_output_acc: 0.6036 - footwear_output_acc: 0.6169 - pose_output_acc: 0.6913 - emotion_output_acc: 0.7136 - val_loss: 7.1093 - val_gender_output_loss: 0.5075 - val_image_quality_output_loss: 0.9541 - val_age_output_loss: 1.3927 - val_weight_output_loss: 0.9475 - val_bag_output_loss: 0.8760 - val_footwear_output_loss: 0.8484 - val_pose_output_loss: 0.6811 - val_emotion_output_loss: 0.9019 - val_gender_output_acc: 0.7504 - val_image_quality_output_acc: 0.5625 - val_age_output_acc: 0.3958 - val_weight_output_acc: 0.6477 - val_bag_output_acc: 0.5949 - val_footwear_output_acc: 0.6109 - val_pose_output_acc: 0.7169 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 7.10156\n",
            "Epoch 33/200\n",
            "339/339 [==============================] - 171s 506ms/step - loss: 7.1111 - gender_output_loss: 0.5116 - image_quality_output_loss: 0.9624 - age_output_loss: 1.3785 - weight_output_loss: 0.9596 - bag_output_loss: 0.8532 - footwear_output_loss: 0.8415 - pose_output_loss: 0.7267 - emotion_output_loss: 0.8777 - gender_output_acc: 0.7477 - image_quality_output_acc: 0.5533 - age_output_acc: 0.4029 - weight_output_acc: 0.6315 - bag_output_acc: 0.6095 - footwear_output_acc: 0.6157 - pose_output_acc: 0.6885 - emotion_output_acc: 0.7138 - val_loss: 7.0893 - val_gender_output_loss: 0.4996 - val_image_quality_output_loss: 0.9538 - val_age_output_loss: 1.3922 - val_weight_output_loss: 0.9447 - val_bag_output_loss: 0.8732 - val_footwear_output_loss: 0.8466 - val_pose_output_loss: 0.6775 - val_emotion_output_loss: 0.9017 - val_gender_output_acc: 0.7541 - val_image_quality_output_acc: 0.5603 - val_age_output_acc: 0.3999 - val_weight_output_acc: 0.6499 - val_bag_output_acc: 0.5978 - val_footwear_output_acc: 0.6131 - val_pose_output_acc: 0.7176 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00033: val_loss improved from 7.10156 to 7.08932, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 34/200\n",
            "339/339 [==============================] - 170s 501ms/step - loss: 7.0926 - gender_output_loss: 0.5045 - image_quality_output_loss: 0.9597 - age_output_loss: 1.3760 - weight_output_loss: 0.9614 - bag_output_loss: 0.8533 - footwear_output_loss: 0.8404 - pose_output_loss: 0.7206 - emotion_output_loss: 0.8766 - gender_output_acc: 0.7474 - image_quality_output_acc: 0.5541 - age_output_acc: 0.4012 - weight_output_acc: 0.6327 - bag_output_acc: 0.6114 - footwear_output_acc: 0.6183 - pose_output_acc: 0.6931 - emotion_output_acc: 0.7137 - val_loss: 7.0966 - val_gender_output_loss: 0.5039 - val_image_quality_output_loss: 0.9531 - val_age_output_loss: 1.3915 - val_weight_output_loss: 0.9451 - val_bag_output_loss: 0.8740 - val_footwear_output_loss: 0.8471 - val_pose_output_loss: 0.6804 - val_emotion_output_loss: 0.9015 - val_gender_output_acc: 0.7500 - val_image_quality_output_acc: 0.5629 - val_age_output_acc: 0.3969 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5964 - val_footwear_output_acc: 0.6105 - val_pose_output_acc: 0.7147 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 7.08932\n",
            "Epoch 35/200\n",
            "339/339 [==============================] - 172s 507ms/step - loss: 7.1015 - gender_output_loss: 0.5084 - image_quality_output_loss: 0.9600 - age_output_loss: 1.3782 - weight_output_loss: 0.9636 - bag_output_loss: 0.8540 - footwear_output_loss: 0.8404 - pose_output_loss: 0.7229 - emotion_output_loss: 0.8740 - gender_output_acc: 0.7457 - image_quality_output_acc: 0.5542 - age_output_acc: 0.4002 - weight_output_acc: 0.6314 - bag_output_acc: 0.6057 - footwear_output_acc: 0.6209 - pose_output_acc: 0.6883 - emotion_output_acc: 0.7138 - val_loss: 7.0936 - val_gender_output_loss: 0.5017 - val_image_quality_output_loss: 0.9536 - val_age_output_loss: 1.3922 - val_weight_output_loss: 0.9454 - val_bag_output_loss: 0.8728 - val_footwear_output_loss: 0.8477 - val_pose_output_loss: 0.6788 - val_emotion_output_loss: 0.9013 - val_gender_output_acc: 0.7474 - val_image_quality_output_acc: 0.5606 - val_age_output_acc: 0.3981 - val_weight_output_acc: 0.6488 - val_bag_output_acc: 0.5975 - val_footwear_output_acc: 0.6090 - val_pose_output_acc: 0.7154 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 7.08932\n",
            "Epoch 36/200\n",
            "339/339 [==============================] - 171s 504ms/step - loss: 7.1039 - gender_output_loss: 0.5085 - image_quality_output_loss: 0.9608 - age_output_loss: 1.3793 - weight_output_loss: 0.9612 - bag_output_loss: 0.8546 - footwear_output_loss: 0.8403 - pose_output_loss: 0.7233 - emotion_output_loss: 0.8759 - gender_output_acc: 0.7457 - image_quality_output_acc: 0.5529 - age_output_acc: 0.4011 - weight_output_acc: 0.6336 - bag_output_acc: 0.6126 - footwear_output_acc: 0.6232 - pose_output_acc: 0.6883 - emotion_output_acc: 0.7136 - val_loss: 7.0905 - val_gender_output_loss: 0.5011 - val_image_quality_output_loss: 0.9532 - val_age_output_loss: 1.3923 - val_weight_output_loss: 0.9450 - val_bag_output_loss: 0.8726 - val_footwear_output_loss: 0.8473 - val_pose_output_loss: 0.6780 - val_emotion_output_loss: 0.9010 - val_gender_output_acc: 0.7515 - val_image_quality_output_acc: 0.5603 - val_age_output_acc: 0.3984 - val_weight_output_acc: 0.6484 - val_bag_output_acc: 0.5986 - val_footwear_output_acc: 0.6109 - val_pose_output_acc: 0.7169 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 7.08932\n",
            "Epoch 37/200\n",
            "339/339 [==============================] - 171s 504ms/step - loss: 7.0944 - gender_output_loss: 0.5072 - image_quality_output_loss: 0.9624 - age_output_loss: 1.3767 - weight_output_loss: 0.9626 - bag_output_loss: 0.8549 - footwear_output_loss: 0.8369 - pose_output_loss: 0.7186 - emotion_output_loss: 0.8752 - gender_output_acc: 0.7481 - image_quality_output_acc: 0.5553 - age_output_acc: 0.4030 - weight_output_acc: 0.6333 - bag_output_acc: 0.6075 - footwear_output_acc: 0.6232 - pose_output_acc: 0.6915 - emotion_output_acc: 0.7135 - val_loss: 7.0862 - val_gender_output_loss: 0.5000 - val_image_quality_output_loss: 0.9529 - val_age_output_loss: 1.3920 - val_weight_output_loss: 0.9450 - val_bag_output_loss: 0.8729 - val_footwear_output_loss: 0.8458 - val_pose_output_loss: 0.6769 - val_emotion_output_loss: 0.9007 - val_gender_output_acc: 0.7511 - val_image_quality_output_acc: 0.5606 - val_age_output_acc: 0.3988 - val_weight_output_acc: 0.6484 - val_bag_output_acc: 0.5978 - val_footwear_output_acc: 0.6109 - val_pose_output_acc: 0.7161 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00037: val_loss improved from 7.08932 to 7.08625, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 38/200\n",
            "339/339 [==============================] - 170s 501ms/step - loss: 7.0873 - gender_output_loss: 0.5018 - image_quality_output_loss: 0.9603 - age_output_loss: 1.3775 - weight_output_loss: 0.9613 - bag_output_loss: 0.8530 - footwear_output_loss: 0.8419 - pose_output_loss: 0.7169 - emotion_output_loss: 0.8745 - gender_output_acc: 0.7498 - image_quality_output_acc: 0.5520 - age_output_acc: 0.4037 - weight_output_acc: 0.6317 - bag_output_acc: 0.6097 - footwear_output_acc: 0.6182 - pose_output_acc: 0.6893 - emotion_output_acc: 0.7135 - val_loss: 7.0858 - val_gender_output_loss: 0.5001 - val_image_quality_output_loss: 0.9527 - val_age_output_loss: 1.3921 - val_weight_output_loss: 0.9446 - val_bag_output_loss: 0.8727 - val_footwear_output_loss: 0.8453 - val_pose_output_loss: 0.6774 - val_emotion_output_loss: 0.9009 - val_gender_output_acc: 0.7541 - val_image_quality_output_acc: 0.5599 - val_age_output_acc: 0.4007 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.5986 - val_footwear_output_acc: 0.6120 - val_pose_output_acc: 0.7173 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00038: val_loss improved from 7.08625 to 7.08580, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 39/200\n",
            "339/339 [==============================] - 170s 502ms/step - loss: 7.0889 - gender_output_loss: 0.5051 - image_quality_output_loss: 0.9606 - age_output_loss: 1.3804 - weight_output_loss: 0.9601 - bag_output_loss: 0.8541 - footwear_output_loss: 0.8371 - pose_output_loss: 0.7166 - emotion_output_loss: 0.8749 - gender_output_acc: 0.7490 - image_quality_output_acc: 0.5554 - age_output_acc: 0.4009 - weight_output_acc: 0.6338 - bag_output_acc: 0.6077 - footwear_output_acc: 0.6184 - pose_output_acc: 0.6902 - emotion_output_acc: 0.7137 - val_loss: 7.0887 - val_gender_output_loss: 0.5007 - val_image_quality_output_loss: 0.9531 - val_age_output_loss: 1.3923 - val_weight_output_loss: 0.9452 - val_bag_output_loss: 0.8736 - val_footwear_output_loss: 0.8458 - val_pose_output_loss: 0.6772 - val_emotion_output_loss: 0.9008 - val_gender_output_acc: 0.7478 - val_image_quality_output_acc: 0.5610 - val_age_output_acc: 0.3988 - val_weight_output_acc: 0.6484 - val_bag_output_acc: 0.5993 - val_footwear_output_acc: 0.6112 - val_pose_output_acc: 0.7176 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 7.08580\n",
            "Epoch 40/200\n",
            "339/339 [==============================] - 172s 507ms/step - loss: 7.0979 - gender_output_loss: 0.5044 - image_quality_output_loss: 0.9605 - age_output_loss: 1.3791 - weight_output_loss: 0.9634 - bag_output_loss: 0.8523 - footwear_output_loss: 0.8424 - pose_output_loss: 0.7205 - emotion_output_loss: 0.8756 - gender_output_acc: 0.7444 - image_quality_output_acc: 0.5529 - age_output_acc: 0.4051 - weight_output_acc: 0.6329 - bag_output_acc: 0.6090 - footwear_output_acc: 0.6149 - pose_output_acc: 0.6916 - emotion_output_acc: 0.7138 - val_loss: 7.0824 - val_gender_output_loss: 0.4994 - val_image_quality_output_loss: 0.9528 - val_age_output_loss: 1.3918 - val_weight_output_loss: 0.9446 - val_bag_output_loss: 0.8731 - val_footwear_output_loss: 0.8450 - val_pose_output_loss: 0.6752 - val_emotion_output_loss: 0.9005 - val_gender_output_acc: 0.7530 - val_image_quality_output_acc: 0.5592 - val_age_output_acc: 0.3992 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5960 - val_footwear_output_acc: 0.6112 - val_pose_output_acc: 0.7217 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00040: val_loss improved from 7.08580 to 7.08237, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 41/200\n",
            "339/339 [==============================] - 174s 513ms/step - loss: 7.0939 - gender_output_loss: 0.5072 - image_quality_output_loss: 0.9601 - age_output_loss: 1.3782 - weight_output_loss: 0.9625 - bag_output_loss: 0.8524 - footwear_output_loss: 0.8369 - pose_output_loss: 0.7213 - emotion_output_loss: 0.8753 - gender_output_acc: 0.7429 - image_quality_output_acc: 0.5525 - age_output_acc: 0.4007 - weight_output_acc: 0.6327 - bag_output_acc: 0.6124 - footwear_output_acc: 0.6210 - pose_output_acc: 0.6966 - emotion_output_acc: 0.7134 - val_loss: 7.0855 - val_gender_output_loss: 0.5003 - val_image_quality_output_loss: 0.9530 - val_age_output_loss: 1.3919 - val_weight_output_loss: 0.9448 - val_bag_output_loss: 0.8731 - val_footwear_output_loss: 0.8447 - val_pose_output_loss: 0.6772 - val_emotion_output_loss: 0.9005 - val_gender_output_acc: 0.7474 - val_image_quality_output_acc: 0.5599 - val_age_output_acc: 0.3992 - val_weight_output_acc: 0.6484 - val_bag_output_acc: 0.5975 - val_footwear_output_acc: 0.6135 - val_pose_output_acc: 0.7184 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 7.08237\n",
            "Epoch 42/200\n",
            "339/339 [==============================] - 173s 511ms/step - loss: 7.1004 - gender_output_loss: 0.5030 - image_quality_output_loss: 0.9605 - age_output_loss: 1.3780 - weight_output_loss: 0.9633 - bag_output_loss: 0.8550 - footwear_output_loss: 0.8414 - pose_output_loss: 0.7236 - emotion_output_loss: 0.8755 - gender_output_acc: 0.7498 - image_quality_output_acc: 0.5534 - age_output_acc: 0.4030 - weight_output_acc: 0.6323 - bag_output_acc: 0.6032 - footwear_output_acc: 0.6182 - pose_output_acc: 0.6891 - emotion_output_acc: 0.7143 - val_loss: 7.0824 - val_gender_output_loss: 0.4998 - val_image_quality_output_loss: 0.9526 - val_age_output_loss: 1.3920 - val_weight_output_loss: 0.9454 - val_bag_output_loss: 0.8737 - val_footwear_output_loss: 0.8436 - val_pose_output_loss: 0.6745 - val_emotion_output_loss: 0.9007 - val_gender_output_acc: 0.7556 - val_image_quality_output_acc: 0.5606 - val_age_output_acc: 0.3996 - val_weight_output_acc: 0.6488 - val_bag_output_acc: 0.5986 - val_footwear_output_acc: 0.6112 - val_pose_output_acc: 0.7202 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 7.08237\n",
            "Epoch 43/200\n",
            "339/339 [==============================] - 173s 511ms/step - loss: 7.0889 - gender_output_loss: 0.5028 - image_quality_output_loss: 0.9608 - age_output_loss: 1.3777 - weight_output_loss: 0.9622 - bag_output_loss: 0.8553 - footwear_output_loss: 0.8351 - pose_output_loss: 0.7215 - emotion_output_loss: 0.8736 - gender_output_acc: 0.7504 - image_quality_output_acc: 0.5539 - age_output_acc: 0.4017 - weight_output_acc: 0.6324 - bag_output_acc: 0.6064 - footwear_output_acc: 0.6261 - pose_output_acc: 0.6947 - emotion_output_acc: 0.7138 - val_loss: 7.0776 - val_gender_output_loss: 0.4982 - val_image_quality_output_loss: 0.9529 - val_age_output_loss: 1.3918 - val_weight_output_loss: 0.9449 - val_bag_output_loss: 0.8725 - val_footwear_output_loss: 0.8447 - val_pose_output_loss: 0.6722 - val_emotion_output_loss: 0.9004 - val_gender_output_acc: 0.7515 - val_image_quality_output_acc: 0.5603 - val_age_output_acc: 0.3996 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.6053 - val_footwear_output_acc: 0.6116 - val_pose_output_acc: 0.7202 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00043: val_loss improved from 7.08237 to 7.07764, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 44/200\n",
            "339/339 [==============================] - 172s 507ms/step - loss: 7.0909 - gender_output_loss: 0.5042 - image_quality_output_loss: 0.9621 - age_output_loss: 1.3776 - weight_output_loss: 0.9616 - bag_output_loss: 0.8545 - footwear_output_loss: 0.8346 - pose_output_loss: 0.7191 - emotion_output_loss: 0.8771 - gender_output_acc: 0.7482 - image_quality_output_acc: 0.5531 - age_output_acc: 0.4027 - weight_output_acc: 0.6328 - bag_output_acc: 0.6045 - footwear_output_acc: 0.6244 - pose_output_acc: 0.6966 - emotion_output_acc: 0.7137 - val_loss: 7.0795 - val_gender_output_loss: 0.5000 - val_image_quality_output_loss: 0.9520 - val_age_output_loss: 1.3918 - val_weight_output_loss: 0.9449 - val_bag_output_loss: 0.8712 - val_footwear_output_loss: 0.8455 - val_pose_output_loss: 0.6739 - val_emotion_output_loss: 0.9001 - val_gender_output_acc: 0.7530 - val_image_quality_output_acc: 0.5603 - val_age_output_acc: 0.3996 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.6001 - val_footwear_output_acc: 0.6116 - val_pose_output_acc: 0.7221 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 7.07764\n",
            "Epoch 45/200\n",
            "339/339 [==============================] - 173s 510ms/step - loss: 7.0951 - gender_output_loss: 0.5095 - image_quality_output_loss: 0.9606 - age_output_loss: 1.3784 - weight_output_loss: 0.9611 - bag_output_loss: 0.8536 - footwear_output_loss: 0.8370 - pose_output_loss: 0.7206 - emotion_output_loss: 0.8743 - gender_output_acc: 0.7456 - image_quality_output_acc: 0.5524 - age_output_acc: 0.3990 - weight_output_acc: 0.6340 - bag_output_acc: 0.6115 - footwear_output_acc: 0.6202 - pose_output_acc: 0.6909 - emotion_output_acc: 0.7137 - val_loss: 7.0782 - val_gender_output_loss: 0.4983 - val_image_quality_output_loss: 0.9520 - val_age_output_loss: 1.3920 - val_weight_output_loss: 0.9449 - val_bag_output_loss: 0.8734 - val_footwear_output_loss: 0.8424 - val_pose_output_loss: 0.6742 - val_emotion_output_loss: 0.9009 - val_gender_output_acc: 0.7567 - val_image_quality_output_acc: 0.5592 - val_age_output_acc: 0.3984 - val_weight_output_acc: 0.6484 - val_bag_output_acc: 0.5978 - val_footwear_output_acc: 0.6094 - val_pose_output_acc: 0.7232 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 7.07764\n",
            "Epoch 46/200\n",
            "339/339 [==============================] - 174s 512ms/step - loss: 7.0803 - gender_output_loss: 0.5022 - image_quality_output_loss: 0.9581 - age_output_loss: 1.3778 - weight_output_loss: 0.9593 - bag_output_loss: 0.8554 - footwear_output_loss: 0.8396 - pose_output_loss: 0.7123 - emotion_output_loss: 0.8757 - gender_output_acc: 0.7494 - image_quality_output_acc: 0.5540 - age_output_acc: 0.4039 - weight_output_acc: 0.6332 - bag_output_acc: 0.6091 - footwear_output_acc: 0.6198 - pose_output_acc: 0.6962 - emotion_output_acc: 0.7139 - val_loss: 7.0799 - val_gender_output_loss: 0.4988 - val_image_quality_output_loss: 0.9520 - val_age_output_loss: 1.3921 - val_weight_output_loss: 0.9450 - val_bag_output_loss: 0.8713 - val_footwear_output_loss: 0.8471 - val_pose_output_loss: 0.6733 - val_emotion_output_loss: 0.9002 - val_gender_output_acc: 0.7519 - val_image_quality_output_acc: 0.5632 - val_age_output_acc: 0.3958 - val_weight_output_acc: 0.6499 - val_bag_output_acc: 0.6038 - val_footwear_output_acc: 0.6116 - val_pose_output_acc: 0.7232 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 7.07764\n",
            "Epoch 47/200\n",
            "339/339 [==============================] - 173s 511ms/step - loss: 7.0874 - gender_output_loss: 0.5012 - image_quality_output_loss: 0.9596 - age_output_loss: 1.3793 - weight_output_loss: 0.9623 - bag_output_loss: 0.8563 - footwear_output_loss: 0.8359 - pose_output_loss: 0.7166 - emotion_output_loss: 0.8763 - gender_output_acc: 0.7504 - image_quality_output_acc: 0.5517 - age_output_acc: 0.4015 - weight_output_acc: 0.6320 - bag_output_acc: 0.6080 - footwear_output_acc: 0.6239 - pose_output_acc: 0.6962 - emotion_output_acc: 0.7136 - val_loss: 7.0948 - val_gender_output_loss: 0.5078 - val_image_quality_output_loss: 0.9501 - val_age_output_loss: 1.3937 - val_weight_output_loss: 0.9458 - val_bag_output_loss: 0.8742 - val_footwear_output_loss: 0.8491 - val_pose_output_loss: 0.6742 - val_emotion_output_loss: 0.8997 - val_gender_output_acc: 0.7500 - val_image_quality_output_acc: 0.5625 - val_age_output_acc: 0.3917 - val_weight_output_acc: 0.6473 - val_bag_output_acc: 0.6008 - val_footwear_output_acc: 0.6131 - val_pose_output_acc: 0.7176 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 7.07764\n",
            "Epoch 48/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 7.0801 - gender_output_loss: 0.5034 - image_quality_output_loss: 0.9594 - age_output_loss: 1.3766 - weight_output_loss: 0.9613 - bag_output_loss: 0.8534 - footwear_output_loss: 0.8373 - pose_output_loss: 0.7130 - emotion_output_loss: 0.8757 - gender_output_acc: 0.7475 - image_quality_output_acc: 0.5553 - age_output_acc: 0.3996 - weight_output_acc: 0.6331 - bag_output_acc: 0.6072 - footwear_output_acc: 0.6237 - pose_output_acc: 0.6953 - emotion_output_acc: 0.7136 - val_loss: 7.0979 - val_gender_output_loss: 0.5097 - val_image_quality_output_loss: 0.9518 - val_age_output_loss: 1.3926 - val_weight_output_loss: 0.9470 - val_bag_output_loss: 0.8753 - val_footwear_output_loss: 0.8458 - val_pose_output_loss: 0.6761 - val_emotion_output_loss: 0.8997 - val_gender_output_acc: 0.7504 - val_image_quality_output_acc: 0.5621 - val_age_output_acc: 0.3962 - val_weight_output_acc: 0.6469 - val_bag_output_acc: 0.5982 - val_footwear_output_acc: 0.6086 - val_pose_output_acc: 0.7176 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 7.07764\n",
            "Epoch 49/200\n",
            "339/339 [==============================] - 174s 513ms/step - loss: 7.0677 - gender_output_loss: 0.4999 - image_quality_output_loss: 0.9589 - age_output_loss: 1.3767 - weight_output_loss: 0.9580 - bag_output_loss: 0.8547 - footwear_output_loss: 0.8352 - pose_output_loss: 0.7092 - emotion_output_loss: 0.8751 - gender_output_acc: 0.7505 - image_quality_output_acc: 0.5548 - age_output_acc: 0.4066 - weight_output_acc: 0.6318 - bag_output_acc: 0.6077 - footwear_output_acc: 0.6220 - pose_output_acc: 0.6971 - emotion_output_acc: 0.7140 - val_loss: 7.0677 - val_gender_output_loss: 0.4943 - val_image_quality_output_loss: 0.9516 - val_age_output_loss: 1.3915 - val_weight_output_loss: 0.9451 - val_bag_output_loss: 0.8702 - val_footwear_output_loss: 0.8448 - val_pose_output_loss: 0.6714 - val_emotion_output_loss: 0.8987 - val_gender_output_acc: 0.7560 - val_image_quality_output_acc: 0.5599 - val_age_output_acc: 0.3981 - val_weight_output_acc: 0.6484 - val_bag_output_acc: 0.5997 - val_footwear_output_acc: 0.6124 - val_pose_output_acc: 0.7228 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00049: val_loss improved from 7.07764 to 7.06768, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 50/200\n",
            "339/339 [==============================] - 172s 508ms/step - loss: 7.0774 - gender_output_loss: 0.4948 - image_quality_output_loss: 0.9615 - age_output_loss: 1.3770 - weight_output_loss: 0.9623 - bag_output_loss: 0.8534 - footwear_output_loss: 0.8374 - pose_output_loss: 0.7165 - emotion_output_loss: 0.8745 - gender_output_acc: 0.7558 - image_quality_output_acc: 0.5521 - age_output_acc: 0.4016 - weight_output_acc: 0.6330 - bag_output_acc: 0.6105 - footwear_output_acc: 0.6185 - pose_output_acc: 0.6944 - emotion_output_acc: 0.7138 - val_loss: 7.0738 - val_gender_output_loss: 0.4999 - val_image_quality_output_loss: 0.9498 - val_age_output_loss: 1.3933 - val_weight_output_loss: 0.9457 - val_bag_output_loss: 0.8730 - val_footwear_output_loss: 0.8442 - val_pose_output_loss: 0.6700 - val_emotion_output_loss: 0.8978 - val_gender_output_acc: 0.7623 - val_image_quality_output_acc: 0.5636 - val_age_output_acc: 0.3943 - val_weight_output_acc: 0.6477 - val_bag_output_acc: 0.6031 - val_footwear_output_acc: 0.6127 - val_pose_output_acc: 0.7221 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 7.06768\n",
            "Epoch 51/200\n",
            "339/339 [==============================] - 174s 512ms/step - loss: 7.0795 - gender_output_loss: 0.5016 - image_quality_output_loss: 0.9605 - age_output_loss: 1.3775 - weight_output_loss: 0.9633 - bag_output_loss: 0.8542 - footwear_output_loss: 0.8363 - pose_output_loss: 0.7096 - emotion_output_loss: 0.8766 - gender_output_acc: 0.7489 - image_quality_output_acc: 0.5529 - age_output_acc: 0.4023 - weight_output_acc: 0.6331 - bag_output_acc: 0.6086 - footwear_output_acc: 0.6208 - pose_output_acc: 0.6996 - emotion_output_acc: 0.7136 - val_loss: 7.1538 - val_gender_output_loss: 0.5189 - val_image_quality_output_loss: 0.9489 - val_age_output_loss: 1.4039 - val_weight_output_loss: 0.9445 - val_bag_output_loss: 0.8798 - val_footwear_output_loss: 0.8632 - val_pose_output_loss: 0.6913 - val_emotion_output_loss: 0.9033 - val_gender_output_acc: 0.7340 - val_image_quality_output_acc: 0.5599 - val_age_output_acc: 0.3981 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.5971 - val_footwear_output_acc: 0.6071 - val_pose_output_acc: 0.7176 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 7.06768\n",
            "Epoch 52/200\n",
            "339/339 [==============================] - 173s 511ms/step - loss: 7.1576 - gender_output_loss: 0.5234 - image_quality_output_loss: 0.9598 - age_output_loss: 1.3855 - weight_output_loss: 0.9653 - bag_output_loss: 0.8604 - footwear_output_loss: 0.8572 - pose_output_loss: 0.7276 - emotion_output_loss: 0.8784 - gender_output_acc: 0.7353 - image_quality_output_acc: 0.5538 - age_output_acc: 0.4005 - weight_output_acc: 0.6320 - bag_output_acc: 0.6015 - footwear_output_acc: 0.6174 - pose_output_acc: 0.6953 - emotion_output_acc: 0.7140 - val_loss: 7.1604 - val_gender_output_loss: 0.5162 - val_image_quality_output_loss: 0.9557 - val_age_output_loss: 1.3926 - val_weight_output_loss: 0.9457 - val_bag_output_loss: 0.8796 - val_footwear_output_loss: 0.8690 - val_pose_output_loss: 0.6985 - val_emotion_output_loss: 0.9030 - val_gender_output_acc: 0.7362 - val_image_quality_output_acc: 0.5476 - val_age_output_acc: 0.4029 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.5900 - val_footwear_output_acc: 0.5952 - val_pose_output_acc: 0.7124 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 7.06768\n",
            "Epoch 53/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 7.1740 - gender_output_loss: 0.5214 - image_quality_output_loss: 0.9612 - age_output_loss: 1.3829 - weight_output_loss: 0.9685 - bag_output_loss: 0.8635 - footwear_output_loss: 0.8564 - pose_output_loss: 0.7402 - emotion_output_loss: 0.8799 - gender_output_acc: 0.7394 - image_quality_output_acc: 0.5537 - age_output_acc: 0.4016 - weight_output_acc: 0.6323 - bag_output_acc: 0.6034 - footwear_output_acc: 0.6190 - pose_output_acc: 0.6795 - emotion_output_acc: 0.7136 - val_loss: 7.2898 - val_gender_output_loss: 0.5506 - val_image_quality_output_loss: 0.9564 - val_age_output_loss: 1.4189 - val_weight_output_loss: 0.9505 - val_bag_output_loss: 0.8866 - val_footwear_output_loss: 0.8749 - val_pose_output_loss: 0.7367 - val_emotion_output_loss: 0.9152 - val_gender_output_acc: 0.7221 - val_image_quality_output_acc: 0.5569 - val_age_output_acc: 0.3984 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.5807 - val_footwear_output_acc: 0.5949 - val_pose_output_acc: 0.6882 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 7.06768\n",
            "Epoch 54/200\n",
            "339/339 [==============================] - 174s 512ms/step - loss: 7.1651 - gender_output_loss: 0.5167 - image_quality_output_loss: 0.9620 - age_output_loss: 1.3837 - weight_output_loss: 0.9655 - bag_output_loss: 0.8634 - footwear_output_loss: 0.8593 - pose_output_loss: 0.7352 - emotion_output_loss: 0.8795 - gender_output_acc: 0.7436 - image_quality_output_acc: 0.5518 - age_output_acc: 0.4020 - weight_output_acc: 0.6324 - bag_output_acc: 0.5962 - footwear_output_acc: 0.6114 - pose_output_acc: 0.6847 - emotion_output_acc: 0.7136 - val_loss: 7.2498 - val_gender_output_loss: 0.5509 - val_image_quality_output_loss: 0.9527 - val_age_output_loss: 1.4073 - val_weight_output_loss: 0.9623 - val_bag_output_loss: 0.8883 - val_footwear_output_loss: 0.8753 - val_pose_output_loss: 0.7136 - val_emotion_output_loss: 0.8994 - val_gender_output_acc: 0.7121 - val_image_quality_output_acc: 0.5606 - val_age_output_acc: 0.3910 - val_weight_output_acc: 0.6488 - val_bag_output_acc: 0.5930 - val_footwear_output_acc: 0.6004 - val_pose_output_acc: 0.7024 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 7.06768\n",
            "Epoch 55/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 7.1538 - gender_output_loss: 0.5180 - image_quality_output_loss: 0.9588 - age_output_loss: 1.3858 - weight_output_loss: 0.9688 - bag_output_loss: 0.8605 - footwear_output_loss: 0.8562 - pose_output_loss: 0.7285 - emotion_output_loss: 0.8772 - gender_output_acc: 0.7423 - image_quality_output_acc: 0.5517 - age_output_acc: 0.3968 - weight_output_acc: 0.6323 - bag_output_acc: 0.6072 - footwear_output_acc: 0.6125 - pose_output_acc: 0.6886 - emotion_output_acc: 0.7138 - val_loss: 7.3250 - val_gender_output_loss: 0.5484 - val_image_quality_output_loss: 0.9485 - val_age_output_loss: 1.4123 - val_weight_output_loss: 0.9632 - val_bag_output_loss: 0.8966 - val_footwear_output_loss: 0.9407 - val_pose_output_loss: 0.7113 - val_emotion_output_loss: 0.9039 - val_gender_output_acc: 0.7195 - val_image_quality_output_acc: 0.5625 - val_age_output_acc: 0.3884 - val_weight_output_acc: 0.6469 - val_bag_output_acc: 0.5841 - val_footwear_output_acc: 0.5621 - val_pose_output_acc: 0.6949 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 7.06768\n",
            "Epoch 56/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 7.1232 - gender_output_loss: 0.5077 - image_quality_output_loss: 0.9534 - age_output_loss: 1.3828 - weight_output_loss: 0.9642 - bag_output_loss: 0.8630 - footwear_output_loss: 0.8565 - pose_output_loss: 0.7194 - emotion_output_loss: 0.8760 - gender_output_acc: 0.7464 - image_quality_output_acc: 0.5532 - age_output_acc: 0.4004 - weight_output_acc: 0.6315 - bag_output_acc: 0.6059 - footwear_output_acc: 0.6138 - pose_output_acc: 0.6946 - emotion_output_acc: 0.7137 - val_loss: 7.1165 - val_gender_output_loss: 0.4935 - val_image_quality_output_loss: 0.9618 - val_age_output_loss: 1.3978 - val_weight_output_loss: 0.9483 - val_bag_output_loss: 0.8709 - val_footwear_output_loss: 0.8526 - val_pose_output_loss: 0.6893 - val_emotion_output_loss: 0.9025 - val_gender_output_acc: 0.7582 - val_image_quality_output_acc: 0.5606 - val_age_output_acc: 0.3951 - val_weight_output_acc: 0.6469 - val_bag_output_acc: 0.5990 - val_footwear_output_acc: 0.6109 - val_pose_output_acc: 0.7154 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 7.06768\n",
            "Epoch 57/200\n",
            "339/339 [==============================] - 174s 513ms/step - loss: 7.0924 - gender_output_loss: 0.4950 - image_quality_output_loss: 0.9523 - age_output_loss: 1.3811 - weight_output_loss: 0.9633 - bag_output_loss: 0.8580 - footwear_output_loss: 0.8536 - pose_output_loss: 0.7146 - emotion_output_loss: 0.8745 - gender_output_acc: 0.7552 - image_quality_output_acc: 0.5538 - age_output_acc: 0.4023 - weight_output_acc: 0.6330 - bag_output_acc: 0.6078 - footwear_output_acc: 0.6136 - pose_output_acc: 0.6949 - emotion_output_acc: 0.7137 - val_loss: 7.1155 - val_gender_output_loss: 0.4940 - val_image_quality_output_loss: 0.9527 - val_age_output_loss: 1.3972 - val_weight_output_loss: 0.9490 - val_bag_output_loss: 0.8750 - val_footwear_output_loss: 0.8716 - val_pose_output_loss: 0.6762 - val_emotion_output_loss: 0.8998 - val_gender_output_acc: 0.7470 - val_image_quality_output_acc: 0.5647 - val_age_output_acc: 0.3910 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.6016 - val_footwear_output_acc: 0.5986 - val_pose_output_acc: 0.7165 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 7.06768\n",
            "Epoch 58/200\n",
            "339/339 [==============================] - 174s 513ms/step - loss: 7.0902 - gender_output_loss: 0.5013 - image_quality_output_loss: 0.9522 - age_output_loss: 1.3834 - weight_output_loss: 0.9667 - bag_output_loss: 0.8592 - footwear_output_loss: 0.8475 - pose_output_loss: 0.7010 - emotion_output_loss: 0.8789 - gender_output_acc: 0.7512 - image_quality_output_acc: 0.5540 - age_output_acc: 0.4023 - weight_output_acc: 0.6311 - bag_output_acc: 0.6026 - footwear_output_acc: 0.6135 - pose_output_acc: 0.7030 - emotion_output_acc: 0.7137 - val_loss: 7.1339 - val_gender_output_loss: 0.5165 - val_image_quality_output_loss: 0.9461 - val_age_output_loss: 1.4016 - val_weight_output_loss: 0.9506 - val_bag_output_loss: 0.8858 - val_footwear_output_loss: 0.8558 - val_pose_output_loss: 0.6723 - val_emotion_output_loss: 0.9052 - val_gender_output_acc: 0.7433 - val_image_quality_output_acc: 0.5636 - val_age_output_acc: 0.3940 - val_weight_output_acc: 0.6499 - val_bag_output_acc: 0.5982 - val_footwear_output_acc: 0.6094 - val_pose_output_acc: 0.7087 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 7.06768\n",
            "Epoch 59/200\n",
            "339/339 [==============================] - 173s 511ms/step - loss: 7.0740 - gender_output_loss: 0.4918 - image_quality_output_loss: 0.9527 - age_output_loss: 1.3806 - weight_output_loss: 0.9644 - bag_output_loss: 0.8574 - footwear_output_loss: 0.8535 - pose_output_loss: 0.6988 - emotion_output_loss: 0.8747 - gender_output_acc: 0.7611 - image_quality_output_acc: 0.5542 - age_output_acc: 0.3999 - weight_output_acc: 0.6314 - bag_output_acc: 0.6078 - footwear_output_acc: 0.6175 - pose_output_acc: 0.7080 - emotion_output_acc: 0.7140 - val_loss: 7.0703 - val_gender_output_loss: 0.4852 - val_image_quality_output_loss: 0.9354 - val_age_output_loss: 1.3986 - val_weight_output_loss: 0.9447 - val_bag_output_loss: 0.8740 - val_footwear_output_loss: 0.8641 - val_pose_output_loss: 0.6720 - val_emotion_output_loss: 0.8963 - val_gender_output_acc: 0.7638 - val_image_quality_output_acc: 0.5655 - val_age_output_acc: 0.3921 - val_weight_output_acc: 0.6507 - val_bag_output_acc: 0.5971 - val_footwear_output_acc: 0.6097 - val_pose_output_acc: 0.7202 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 7.06768\n",
            "Epoch 60/200\n",
            "339/339 [==============================] - 174s 513ms/step - loss: 7.0416 - gender_output_loss: 0.4877 - image_quality_output_loss: 0.9474 - age_output_loss: 1.3825 - weight_output_loss: 0.9623 - bag_output_loss: 0.8546 - footwear_output_loss: 0.8447 - pose_output_loss: 0.6872 - emotion_output_loss: 0.8752 - gender_output_acc: 0.7641 - image_quality_output_acc: 0.5554 - age_output_acc: 0.3983 - weight_output_acc: 0.6320 - bag_output_acc: 0.6138 - footwear_output_acc: 0.6177 - pose_output_acc: 0.7060 - emotion_output_acc: 0.7136 - val_loss: 7.1310 - val_gender_output_loss: 0.5038 - val_image_quality_output_loss: 0.9355 - val_age_output_loss: 1.4066 - val_weight_output_loss: 0.9505 - val_bag_output_loss: 0.8890 - val_footwear_output_loss: 0.8416 - val_pose_output_loss: 0.6976 - val_emotion_output_loss: 0.9064 - val_gender_output_acc: 0.7541 - val_image_quality_output_acc: 0.5677 - val_age_output_acc: 0.3806 - val_weight_output_acc: 0.6525 - val_bag_output_acc: 0.5975 - val_footwear_output_acc: 0.6150 - val_pose_output_acc: 0.6953 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 7.06768\n",
            "Epoch 61/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 7.0193 - gender_output_loss: 0.4863 - image_quality_output_loss: 0.9457 - age_output_loss: 1.3795 - weight_output_loss: 0.9619 - bag_output_loss: 0.8503 - footwear_output_loss: 0.8441 - pose_output_loss: 0.6813 - emotion_output_loss: 0.8702 - gender_output_acc: 0.7610 - image_quality_output_acc: 0.5541 - age_output_acc: 0.4025 - weight_output_acc: 0.6334 - bag_output_acc: 0.6151 - footwear_output_acc: 0.6247 - pose_output_acc: 0.7095 - emotion_output_acc: 0.7137 - val_loss: 7.1502 - val_gender_output_loss: 0.5356 - val_image_quality_output_loss: 0.9440 - val_age_output_loss: 1.3959 - val_weight_output_loss: 0.9551 - val_bag_output_loss: 0.8957 - val_footwear_output_loss: 0.8625 - val_pose_output_loss: 0.6636 - val_emotion_output_loss: 0.8978 - val_gender_output_acc: 0.7202 - val_image_quality_output_acc: 0.5647 - val_age_output_acc: 0.3955 - val_weight_output_acc: 0.6447 - val_bag_output_acc: 0.5971 - val_footwear_output_acc: 0.6142 - val_pose_output_acc: 0.7258 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 7.06768\n",
            "Epoch 62/200\n",
            "339/339 [==============================] - 175s 515ms/step - loss: 6.9969 - gender_output_loss: 0.4747 - image_quality_output_loss: 0.9429 - age_output_loss: 1.3755 - weight_output_loss: 0.9615 - bag_output_loss: 0.8534 - footwear_output_loss: 0.8457 - pose_output_loss: 0.6702 - emotion_output_loss: 0.8730 - gender_output_acc: 0.7634 - image_quality_output_acc: 0.5526 - age_output_acc: 0.3998 - weight_output_acc: 0.6306 - bag_output_acc: 0.6136 - footwear_output_acc: 0.6248 - pose_output_acc: 0.7191 - emotion_output_acc: 0.7139 - val_loss: 6.9759 - val_gender_output_loss: 0.4670 - val_image_quality_output_loss: 0.9380 - val_age_output_loss: 1.3901 - val_weight_output_loss: 0.9428 - val_bag_output_loss: 0.8628 - val_footwear_output_loss: 0.8394 - val_pose_output_loss: 0.6411 - val_emotion_output_loss: 0.8948 - val_gender_output_acc: 0.7693 - val_image_quality_output_acc: 0.5673 - val_age_output_acc: 0.3966 - val_weight_output_acc: 0.6510 - val_bag_output_acc: 0.6060 - val_footwear_output_acc: 0.6190 - val_pose_output_acc: 0.7426 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00062: val_loss improved from 7.06768 to 6.97594, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 63/200\n",
            "339/339 [==============================] - 174s 512ms/step - loss: 6.9436 - gender_output_loss: 0.4619 - image_quality_output_loss: 0.9366 - age_output_loss: 1.3764 - weight_output_loss: 0.9611 - bag_output_loss: 0.8479 - footwear_output_loss: 0.8366 - pose_output_loss: 0.6546 - emotion_output_loss: 0.8685 - gender_output_acc: 0.7736 - image_quality_output_acc: 0.5562 - age_output_acc: 0.4037 - weight_output_acc: 0.6328 - bag_output_acc: 0.6162 - footwear_output_acc: 0.6246 - pose_output_acc: 0.7240 - emotion_output_acc: 0.7138 - val_loss: 7.0014 - val_gender_output_loss: 0.4876 - val_image_quality_output_loss: 0.9444 - val_age_output_loss: 1.3957 - val_weight_output_loss: 0.9456 - val_bag_output_loss: 0.8728 - val_footwear_output_loss: 0.8303 - val_pose_output_loss: 0.6287 - val_emotion_output_loss: 0.8963 - val_gender_output_acc: 0.7526 - val_image_quality_output_acc: 0.5506 - val_age_output_acc: 0.3862 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.5990 - val_footwear_output_acc: 0.6179 - val_pose_output_acc: 0.7455 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 6.97594\n",
            "Epoch 64/200\n",
            "339/339 [==============================] - 175s 516ms/step - loss: 6.9348 - gender_output_loss: 0.4613 - image_quality_output_loss: 0.9357 - age_output_loss: 1.3751 - weight_output_loss: 0.9572 - bag_output_loss: 0.8433 - footwear_output_loss: 0.8350 - pose_output_loss: 0.6563 - emotion_output_loss: 0.8709 - gender_output_acc: 0.7746 - image_quality_output_acc: 0.5599 - age_output_acc: 0.4032 - weight_output_acc: 0.6330 - bag_output_acc: 0.6219 - footwear_output_acc: 0.6240 - pose_output_acc: 0.7236 - emotion_output_acc: 0.7135 - val_loss: 7.0410 - val_gender_output_loss: 0.4805 - val_image_quality_output_loss: 0.9215 - val_age_output_loss: 1.3993 - val_weight_output_loss: 0.9419 - val_bag_output_loss: 0.8702 - val_footwear_output_loss: 0.8358 - val_pose_output_loss: 0.6943 - val_emotion_output_loss: 0.8974 - val_gender_output_acc: 0.7563 - val_image_quality_output_acc: 0.5740 - val_age_output_acc: 0.3966 - val_weight_output_acc: 0.6514 - val_bag_output_acc: 0.6031 - val_footwear_output_acc: 0.6231 - val_pose_output_acc: 0.6849 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 6.97594\n",
            "Epoch 65/200\n",
            "339/339 [==============================] - 175s 517ms/step - loss: 6.8882 - gender_output_loss: 0.4490 - image_quality_output_loss: 0.9331 - age_output_loss: 1.3753 - weight_output_loss: 0.9572 - bag_output_loss: 0.8451 - footwear_output_loss: 0.8283 - pose_output_loss: 0.6358 - emotion_output_loss: 0.8644 - gender_output_acc: 0.7826 - image_quality_output_acc: 0.5599 - age_output_acc: 0.3988 - weight_output_acc: 0.6327 - bag_output_acc: 0.6221 - footwear_output_acc: 0.6303 - pose_output_acc: 0.7388 - emotion_output_acc: 0.7135 - val_loss: 7.0499 - val_gender_output_loss: 0.4964 - val_image_quality_output_loss: 0.9383 - val_age_output_loss: 1.4013 - val_weight_output_loss: 0.9536 - val_bag_output_loss: 0.8634 - val_footwear_output_loss: 0.8529 - val_pose_output_loss: 0.6473 - val_emotion_output_loss: 0.8967 - val_gender_output_acc: 0.7571 - val_image_quality_output_acc: 0.5614 - val_age_output_acc: 0.3943 - val_weight_output_acc: 0.6481 - val_bag_output_acc: 0.6068 - val_footwear_output_acc: 0.6105 - val_pose_output_acc: 0.7329 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 6.97594\n",
            "Epoch 66/200\n",
            "339/339 [==============================] - 175s 516ms/step - loss: 6.8658 - gender_output_loss: 0.4455 - image_quality_output_loss: 0.9284 - age_output_loss: 1.3744 - weight_output_loss: 0.9535 - bag_output_loss: 0.8387 - footwear_output_loss: 0.8300 - pose_output_loss: 0.6297 - emotion_output_loss: 0.8656 - gender_output_acc: 0.7864 - image_quality_output_acc: 0.5624 - age_output_acc: 0.4019 - weight_output_acc: 0.6336 - bag_output_acc: 0.6224 - footwear_output_acc: 0.6297 - pose_output_acc: 0.7377 - emotion_output_acc: 0.7133 - val_loss: 6.9336 - val_gender_output_loss: 0.4665 - val_image_quality_output_loss: 0.9215 - val_age_output_loss: 1.3929 - val_weight_output_loss: 0.9375 - val_bag_output_loss: 0.8599 - val_footwear_output_loss: 0.8391 - val_pose_output_loss: 0.6230 - val_emotion_output_loss: 0.8934 - val_gender_output_acc: 0.7731 - val_image_quality_output_acc: 0.5685 - val_age_output_acc: 0.3947 - val_weight_output_acc: 0.6499 - val_bag_output_acc: 0.6112 - val_footwear_output_acc: 0.6224 - val_pose_output_acc: 0.7440 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00066: val_loss improved from 6.97594 to 6.93359, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 67/200\n",
            "339/339 [==============================] - 174s 515ms/step - loss: 6.8210 - gender_output_loss: 0.4296 - image_quality_output_loss: 0.9247 - age_output_loss: 1.3675 - weight_output_loss: 0.9562 - bag_output_loss: 0.8362 - footwear_output_loss: 0.8239 - pose_output_loss: 0.6177 - emotion_output_loss: 0.8652 - gender_output_acc: 0.7968 - image_quality_output_acc: 0.5638 - age_output_acc: 0.4073 - weight_output_acc: 0.6331 - bag_output_acc: 0.6275 - footwear_output_acc: 0.6331 - pose_output_acc: 0.7450 - emotion_output_acc: 0.7137 - val_loss: 6.9133 - val_gender_output_loss: 0.4339 - val_image_quality_output_loss: 0.9387 - val_age_output_loss: 1.3877 - val_weight_output_loss: 0.9468 - val_bag_output_loss: 0.8643 - val_footwear_output_loss: 0.8390 - val_pose_output_loss: 0.6082 - val_emotion_output_loss: 0.8948 - val_gender_output_acc: 0.7943 - val_image_quality_output_acc: 0.5536 - val_age_output_acc: 0.4014 - val_weight_output_acc: 0.6451 - val_bag_output_acc: 0.6101 - val_footwear_output_acc: 0.6239 - val_pose_output_acc: 0.7470 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00067: val_loss improved from 6.93359 to 6.91331, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 68/200\n",
            "339/339 [==============================] - 174s 512ms/step - loss: 6.8023 - gender_output_loss: 0.4304 - image_quality_output_loss: 0.9267 - age_output_loss: 1.3709 - weight_output_loss: 0.9526 - bag_output_loss: 0.8342 - footwear_output_loss: 0.8214 - pose_output_loss: 0.6051 - emotion_output_loss: 0.8610 - gender_output_acc: 0.7968 - image_quality_output_acc: 0.5578 - age_output_acc: 0.4021 - weight_output_acc: 0.6326 - bag_output_acc: 0.6269 - footwear_output_acc: 0.6373 - pose_output_acc: 0.7494 - emotion_output_acc: 0.7138 - val_loss: 6.8429 - val_gender_output_loss: 0.4291 - val_image_quality_output_loss: 0.9191 - val_age_output_loss: 1.3885 - val_weight_output_loss: 0.9355 - val_bag_output_loss: 0.8574 - val_footwear_output_loss: 0.8198 - val_pose_output_loss: 0.6008 - val_emotion_output_loss: 0.8927 - val_gender_output_acc: 0.7883 - val_image_quality_output_acc: 0.5670 - val_age_output_acc: 0.4103 - val_weight_output_acc: 0.6477 - val_bag_output_acc: 0.6101 - val_footwear_output_acc: 0.6220 - val_pose_output_acc: 0.7567 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00068: val_loss improved from 6.91331 to 6.84287, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 69/200\n",
            "339/339 [==============================] - 173s 510ms/step - loss: 6.8041 - gender_output_loss: 0.4302 - image_quality_output_loss: 0.9314 - age_output_loss: 1.3695 - weight_output_loss: 0.9497 - bag_output_loss: 0.8357 - footwear_output_loss: 0.8185 - pose_output_loss: 0.6075 - emotion_output_loss: 0.8616 - gender_output_acc: 0.7950 - image_quality_output_acc: 0.5572 - age_output_acc: 0.4052 - weight_output_acc: 0.6338 - bag_output_acc: 0.6253 - footwear_output_acc: 0.6352 - pose_output_acc: 0.7472 - emotion_output_acc: 0.7137 - val_loss: 7.0178 - val_gender_output_loss: 0.4495 - val_image_quality_output_loss: 0.9290 - val_age_output_loss: 1.3898 - val_weight_output_loss: 0.9410 - val_bag_output_loss: 0.8730 - val_footwear_output_loss: 0.8488 - val_pose_output_loss: 0.6891 - val_emotion_output_loss: 0.8975 - val_gender_output_acc: 0.7742 - val_image_quality_output_acc: 0.5666 - val_age_output_acc: 0.3999 - val_weight_output_acc: 0.6484 - val_bag_output_acc: 0.5915 - val_footwear_output_acc: 0.6124 - val_pose_output_acc: 0.7254 - val_emotion_output_acc: 0.7031\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 6.84287\n",
            "Epoch 70/200\n",
            "339/339 [==============================] - 174s 512ms/step - loss: 6.7649 - gender_output_loss: 0.4225 - image_quality_output_loss: 0.9252 - age_output_loss: 1.3686 - weight_output_loss: 0.9489 - bag_output_loss: 0.8306 - footwear_output_loss: 0.8112 - pose_output_loss: 0.5974 - emotion_output_loss: 0.8606 - gender_output_acc: 0.8010 - image_quality_output_acc: 0.5584 - age_output_acc: 0.4072 - weight_output_acc: 0.6356 - bag_output_acc: 0.6315 - footwear_output_acc: 0.6425 - pose_output_acc: 0.7556 - emotion_output_acc: 0.7142 - val_loss: 6.9020 - val_gender_output_loss: 0.4410 - val_image_quality_output_loss: 0.9272 - val_age_output_loss: 1.3974 - val_weight_output_loss: 0.9566 - val_bag_output_loss: 0.8515 - val_footwear_output_loss: 0.8210 - val_pose_output_loss: 0.6172 - val_emotion_output_loss: 0.8902 - val_gender_output_acc: 0.7794 - val_image_quality_output_acc: 0.5599 - val_age_output_acc: 0.3992 - val_weight_output_acc: 0.6425 - val_bag_output_acc: 0.6187 - val_footwear_output_acc: 0.6257 - val_pose_output_acc: 0.7519 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 6.84287\n",
            "Epoch 71/200\n",
            "339/339 [==============================] - 174s 513ms/step - loss: 6.7421 - gender_output_loss: 0.4138 - image_quality_output_loss: 0.9212 - age_output_loss: 1.3681 - weight_output_loss: 0.9507 - bag_output_loss: 0.8241 - footwear_output_loss: 0.8086 - pose_output_loss: 0.5952 - emotion_output_loss: 0.8603 - gender_output_acc: 0.8094 - image_quality_output_acc: 0.5635 - age_output_acc: 0.4017 - weight_output_acc: 0.6330 - bag_output_acc: 0.6346 - footwear_output_acc: 0.6393 - pose_output_acc: 0.7577 - emotion_output_acc: 0.7140 - val_loss: 6.8952 - val_gender_output_loss: 0.4354 - val_image_quality_output_loss: 0.9226 - val_age_output_loss: 1.3883 - val_weight_output_loss: 0.9421 - val_bag_output_loss: 0.8537 - val_footwear_output_loss: 0.8488 - val_pose_output_loss: 0.6108 - val_emotion_output_loss: 0.8935 - val_gender_output_acc: 0.7939 - val_image_quality_output_acc: 0.5651 - val_age_output_acc: 0.4007 - val_weight_output_acc: 0.6518 - val_bag_output_acc: 0.6194 - val_footwear_output_acc: 0.6138 - val_pose_output_acc: 0.7522 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 6.84287\n",
            "Epoch 72/200\n",
            "339/339 [==============================] - 175s 518ms/step - loss: 6.6876 - gender_output_loss: 0.4021 - image_quality_output_loss: 0.9200 - age_output_loss: 1.3633 - weight_output_loss: 0.9460 - bag_output_loss: 0.8206 - footwear_output_loss: 0.8036 - pose_output_loss: 0.5758 - emotion_output_loss: 0.8562 - gender_output_acc: 0.8122 - image_quality_output_acc: 0.5633 - age_output_acc: 0.4062 - weight_output_acc: 0.6342 - bag_output_acc: 0.6350 - footwear_output_acc: 0.6412 - pose_output_acc: 0.7625 - emotion_output_acc: 0.7137 - val_loss: 6.8050 - val_gender_output_loss: 0.4163 - val_image_quality_output_loss: 0.9159 - val_age_output_loss: 1.3861 - val_weight_output_loss: 0.9359 - val_bag_output_loss: 0.8510 - val_footwear_output_loss: 0.8195 - val_pose_output_loss: 0.5845 - val_emotion_output_loss: 0.8957 - val_gender_output_acc: 0.7991 - val_image_quality_output_acc: 0.5662 - val_age_output_acc: 0.3999 - val_weight_output_acc: 0.6522 - val_bag_output_acc: 0.6172 - val_footwear_output_acc: 0.6298 - val_pose_output_acc: 0.7571 - val_emotion_output_acc: 0.7031\n",
            "\n",
            "Epoch 00072: val_loss improved from 6.84287 to 6.80498, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 73/200\n",
            "339/339 [==============================] - 174s 512ms/step - loss: 6.6233 - gender_output_loss: 0.3916 - image_quality_output_loss: 0.9114 - age_output_loss: 1.3568 - weight_output_loss: 0.9395 - bag_output_loss: 0.8162 - footwear_output_loss: 0.7951 - pose_output_loss: 0.5587 - emotion_output_loss: 0.8541 - gender_output_acc: 0.8215 - image_quality_output_acc: 0.5663 - age_output_acc: 0.4091 - weight_output_acc: 0.6355 - bag_output_acc: 0.6371 - footwear_output_acc: 0.6468 - pose_output_acc: 0.7716 - emotion_output_acc: 0.7138 - val_loss: 6.9311 - val_gender_output_loss: 0.4820 - val_image_quality_output_loss: 0.9398 - val_age_output_loss: 1.3896 - val_weight_output_loss: 0.9360 - val_bag_output_loss: 0.8817 - val_footwear_output_loss: 0.8157 - val_pose_output_loss: 0.5887 - val_emotion_output_loss: 0.8977 - val_gender_output_acc: 0.7641 - val_image_quality_output_acc: 0.5547 - val_age_output_acc: 0.3958 - val_weight_output_acc: 0.6514 - val_bag_output_acc: 0.5755 - val_footwear_output_acc: 0.6254 - val_pose_output_acc: 0.7571 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 6.80498\n",
            "Epoch 74/200\n",
            "339/339 [==============================] - 174s 513ms/step - loss: 6.6012 - gender_output_loss: 0.3804 - image_quality_output_loss: 0.9105 - age_output_loss: 1.3569 - weight_output_loss: 0.9401 - bag_output_loss: 0.8122 - footwear_output_loss: 0.7957 - pose_output_loss: 0.5478 - emotion_output_loss: 0.8575 - gender_output_acc: 0.8260 - image_quality_output_acc: 0.5655 - age_output_acc: 0.4084 - weight_output_acc: 0.6369 - bag_output_acc: 0.6431 - footwear_output_acc: 0.6446 - pose_output_acc: 0.7758 - emotion_output_acc: 0.7131 - val_loss: 6.8150 - val_gender_output_loss: 0.4476 - val_image_quality_output_loss: 0.9102 - val_age_output_loss: 1.3839 - val_weight_output_loss: 0.9364 - val_bag_output_loss: 0.8567 - val_footwear_output_loss: 0.8143 - val_pose_output_loss: 0.5722 - val_emotion_output_loss: 0.8937 - val_gender_output_acc: 0.7876 - val_image_quality_output_acc: 0.5685 - val_age_output_acc: 0.3955 - val_weight_output_acc: 0.6514 - val_bag_output_acc: 0.6150 - val_footwear_output_acc: 0.6332 - val_pose_output_acc: 0.7705 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 6.80498\n",
            "Epoch 75/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 6.5325 - gender_output_loss: 0.3691 - image_quality_output_loss: 0.9037 - age_output_loss: 1.3514 - weight_output_loss: 0.9357 - bag_output_loss: 0.8027 - footwear_output_loss: 0.7894 - pose_output_loss: 0.5303 - emotion_output_loss: 0.8502 - gender_output_acc: 0.8303 - image_quality_output_acc: 0.5666 - age_output_acc: 0.4140 - weight_output_acc: 0.6352 - bag_output_acc: 0.6485 - footwear_output_acc: 0.6504 - pose_output_acc: 0.7856 - emotion_output_acc: 0.7136 - val_loss: 6.8021 - val_gender_output_loss: 0.4092 - val_image_quality_output_loss: 0.9321 - val_age_output_loss: 1.3892 - val_weight_output_loss: 0.9384 - val_bag_output_loss: 0.8441 - val_footwear_output_loss: 0.8204 - val_pose_output_loss: 0.5757 - val_emotion_output_loss: 0.8931 - val_gender_output_acc: 0.8039 - val_image_quality_output_acc: 0.5580 - val_age_output_acc: 0.3917 - val_weight_output_acc: 0.6518 - val_bag_output_acc: 0.6190 - val_footwear_output_acc: 0.6302 - val_pose_output_acc: 0.7649 - val_emotion_output_acc: 0.7031\n",
            "\n",
            "Epoch 00075: val_loss improved from 6.80498 to 6.80214, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 76/200\n",
            "339/339 [==============================] - 174s 512ms/step - loss: 6.4727 - gender_output_loss: 0.3550 - image_quality_output_loss: 0.9015 - age_output_loss: 1.3474 - weight_output_loss: 0.9304 - bag_output_loss: 0.8012 - footwear_output_loss: 0.7753 - pose_output_loss: 0.5140 - emotion_output_loss: 0.8480 - gender_output_acc: 0.8403 - image_quality_output_acc: 0.5699 - age_output_acc: 0.4084 - weight_output_acc: 0.6374 - bag_output_acc: 0.6473 - footwear_output_acc: 0.6596 - pose_output_acc: 0.7921 - emotion_output_acc: 0.7137 - val_loss: 6.7956 - val_gender_output_loss: 0.4130 - val_image_quality_output_loss: 0.9152 - val_age_output_loss: 1.3815 - val_weight_output_loss: 0.9311 - val_bag_output_loss: 0.8505 - val_footwear_output_loss: 0.8159 - val_pose_output_loss: 0.5929 - val_emotion_output_loss: 0.8954 - val_gender_output_acc: 0.8017 - val_image_quality_output_acc: 0.5722 - val_age_output_acc: 0.4029 - val_weight_output_acc: 0.6525 - val_bag_output_acc: 0.6287 - val_footwear_output_acc: 0.6373 - val_pose_output_acc: 0.7578 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00076: val_loss improved from 6.80214 to 6.79555, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 77/200\n",
            "339/339 [==============================] - 173s 511ms/step - loss: 6.4963 - gender_output_loss: 0.3548 - image_quality_output_loss: 0.9035 - age_output_loss: 1.3432 - weight_output_loss: 0.9337 - bag_output_loss: 0.8028 - footwear_output_loss: 0.7885 - pose_output_loss: 0.5208 - emotion_output_loss: 0.8490 - gender_output_acc: 0.8372 - image_quality_output_acc: 0.5689 - age_output_acc: 0.4187 - weight_output_acc: 0.6359 - bag_output_acc: 0.6495 - footwear_output_acc: 0.6539 - pose_output_acc: 0.7939 - emotion_output_acc: 0.7140 - val_loss: 6.8103 - val_gender_output_loss: 0.4018 - val_image_quality_output_loss: 0.9105 - val_age_output_loss: 1.3794 - val_weight_output_loss: 0.9322 - val_bag_output_loss: 0.8427 - val_footwear_output_loss: 0.8070 - val_pose_output_loss: 0.6395 - val_emotion_output_loss: 0.8971 - val_gender_output_acc: 0.8155 - val_image_quality_output_acc: 0.5714 - val_age_output_acc: 0.4059 - val_weight_output_acc: 0.6518 - val_bag_output_acc: 0.6187 - val_footwear_output_acc: 0.6280 - val_pose_output_acc: 0.7347 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 6.79555\n",
            "Epoch 78/200\n",
            "339/339 [==============================] - 175s 517ms/step - loss: 6.5404 - gender_output_loss: 0.3699 - image_quality_output_loss: 0.9084 - age_output_loss: 1.3504 - weight_output_loss: 0.9288 - bag_output_loss: 0.8081 - footwear_output_loss: 0.7859 - pose_output_loss: 0.5373 - emotion_output_loss: 0.8517 - gender_output_acc: 0.8314 - image_quality_output_acc: 0.5665 - age_output_acc: 0.4112 - weight_output_acc: 0.6369 - bag_output_acc: 0.6476 - footwear_output_acc: 0.6543 - pose_output_acc: 0.7841 - emotion_output_acc: 0.7134 - val_loss: 6.9720 - val_gender_output_loss: 0.4708 - val_image_quality_output_loss: 0.9190 - val_age_output_loss: 1.3885 - val_weight_output_loss: 0.9369 - val_bag_output_loss: 0.8489 - val_footwear_output_loss: 0.8408 - val_pose_output_loss: 0.6677 - val_emotion_output_loss: 0.8992 - val_gender_output_acc: 0.7671 - val_image_quality_output_acc: 0.5610 - val_age_output_acc: 0.4003 - val_weight_output_acc: 0.6481 - val_bag_output_acc: 0.6213 - val_footwear_output_acc: 0.6194 - val_pose_output_acc: 0.7318 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 6.79555\n",
            "Epoch 79/200\n",
            "339/339 [==============================] - 176s 518ms/step - loss: 6.6052 - gender_output_loss: 0.3888 - image_quality_output_loss: 0.9116 - age_output_loss: 1.3544 - weight_output_loss: 0.9407 - bag_output_loss: 0.8075 - footwear_output_loss: 0.7941 - pose_output_loss: 0.5532 - emotion_output_loss: 0.8549 - gender_output_acc: 0.8229 - image_quality_output_acc: 0.5682 - age_output_acc: 0.4110 - weight_output_acc: 0.6345 - bag_output_acc: 0.6456 - footwear_output_acc: 0.6440 - pose_output_acc: 0.7771 - emotion_output_acc: 0.7132 - val_loss: 6.9736 - val_gender_output_loss: 0.4698 - val_image_quality_output_loss: 0.9295 - val_age_output_loss: 1.3930 - val_weight_output_loss: 0.9359 - val_bag_output_loss: 0.8600 - val_footwear_output_loss: 0.8376 - val_pose_output_loss: 0.6503 - val_emotion_output_loss: 0.8975 - val_gender_output_acc: 0.7716 - val_image_quality_output_acc: 0.5525 - val_age_output_acc: 0.3992 - val_weight_output_acc: 0.6510 - val_bag_output_acc: 0.6217 - val_footwear_output_acc: 0.6261 - val_pose_output_acc: 0.7228 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 6.79555\n",
            "Epoch 80/200\n",
            "339/339 [==============================] - 176s 521ms/step - loss: 6.5847 - gender_output_loss: 0.3794 - image_quality_output_loss: 0.9101 - age_output_loss: 1.3528 - weight_output_loss: 0.9336 - bag_output_loss: 0.8112 - footwear_output_loss: 0.7979 - pose_output_loss: 0.5476 - emotion_output_loss: 0.8523 - gender_output_acc: 0.8251 - image_quality_output_acc: 0.5678 - age_output_acc: 0.4089 - weight_output_acc: 0.6366 - bag_output_acc: 0.6459 - footwear_output_acc: 0.6420 - pose_output_acc: 0.7738 - emotion_output_acc: 0.7140 - val_loss: 6.7906 - val_gender_output_loss: 0.4051 - val_image_quality_output_loss: 0.9166 - val_age_output_loss: 1.3819 - val_weight_output_loss: 0.9362 - val_bag_output_loss: 0.8435 - val_footwear_output_loss: 0.8262 - val_pose_output_loss: 0.5829 - val_emotion_output_loss: 0.8984 - val_gender_output_acc: 0.8151 - val_image_quality_output_acc: 0.5722 - val_age_output_acc: 0.4089 - val_weight_output_acc: 0.6536 - val_bag_output_acc: 0.6272 - val_footwear_output_acc: 0.6306 - val_pose_output_acc: 0.7626 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00080: val_loss improved from 6.79555 to 6.79063, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 81/200\n",
            "339/339 [==============================] - 174s 515ms/step - loss: 6.5623 - gender_output_loss: 0.3789 - image_quality_output_loss: 0.9074 - age_output_loss: 1.3508 - weight_output_loss: 0.9355 - bag_output_loss: 0.8035 - footwear_output_loss: 0.7972 - pose_output_loss: 0.5347 - emotion_output_loss: 0.8542 - gender_output_acc: 0.8284 - image_quality_output_acc: 0.5677 - age_output_acc: 0.4138 - weight_output_acc: 0.6352 - bag_output_acc: 0.6481 - footwear_output_acc: 0.6445 - pose_output_acc: 0.7866 - emotion_output_acc: 0.7130 - val_loss: 6.8913 - val_gender_output_loss: 0.4519 - val_image_quality_output_loss: 0.9227 - val_age_output_loss: 1.3910 - val_weight_output_loss: 0.9359 - val_bag_output_loss: 0.8613 - val_footwear_output_loss: 0.8712 - val_pose_output_loss: 0.5615 - val_emotion_output_loss: 0.8958 - val_gender_output_acc: 0.7924 - val_image_quality_output_acc: 0.5580 - val_age_output_acc: 0.3940 - val_weight_output_acc: 0.6503 - val_bag_output_acc: 0.6060 - val_footwear_output_acc: 0.6019 - val_pose_output_acc: 0.7794 - val_emotion_output_acc: 0.7035\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 6.79063\n",
            "Epoch 82/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 6.5607 - gender_output_loss: 0.3749 - image_quality_output_loss: 0.9121 - age_output_loss: 1.3497 - weight_output_loss: 0.9342 - bag_output_loss: 0.8121 - footwear_output_loss: 0.7915 - pose_output_loss: 0.5342 - emotion_output_loss: 0.8519 - gender_output_acc: 0.8333 - image_quality_output_acc: 0.5626 - age_output_acc: 0.4156 - weight_output_acc: 0.6384 - bag_output_acc: 0.6421 - footwear_output_acc: 0.6465 - pose_output_acc: 0.7836 - emotion_output_acc: 0.7134 - val_loss: 6.9937 - val_gender_output_loss: 0.4199 - val_image_quality_output_loss: 0.9373 - val_age_output_loss: 1.3928 - val_weight_output_loss: 0.9519 - val_bag_output_loss: 0.8605 - val_footwear_output_loss: 0.8747 - val_pose_output_loss: 0.6510 - val_emotion_output_loss: 0.9057 - val_gender_output_acc: 0.8006 - val_image_quality_output_acc: 0.5528 - val_age_output_acc: 0.3850 - val_weight_output_acc: 0.6458 - val_bag_output_acc: 0.6146 - val_footwear_output_acc: 0.5990 - val_pose_output_acc: 0.7228 - val_emotion_output_acc: 0.7020\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 6.79063\n",
            "Epoch 83/200\n",
            "339/339 [==============================] - 175s 518ms/step - loss: 6.5207 - gender_output_loss: 0.3638 - image_quality_output_loss: 0.9082 - age_output_loss: 1.3486 - weight_output_loss: 0.9347 - bag_output_loss: 0.8031 - footwear_output_loss: 0.7858 - pose_output_loss: 0.5255 - emotion_output_loss: 0.8511 - gender_output_acc: 0.8342 - image_quality_output_acc: 0.5678 - age_output_acc: 0.4164 - weight_output_acc: 0.6375 - bag_output_acc: 0.6493 - footwear_output_acc: 0.6506 - pose_output_acc: 0.7889 - emotion_output_acc: 0.7132 - val_loss: 6.8676 - val_gender_output_loss: 0.4520 - val_image_quality_output_loss: 0.9211 - val_age_output_loss: 1.3863 - val_weight_output_loss: 0.9342 - val_bag_output_loss: 0.8605 - val_footwear_output_loss: 0.8217 - val_pose_output_loss: 0.5982 - val_emotion_output_loss: 0.8935 - val_gender_output_acc: 0.7917 - val_image_quality_output_acc: 0.5666 - val_age_output_acc: 0.3958 - val_weight_output_acc: 0.6496 - val_bag_output_acc: 0.6231 - val_footwear_output_acc: 0.6261 - val_pose_output_acc: 0.7608 - val_emotion_output_acc: 0.7020\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 6.79063\n",
            "Epoch 84/200\n",
            "339/339 [==============================] - 175s 517ms/step - loss: 6.5072 - gender_output_loss: 0.3670 - image_quality_output_loss: 0.9050 - age_output_loss: 1.3442 - weight_output_loss: 0.9285 - bag_output_loss: 0.8048 - footwear_output_loss: 0.7833 - pose_output_loss: 0.5210 - emotion_output_loss: 0.8533 - gender_output_acc: 0.8339 - image_quality_output_acc: 0.5629 - age_output_acc: 0.4110 - weight_output_acc: 0.6395 - bag_output_acc: 0.6471 - footwear_output_acc: 0.6499 - pose_output_acc: 0.7925 - emotion_output_acc: 0.7140 - val_loss: 6.9411 - val_gender_output_loss: 0.4413 - val_image_quality_output_loss: 0.9294 - val_age_output_loss: 1.3908 - val_weight_output_loss: 0.9393 - val_bag_output_loss: 0.8534 - val_footwear_output_loss: 0.8453 - val_pose_output_loss: 0.6485 - val_emotion_output_loss: 0.8933 - val_gender_output_acc: 0.7906 - val_image_quality_output_acc: 0.5547 - val_age_output_acc: 0.4003 - val_weight_output_acc: 0.6477 - val_bag_output_acc: 0.6161 - val_footwear_output_acc: 0.6049 - val_pose_output_acc: 0.7292 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 6.79063\n",
            "Epoch 85/200\n",
            "339/339 [==============================] - 175s 517ms/step - loss: 6.5019 - gender_output_loss: 0.3639 - image_quality_output_loss: 0.9045 - age_output_loss: 1.3404 - weight_output_loss: 0.9304 - bag_output_loss: 0.8033 - footwear_output_loss: 0.7893 - pose_output_loss: 0.5219 - emotion_output_loss: 0.8483 - gender_output_acc: 0.8334 - image_quality_output_acc: 0.5700 - age_output_acc: 0.4145 - weight_output_acc: 0.6363 - bag_output_acc: 0.6506 - footwear_output_acc: 0.6444 - pose_output_acc: 0.7934 - emotion_output_acc: 0.7134 - val_loss: 6.9234 - val_gender_output_loss: 0.4475 - val_image_quality_output_loss: 0.9262 - val_age_output_loss: 1.4078 - val_weight_output_loss: 0.9552 - val_bag_output_loss: 0.8628 - val_footwear_output_loss: 0.8230 - val_pose_output_loss: 0.5997 - val_emotion_output_loss: 0.9010 - val_gender_output_acc: 0.7972 - val_image_quality_output_acc: 0.5592 - val_age_output_acc: 0.3858 - val_weight_output_acc: 0.6350 - val_bag_output_acc: 0.6246 - val_footwear_output_acc: 0.6321 - val_pose_output_acc: 0.7619 - val_emotion_output_acc: 0.7020\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 6.79063\n",
            "Epoch 86/200\n",
            "339/339 [==============================] - 175s 515ms/step - loss: 6.4439 - gender_output_loss: 0.3470 - image_quality_output_loss: 0.9012 - age_output_loss: 1.3431 - weight_output_loss: 0.9253 - bag_output_loss: 0.8025 - footwear_output_loss: 0.7850 - pose_output_loss: 0.4938 - emotion_output_loss: 0.8460 - gender_output_acc: 0.8465 - image_quality_output_acc: 0.5706 - age_output_acc: 0.4107 - weight_output_acc: 0.6355 - bag_output_acc: 0.6503 - footwear_output_acc: 0.6520 - pose_output_acc: 0.8042 - emotion_output_acc: 0.7140 - val_loss: 6.9092 - val_gender_output_loss: 0.4344 - val_image_quality_output_loss: 0.9212 - val_age_output_loss: 1.3844 - val_weight_output_loss: 0.9443 - val_bag_output_loss: 0.8437 - val_footwear_output_loss: 0.8111 - val_pose_output_loss: 0.6659 - val_emotion_output_loss: 0.9041 - val_gender_output_acc: 0.8006 - val_image_quality_output_acc: 0.5737 - val_age_output_acc: 0.4048 - val_weight_output_acc: 0.6533 - val_bag_output_acc: 0.6265 - val_footwear_output_acc: 0.6243 - val_pose_output_acc: 0.7504 - val_emotion_output_acc: 0.7031\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 6.79063\n",
            "Epoch 87/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 6.4062 - gender_output_loss: 0.3473 - image_quality_output_loss: 0.8960 - age_output_loss: 1.3405 - weight_output_loss: 0.9219 - bag_output_loss: 0.7923 - footwear_output_loss: 0.7750 - pose_output_loss: 0.4909 - emotion_output_loss: 0.8422 - gender_output_acc: 0.8443 - image_quality_output_acc: 0.5717 - age_output_acc: 0.4160 - weight_output_acc: 0.6400 - bag_output_acc: 0.6572 - footwear_output_acc: 0.6556 - pose_output_acc: 0.8047 - emotion_output_acc: 0.7140 - val_loss: 6.8997 - val_gender_output_loss: 0.4591 - val_image_quality_output_loss: 0.9204 - val_age_output_loss: 1.3963 - val_weight_output_loss: 0.9445 - val_bag_output_loss: 0.8722 - val_footwear_output_loss: 0.8286 - val_pose_output_loss: 0.5849 - val_emotion_output_loss: 0.8937 - val_gender_output_acc: 0.7868 - val_image_quality_output_acc: 0.5696 - val_age_output_acc: 0.4003 - val_weight_output_acc: 0.6507 - val_bag_output_acc: 0.6101 - val_footwear_output_acc: 0.6213 - val_pose_output_acc: 0.7786 - val_emotion_output_acc: 0.7031\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 6.79063\n",
            "Epoch 88/200\n",
            "339/339 [==============================] - 175s 516ms/step - loss: 6.4254 - gender_output_loss: 0.3457 - image_quality_output_loss: 0.8985 - age_output_loss: 1.3392 - weight_output_loss: 0.9210 - bag_output_loss: 0.7946 - footwear_output_loss: 0.7849 - pose_output_loss: 0.4990 - emotion_output_loss: 0.8424 - gender_output_acc: 0.8476 - image_quality_output_acc: 0.5760 - age_output_acc: 0.4142 - weight_output_acc: 0.6416 - bag_output_acc: 0.6578 - footwear_output_acc: 0.6494 - pose_output_acc: 0.8048 - emotion_output_acc: 0.7140 - val_loss: 6.7722 - val_gender_output_loss: 0.3910 - val_image_quality_output_loss: 0.9308 - val_age_output_loss: 1.3889 - val_weight_output_loss: 0.9408 - val_bag_output_loss: 0.8417 - val_footwear_output_loss: 0.8113 - val_pose_output_loss: 0.5690 - val_emotion_output_loss: 0.8987 - val_gender_output_acc: 0.8255 - val_image_quality_output_acc: 0.5688 - val_age_output_acc: 0.3973 - val_weight_output_acc: 0.6548 - val_bag_output_acc: 0.6287 - val_footwear_output_acc: 0.6291 - val_pose_output_acc: 0.7671 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00088: val_loss improved from 6.79063 to 6.77219, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 89/200\n",
            "339/339 [==============================] - 173s 511ms/step - loss: 6.3778 - gender_output_loss: 0.3438 - image_quality_output_loss: 0.8945 - age_output_loss: 1.3339 - weight_output_loss: 0.9197 - bag_output_loss: 0.7864 - footwear_output_loss: 0.7727 - pose_output_loss: 0.4799 - emotion_output_loss: 0.8470 - gender_output_acc: 0.8439 - image_quality_output_acc: 0.5687 - age_output_acc: 0.4157 - weight_output_acc: 0.6389 - bag_output_acc: 0.6586 - footwear_output_acc: 0.6603 - pose_output_acc: 0.8090 - emotion_output_acc: 0.7134 - val_loss: 6.8527 - val_gender_output_loss: 0.4107 - val_image_quality_output_loss: 0.9537 - val_age_output_loss: 1.3824 - val_weight_output_loss: 0.9396 - val_bag_output_loss: 0.8521 - val_footwear_output_loss: 0.8231 - val_pose_output_loss: 0.5940 - val_emotion_output_loss: 0.8971 - val_gender_output_acc: 0.8088 - val_image_quality_output_acc: 0.5565 - val_age_output_acc: 0.4007 - val_weight_output_acc: 0.6499 - val_bag_output_acc: 0.6194 - val_footwear_output_acc: 0.6343 - val_pose_output_acc: 0.7712 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 6.77219\n",
            "Epoch 90/200\n",
            "339/339 [==============================] - 173s 512ms/step - loss: 6.3374 - gender_output_loss: 0.3302 - image_quality_output_loss: 0.8900 - age_output_loss: 1.3286 - weight_output_loss: 0.9153 - bag_output_loss: 0.7812 - footwear_output_loss: 0.7708 - pose_output_loss: 0.4772 - emotion_output_loss: 0.8441 - gender_output_acc: 0.8533 - image_quality_output_acc: 0.5717 - age_output_acc: 0.4149 - weight_output_acc: 0.6402 - bag_output_acc: 0.6603 - footwear_output_acc: 0.6591 - pose_output_acc: 0.8136 - emotion_output_acc: 0.7133 - val_loss: 6.8424 - val_gender_output_loss: 0.4008 - val_image_quality_output_loss: 0.9045 - val_age_output_loss: 1.3827 - val_weight_output_loss: 0.9436 - val_bag_output_loss: 0.8355 - val_footwear_output_loss: 0.8009 - val_pose_output_loss: 0.6834 - val_emotion_output_loss: 0.8908 - val_gender_output_acc: 0.8225 - val_image_quality_output_acc: 0.5733 - val_age_output_acc: 0.3921 - val_weight_output_acc: 0.6462 - val_bag_output_acc: 0.6295 - val_footwear_output_acc: 0.6369 - val_pose_output_acc: 0.7548 - val_emotion_output_acc: 0.7020\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 6.77219\n",
            "Epoch 91/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 6.3185 - gender_output_loss: 0.3126 - image_quality_output_loss: 0.8878 - age_output_loss: 1.3277 - weight_output_loss: 0.9206 - bag_output_loss: 0.7807 - footwear_output_loss: 0.7649 - pose_output_loss: 0.4802 - emotion_output_loss: 0.8440 - gender_output_acc: 0.8638 - image_quality_output_acc: 0.5729 - age_output_acc: 0.4228 - weight_output_acc: 0.6388 - bag_output_acc: 0.6619 - footwear_output_acc: 0.6596 - pose_output_acc: 0.8084 - emotion_output_acc: 0.7139 - val_loss: 6.7217 - val_gender_output_loss: 0.3887 - val_image_quality_output_loss: 0.9012 - val_age_output_loss: 1.3877 - val_weight_output_loss: 0.9376 - val_bag_output_loss: 0.8348 - val_footwear_output_loss: 0.8136 - val_pose_output_loss: 0.5706 - val_emotion_output_loss: 0.8876 - val_gender_output_acc: 0.8229 - val_image_quality_output_acc: 0.5785 - val_age_output_acc: 0.3943 - val_weight_output_acc: 0.6492 - val_bag_output_acc: 0.6280 - val_footwear_output_acc: 0.6321 - val_pose_output_acc: 0.7734 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00091: val_loss improved from 6.77219 to 6.72168, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 92/200\n",
            "339/339 [==============================] - 174s 512ms/step - loss: 6.2737 - gender_output_loss: 0.3207 - image_quality_output_loss: 0.8861 - age_output_loss: 1.3230 - weight_output_loss: 0.9105 - bag_output_loss: 0.7749 - footwear_output_loss: 0.7583 - pose_output_loss: 0.4613 - emotion_output_loss: 0.8389 - gender_output_acc: 0.8576 - image_quality_output_acc: 0.5803 - age_output_acc: 0.4209 - weight_output_acc: 0.6414 - bag_output_acc: 0.6674 - footwear_output_acc: 0.6637 - pose_output_acc: 0.8190 - emotion_output_acc: 0.7144 - val_loss: 6.9258 - val_gender_output_loss: 0.4252 - val_image_quality_output_loss: 0.9308 - val_age_output_loss: 1.4040 - val_weight_output_loss: 0.9433 - val_bag_output_loss: 0.8438 - val_footwear_output_loss: 0.8261 - val_pose_output_loss: 0.6457 - val_emotion_output_loss: 0.9071 - val_gender_output_acc: 0.8006 - val_image_quality_output_acc: 0.5699 - val_age_output_acc: 0.3973 - val_weight_output_acc: 0.6510 - val_bag_output_acc: 0.6328 - val_footwear_output_acc: 0.6254 - val_pose_output_acc: 0.7433 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 6.72168\n",
            "Epoch 93/200\n",
            "339/339 [==============================] - 175s 515ms/step - loss: 6.2796 - gender_output_loss: 0.3226 - image_quality_output_loss: 0.8866 - age_output_loss: 1.3247 - weight_output_loss: 0.9081 - bag_output_loss: 0.7737 - footwear_output_loss: 0.7606 - pose_output_loss: 0.4646 - emotion_output_loss: 0.8386 - gender_output_acc: 0.8540 - image_quality_output_acc: 0.5804 - age_output_acc: 0.4193 - weight_output_acc: 0.6417 - bag_output_acc: 0.6671 - footwear_output_acc: 0.6575 - pose_output_acc: 0.8134 - emotion_output_acc: 0.7140 - val_loss: 6.8522 - val_gender_output_loss: 0.4339 - val_image_quality_output_loss: 0.9162 - val_age_output_loss: 1.4002 - val_weight_output_loss: 0.9469 - val_bag_output_loss: 0.8503 - val_footwear_output_loss: 0.8148 - val_pose_output_loss: 0.5946 - val_emotion_output_loss: 0.8952 - val_gender_output_acc: 0.7984 - val_image_quality_output_acc: 0.5558 - val_age_output_acc: 0.3936 - val_weight_output_acc: 0.6436 - val_bag_output_acc: 0.6220 - val_footwear_output_acc: 0.6298 - val_pose_output_acc: 0.7485 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 6.72168\n",
            "Epoch 94/200\n",
            "339/339 [==============================] - 175s 517ms/step - loss: 6.2522 - gender_output_loss: 0.3189 - image_quality_output_loss: 0.8888 - age_output_loss: 1.3185 - weight_output_loss: 0.9032 - bag_output_loss: 0.7674 - footwear_output_loss: 0.7609 - pose_output_loss: 0.4534 - emotion_output_loss: 0.8411 - gender_output_acc: 0.8565 - image_quality_output_acc: 0.5772 - age_output_acc: 0.4213 - weight_output_acc: 0.6431 - bag_output_acc: 0.6719 - footwear_output_acc: 0.6632 - pose_output_acc: 0.8242 - emotion_output_acc: 0.7135 - val_loss: 6.7259 - val_gender_output_loss: 0.3985 - val_image_quality_output_loss: 0.9048 - val_age_output_loss: 1.3833 - val_weight_output_loss: 0.9454 - val_bag_output_loss: 0.8344 - val_footwear_output_loss: 0.8163 - val_pose_output_loss: 0.5513 - val_emotion_output_loss: 0.8919 - val_gender_output_acc: 0.8147 - val_image_quality_output_acc: 0.5744 - val_age_output_acc: 0.3955 - val_weight_output_acc: 0.6399 - val_bag_output_acc: 0.6313 - val_footwear_output_acc: 0.6321 - val_pose_output_acc: 0.7783 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 6.72168\n",
            "Epoch 95/200\n",
            "339/339 [==============================] - 177s 521ms/step - loss: 6.1913 - gender_output_loss: 0.3051 - image_quality_output_loss: 0.8789 - age_output_loss: 1.3159 - weight_output_loss: 0.8997 - bag_output_loss: 0.7606 - footwear_output_loss: 0.7491 - pose_output_loss: 0.4453 - emotion_output_loss: 0.8367 - gender_output_acc: 0.8650 - image_quality_output_acc: 0.5804 - age_output_acc: 0.4205 - weight_output_acc: 0.6431 - bag_output_acc: 0.6790 - footwear_output_acc: 0.6747 - pose_output_acc: 0.8227 - emotion_output_acc: 0.7136 - val_loss: 6.7007 - val_gender_output_loss: 0.3903 - val_image_quality_output_loss: 0.9114 - val_age_output_loss: 1.3791 - val_weight_output_loss: 0.9404 - val_bag_output_loss: 0.8390 - val_footwear_output_loss: 0.8129 - val_pose_output_loss: 0.5312 - val_emotion_output_loss: 0.8963 - val_gender_output_acc: 0.8192 - val_image_quality_output_acc: 0.5640 - val_age_output_acc: 0.3973 - val_weight_output_acc: 0.6436 - val_bag_output_acc: 0.6291 - val_footwear_output_acc: 0.6310 - val_pose_output_acc: 0.7835 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00095: val_loss improved from 6.72168 to 6.70074, saving model to /content/gdrive/My Drive/Colab Notebooks/Inceptionv3_save_clr/assignment5_Inceptionv3_model_best.h5\n",
            "Epoch 96/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 6.1572 - gender_output_loss: 0.3024 - image_quality_output_loss: 0.8765 - age_output_loss: 1.3145 - weight_output_loss: 0.8972 - bag_output_loss: 0.7579 - footwear_output_loss: 0.7403 - pose_output_loss: 0.4309 - emotion_output_loss: 0.8373 - gender_output_acc: 0.8698 - image_quality_output_acc: 0.5785 - age_output_acc: 0.4292 - weight_output_acc: 0.6458 - bag_output_acc: 0.6818 - footwear_output_acc: 0.6745 - pose_output_acc: 0.8296 - emotion_output_acc: 0.7134 - val_loss: 6.8153 - val_gender_output_loss: 0.4089 - val_image_quality_output_loss: 0.9311 - val_age_output_loss: 1.3821 - val_weight_output_loss: 0.9434 - val_bag_output_loss: 0.8477 - val_footwear_output_loss: 0.8208 - val_pose_output_loss: 0.5840 - val_emotion_output_loss: 0.8973 - val_gender_output_acc: 0.8185 - val_image_quality_output_acc: 0.5562 - val_age_output_acc: 0.3955 - val_weight_output_acc: 0.6462 - val_bag_output_acc: 0.6339 - val_footwear_output_acc: 0.6336 - val_pose_output_acc: 0.7712 - val_emotion_output_acc: 0.7020\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 6.70074\n",
            "Epoch 97/200\n",
            "339/339 [==============================] - 176s 518ms/step - loss: 6.0819 - gender_output_loss: 0.2896 - image_quality_output_loss: 0.8685 - age_output_loss: 1.3027 - weight_output_loss: 0.8883 - bag_output_loss: 0.7485 - footwear_output_loss: 0.7400 - pose_output_loss: 0.4125 - emotion_output_loss: 0.8318 - gender_output_acc: 0.8744 - image_quality_output_acc: 0.5864 - age_output_acc: 0.4318 - weight_output_acc: 0.6495 - bag_output_acc: 0.6868 - footwear_output_acc: 0.6715 - pose_output_acc: 0.8429 - emotion_output_acc: 0.7140 - val_loss: 6.8061 - val_gender_output_loss: 0.4022 - val_image_quality_output_loss: 0.9204 - val_age_output_loss: 1.4014 - val_weight_output_loss: 0.9465 - val_bag_output_loss: 0.8447 - val_footwear_output_loss: 0.8160 - val_pose_output_loss: 0.5766 - val_emotion_output_loss: 0.8983 - val_gender_output_acc: 0.8266 - val_image_quality_output_acc: 0.5766 - val_age_output_acc: 0.3698 - val_weight_output_acc: 0.6414 - val_bag_output_acc: 0.6391 - val_footwear_output_acc: 0.6328 - val_pose_output_acc: 0.7783 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 6.70074\n",
            "Epoch 98/200\n",
            "339/339 [==============================] - 176s 518ms/step - loss: 6.0206 - gender_output_loss: 0.2762 - image_quality_output_loss: 0.8638 - age_output_loss: 1.2949 - weight_output_loss: 0.8833 - bag_output_loss: 0.7416 - footwear_output_loss: 0.7279 - pose_output_loss: 0.4045 - emotion_output_loss: 0.8284 - gender_output_acc: 0.8791 - image_quality_output_acc: 0.5911 - age_output_acc: 0.4306 - weight_output_acc: 0.6518 - bag_output_acc: 0.6883 - footwear_output_acc: 0.6807 - pose_output_acc: 0.8424 - emotion_output_acc: 0.7141 - val_loss: 6.7022 - val_gender_output_loss: 0.3929 - val_image_quality_output_loss: 0.9077 - val_age_output_loss: 1.3813 - val_weight_output_loss: 0.9358 - val_bag_output_loss: 0.8504 - val_footwear_output_loss: 0.8076 - val_pose_output_loss: 0.5345 - val_emotion_output_loss: 0.8920 - val_gender_output_acc: 0.8222 - val_image_quality_output_acc: 0.5647 - val_age_output_acc: 0.4103 - val_weight_output_acc: 0.6536 - val_bag_output_acc: 0.6395 - val_footwear_output_acc: 0.6391 - val_pose_output_acc: 0.7980 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 6.70074\n",
            "Epoch 99/200\n",
            "339/339 [==============================] - 177s 523ms/step - loss: 5.9554 - gender_output_loss: 0.2624 - image_quality_output_loss: 0.8597 - age_output_loss: 1.2869 - weight_output_loss: 0.8740 - bag_output_loss: 0.7340 - footwear_output_loss: 0.7220 - pose_output_loss: 0.3919 - emotion_output_loss: 0.8245 - gender_output_acc: 0.8865 - image_quality_output_acc: 0.5926 - age_output_acc: 0.4342 - weight_output_acc: 0.6537 - bag_output_acc: 0.6911 - footwear_output_acc: 0.6847 - pose_output_acc: 0.8509 - emotion_output_acc: 0.7136 - val_loss: 6.9301 - val_gender_output_loss: 0.4867 - val_image_quality_output_loss: 0.9217 - val_age_output_loss: 1.3942 - val_weight_output_loss: 0.9430 - val_bag_output_loss: 0.8577 - val_footwear_output_loss: 0.8310 - val_pose_output_loss: 0.5924 - val_emotion_output_loss: 0.9035 - val_gender_output_acc: 0.7831 - val_image_quality_output_acc: 0.5740 - val_age_output_acc: 0.3977 - val_weight_output_acc: 0.6436 - val_bag_output_acc: 0.6190 - val_footwear_output_acc: 0.6291 - val_pose_output_acc: 0.7742 - val_emotion_output_acc: 0.7013\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 6.70074\n",
            "Epoch 100/200\n",
            "339/339 [==============================] - 176s 520ms/step - loss: 5.8359 - gender_output_loss: 0.2520 - image_quality_output_loss: 0.8461 - age_output_loss: 1.2744 - weight_output_loss: 0.8586 - bag_output_loss: 0.7173 - footwear_output_loss: 0.7021 - pose_output_loss: 0.3672 - emotion_output_loss: 0.8181 - gender_output_acc: 0.8940 - image_quality_output_acc: 0.5898 - age_output_acc: 0.4451 - weight_output_acc: 0.6548 - bag_output_acc: 0.7006 - footwear_output_acc: 0.6936 - pose_output_acc: 0.8573 - emotion_output_acc: 0.7135 - val_loss: 6.7976 - val_gender_output_loss: 0.4359 - val_image_quality_output_loss: 0.9107 - val_age_output_loss: 1.3923 - val_weight_output_loss: 0.9490 - val_bag_output_loss: 0.8423 - val_footwear_output_loss: 0.8267 - val_pose_output_loss: 0.5441 - val_emotion_output_loss: 0.8965 - val_gender_output_acc: 0.8196 - val_image_quality_output_acc: 0.5618 - val_age_output_acc: 0.3895 - val_weight_output_acc: 0.6376 - val_bag_output_acc: 0.6447 - val_footwear_output_acc: 0.6317 - val_pose_output_acc: 0.7980 - val_emotion_output_acc: 0.7020\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 6.70074\n",
            "Epoch 101/200\n",
            "339/339 [==============================] - 176s 519ms/step - loss: 5.7217 - gender_output_loss: 0.2272 - image_quality_output_loss: 0.8401 - age_output_loss: 1.2606 - weight_output_loss: 0.8509 - bag_output_loss: 0.7077 - footwear_output_loss: 0.6801 - pose_output_loss: 0.3437 - emotion_output_loss: 0.8114 - gender_output_acc: 0.9014 - image_quality_output_acc: 0.5947 - age_output_acc: 0.4511 - weight_output_acc: 0.6592 - bag_output_acc: 0.7040 - footwear_output_acc: 0.7022 - pose_output_acc: 0.8668 - emotion_output_acc: 0.7151 - val_loss: 6.8522 - val_gender_output_loss: 0.4101 - val_image_quality_output_loss: 0.9250 - val_age_output_loss: 1.4012 - val_weight_output_loss: 0.9566 - val_bag_output_loss: 0.8386 - val_footwear_output_loss: 0.8300 - val_pose_output_loss: 0.5863 - val_emotion_output_loss: 0.9045 - val_gender_output_acc: 0.8263 - val_image_quality_output_acc: 0.5618 - val_age_output_acc: 0.3958 - val_weight_output_acc: 0.6265 - val_bag_output_acc: 0.6484 - val_footwear_output_acc: 0.6391 - val_pose_output_acc: 0.7857 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 6.70074\n",
            "Epoch 102/200\n",
            "339/339 [==============================] - 176s 521ms/step - loss: 5.8056 - gender_output_loss: 0.2435 - image_quality_output_loss: 0.8437 - age_output_loss: 1.2679 - weight_output_loss: 0.8592 - bag_output_loss: 0.7065 - footwear_output_loss: 0.6993 - pose_output_loss: 0.3669 - emotion_output_loss: 0.8186 - gender_output_acc: 0.8979 - image_quality_output_acc: 0.5975 - age_output_acc: 0.4448 - weight_output_acc: 0.6576 - bag_output_acc: 0.7011 - footwear_output_acc: 0.6936 - pose_output_acc: 0.8604 - emotion_output_acc: 0.7140 - val_loss: 6.8874 - val_gender_output_loss: 0.4059 - val_image_quality_output_loss: 0.9496 - val_age_output_loss: 1.3753 - val_weight_output_loss: 0.9438 - val_bag_output_loss: 0.8868 - val_footwear_output_loss: 0.8339 - val_pose_output_loss: 0.5895 - val_emotion_output_loss: 0.9025 - val_gender_output_acc: 0.8266 - val_image_quality_output_acc: 0.5283 - val_age_output_acc: 0.4059 - val_weight_output_acc: 0.6518 - val_bag_output_acc: 0.6231 - val_footwear_output_acc: 0.6269 - val_pose_output_acc: 0.7816 - val_emotion_output_acc: 0.6983\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 6.70074\n",
            "Epoch 103/200\n",
            "339/339 [==============================] - 178s 525ms/step - loss: 5.8823 - gender_output_loss: 0.2621 - image_quality_output_loss: 0.8545 - age_output_loss: 1.2729 - weight_output_loss: 0.8620 - bag_output_loss: 0.7178 - footwear_output_loss: 0.7035 - pose_output_loss: 0.3834 - emotion_output_loss: 0.8262 - gender_output_acc: 0.8889 - image_quality_output_acc: 0.5937 - age_output_acc: 0.4395 - weight_output_acc: 0.6578 - bag_output_acc: 0.7024 - footwear_output_acc: 0.6891 - pose_output_acc: 0.8560 - emotion_output_acc: 0.7140 - val_loss: 6.8181 - val_gender_output_loss: 0.4572 - val_image_quality_output_loss: 0.9090 - val_age_output_loss: 1.3918 - val_weight_output_loss: 0.9563 - val_bag_output_loss: 0.8312 - val_footwear_output_loss: 0.8280 - val_pose_output_loss: 0.5463 - val_emotion_output_loss: 0.8982 - val_gender_output_acc: 0.8028 - val_image_quality_output_acc: 0.5681 - val_age_output_acc: 0.4029 - val_weight_output_acc: 0.6280 - val_bag_output_acc: 0.6395 - val_footwear_output_acc: 0.6280 - val_pose_output_acc: 0.7995 - val_emotion_output_acc: 0.7020\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 6.70074\n",
            "Epoch 104/200\n",
            "339/339 [==============================] - 176s 520ms/step - loss: 5.9218 - gender_output_loss: 0.2682 - image_quality_output_loss: 0.8598 - age_output_loss: 1.2766 - weight_output_loss: 0.8680 - bag_output_loss: 0.7275 - footwear_output_loss: 0.7126 - pose_output_loss: 0.3855 - emotion_output_loss: 0.8237 - gender_output_acc: 0.8827 - image_quality_output_acc: 0.5911 - age_output_acc: 0.4408 - weight_output_acc: 0.6554 - bag_output_acc: 0.6989 - footwear_output_acc: 0.6908 - pose_output_acc: 0.8534 - emotion_output_acc: 0.7138 - val_loss: 6.8469 - val_gender_output_loss: 0.3991 - val_image_quality_output_loss: 0.9319 - val_age_output_loss: 1.3965 - val_weight_output_loss: 0.9499 - val_bag_output_loss: 0.8522 - val_footwear_output_loss: 0.8415 - val_pose_output_loss: 0.5710 - val_emotion_output_loss: 0.9049 - val_gender_output_acc: 0.8281 - val_image_quality_output_acc: 0.5577 - val_age_output_acc: 0.4066 - val_weight_output_acc: 0.6488 - val_bag_output_acc: 0.6246 - val_footwear_output_acc: 0.6194 - val_pose_output_acc: 0.7894 - val_emotion_output_acc: 0.7009\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 6.70074\n",
            "Epoch 105/200\n",
            "339/339 [==============================] - 177s 523ms/step - loss: 5.9204 - gender_output_loss: 0.2665 - image_quality_output_loss: 0.8580 - age_output_loss: 1.2793 - weight_output_loss: 0.8705 - bag_output_loss: 0.7246 - footwear_output_loss: 0.7096 - pose_output_loss: 0.3874 - emotion_output_loss: 0.8246 - gender_output_acc: 0.8847 - image_quality_output_acc: 0.5887 - age_output_acc: 0.4384 - weight_output_acc: 0.6539 - bag_output_acc: 0.6999 - footwear_output_acc: 0.6898 - pose_output_acc: 0.8508 - emotion_output_acc: 0.7144 - val_loss: 6.8738 - val_gender_output_loss: 0.4304 - val_image_quality_output_loss: 0.9185 - val_age_output_loss: 1.3969 - val_weight_output_loss: 0.9520 - val_bag_output_loss: 0.8724 - val_footwear_output_loss: 0.8252 - val_pose_output_loss: 0.5773 - val_emotion_output_loss: 0.9011 - val_gender_output_acc: 0.8047 - val_image_quality_output_acc: 0.5696 - val_age_output_acc: 0.3936 - val_weight_output_acc: 0.6376 - val_bag_output_acc: 0.6083 - val_footwear_output_acc: 0.6261 - val_pose_output_acc: 0.7853 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 6.70074\n",
            "Epoch 106/200\n",
            "339/339 [==============================] - 176s 519ms/step - loss: 5.8824 - gender_output_loss: 0.2605 - image_quality_output_loss: 0.8498 - age_output_loss: 1.2702 - weight_output_loss: 0.8702 - bag_output_loss: 0.7239 - footwear_output_loss: 0.7091 - pose_output_loss: 0.3808 - emotion_output_loss: 0.8180 - gender_output_acc: 0.8883 - image_quality_output_acc: 0.5934 - age_output_acc: 0.4443 - weight_output_acc: 0.6524 - bag_output_acc: 0.6978 - footwear_output_acc: 0.6873 - pose_output_acc: 0.8559 - emotion_output_acc: 0.7141 - val_loss: 7.2482 - val_gender_output_loss: 0.4796 - val_image_quality_output_loss: 0.9210 - val_age_output_loss: 1.4414 - val_weight_output_loss: 0.9903 - val_bag_output_loss: 0.8736 - val_footwear_output_loss: 0.8984 - val_pose_output_loss: 0.7237 - val_emotion_output_loss: 0.9201 - val_gender_output_acc: 0.7656 - val_image_quality_output_acc: 0.5696 - val_age_output_acc: 0.3687 - val_weight_output_acc: 0.6217 - val_bag_output_acc: 0.6168 - val_footwear_output_acc: 0.5856 - val_pose_output_acc: 0.6983 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 6.70074\n",
            "Epoch 107/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 5.9044 - gender_output_loss: 0.2671 - image_quality_output_loss: 0.8534 - age_output_loss: 1.2734 - weight_output_loss: 0.8694 - bag_output_loss: 0.7256 - footwear_output_loss: 0.7110 - pose_output_loss: 0.3831 - emotion_output_loss: 0.8214 - gender_output_acc: 0.8823 - image_quality_output_acc: 0.5912 - age_output_acc: 0.4361 - weight_output_acc: 0.6567 - bag_output_acc: 0.6955 - footwear_output_acc: 0.6869 - pose_output_acc: 0.8534 - emotion_output_acc: 0.7144 - val_loss: 6.9954 - val_gender_output_loss: 0.4400 - val_image_quality_output_loss: 0.9385 - val_age_output_loss: 1.4284 - val_weight_output_loss: 0.9870 - val_bag_output_loss: 0.8461 - val_footwear_output_loss: 0.8646 - val_pose_output_loss: 0.5896 - val_emotion_output_loss: 0.9010 - val_gender_output_acc: 0.8121 - val_image_quality_output_acc: 0.5595 - val_age_output_acc: 0.3694 - val_weight_output_acc: 0.6057 - val_bag_output_acc: 0.6313 - val_footwear_output_acc: 0.6105 - val_pose_output_acc: 0.7772 - val_emotion_output_acc: 0.7020\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 6.70074\n",
            "Epoch 108/200\n",
            "339/339 [==============================] - 174s 514ms/step - loss: 5.8513 - gender_output_loss: 0.2591 - image_quality_output_loss: 0.8505 - age_output_loss: 1.2665 - weight_output_loss: 0.8546 - bag_output_loss: 0.7224 - footwear_output_loss: 0.7007 - pose_output_loss: 0.3762 - emotion_output_loss: 0.8213 - gender_output_acc: 0.8919 - image_quality_output_acc: 0.5909 - age_output_acc: 0.4459 - weight_output_acc: 0.6608 - bag_output_acc: 0.7000 - footwear_output_acc: 0.6926 - pose_output_acc: 0.8569 - emotion_output_acc: 0.7137 - val_loss: 6.8267 - val_gender_output_loss: 0.3938 - val_image_quality_output_loss: 0.9302 - val_age_output_loss: 1.3896 - val_weight_output_loss: 0.9530 - val_bag_output_loss: 0.8333 - val_footwear_output_loss: 0.8503 - val_pose_output_loss: 0.5708 - val_emotion_output_loss: 0.9057 - val_gender_output_acc: 0.8222 - val_image_quality_output_acc: 0.5558 - val_age_output_acc: 0.3981 - val_weight_output_acc: 0.6440 - val_bag_output_acc: 0.6332 - val_footwear_output_acc: 0.6120 - val_pose_output_acc: 0.7805 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 6.70074\n",
            "Epoch 109/200\n",
            "339/339 [==============================] - 174s 513ms/step - loss: 5.8864 - gender_output_loss: 0.2703 - image_quality_output_loss: 0.8578 - age_output_loss: 1.2676 - weight_output_loss: 0.8617 - bag_output_loss: 0.7122 - footwear_output_loss: 0.7103 - pose_output_loss: 0.3838 - emotion_output_loss: 0.8227 - gender_output_acc: 0.8831 - image_quality_output_acc: 0.5894 - age_output_acc: 0.4461 - weight_output_acc: 0.6551 - bag_output_acc: 0.7072 - footwear_output_acc: 0.6877 - pose_output_acc: 0.8507 - emotion_output_acc: 0.7136 - val_loss: 6.8862 - val_gender_output_loss: 0.4052 - val_image_quality_output_loss: 0.9149 - val_age_output_loss: 1.3976 - val_weight_output_loss: 0.9411 - val_bag_output_loss: 0.8708 - val_footwear_output_loss: 0.8501 - val_pose_output_loss: 0.6045 - val_emotion_output_loss: 0.9020 - val_gender_output_acc: 0.8278 - val_image_quality_output_acc: 0.5655 - val_age_output_acc: 0.3992 - val_weight_output_acc: 0.6499 - val_bag_output_acc: 0.6261 - val_footwear_output_acc: 0.6261 - val_pose_output_acc: 0.7701 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 6.70074\n",
            "Epoch 110/200\n",
            "339/339 [==============================] - 175s 515ms/step - loss: 5.8437 - gender_output_loss: 0.2601 - image_quality_output_loss: 0.8522 - age_output_loss: 1.2695 - weight_output_loss: 0.8536 - bag_output_loss: 0.7134 - footwear_output_loss: 0.7032 - pose_output_loss: 0.3708 - emotion_output_loss: 0.8209 - gender_output_acc: 0.8912 - image_quality_output_acc: 0.5927 - age_output_acc: 0.4456 - weight_output_acc: 0.6572 - bag_output_acc: 0.7065 - footwear_output_acc: 0.6919 - pose_output_acc: 0.8565 - emotion_output_acc: 0.7144 - val_loss: 7.0748 - val_gender_output_loss: 0.4218 - val_image_quality_output_loss: 1.0026 - val_age_output_loss: 1.3900 - val_weight_output_loss: 0.9503 - val_bag_output_loss: 0.8849 - val_footwear_output_loss: 0.8654 - val_pose_output_loss: 0.6439 - val_emotion_output_loss: 0.9159 - val_gender_output_acc: 0.8054 - val_image_quality_output_acc: 0.5450 - val_age_output_acc: 0.3981 - val_weight_output_acc: 0.6395 - val_bag_output_acc: 0.6086 - val_footwear_output_acc: 0.6094 - val_pose_output_acc: 0.7608 - val_emotion_output_acc: 0.7028\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 6.70074\n",
            "Epoch 111/200\n",
            "339/339 [==============================] - 175s 516ms/step - loss: 5.8882 - gender_output_loss: 0.2774 - image_quality_output_loss: 0.8567 - age_output_loss: 1.2618 - weight_output_loss: 0.8549 - bag_output_loss: 0.7187 - footwear_output_loss: 0.7110 - pose_output_loss: 0.3858 - emotion_output_loss: 0.8218 - gender_output_acc: 0.8798 - image_quality_output_acc: 0.5901 - age_output_acc: 0.4410 - weight_output_acc: 0.6601 - bag_output_acc: 0.6994 - footwear_output_acc: 0.6870 - pose_output_acc: 0.8512 - emotion_output_acc: 0.7148 - val_loss: 7.1353 - val_gender_output_loss: 0.5548 - val_image_quality_output_loss: 0.9411 - val_age_output_loss: 1.4171 - val_weight_output_loss: 0.9703 - val_bag_output_loss: 0.8729 - val_footwear_output_loss: 0.8238 - val_pose_output_loss: 0.6572 - val_emotion_output_loss: 0.8981 - val_gender_output_acc: 0.7790 - val_image_quality_output_acc: 0.5658 - val_age_output_acc: 0.3720 - val_weight_output_acc: 0.6194 - val_bag_output_acc: 0.6317 - val_footwear_output_acc: 0.6432 - val_pose_output_acc: 0.7757 - val_emotion_output_acc: 0.7001\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 6.70074\n",
            "Epoch 112/200\n",
            "339/339 [==============================] - 174s 513ms/step - loss: 5.8209 - gender_output_loss: 0.2591 - image_quality_output_loss: 0.8472 - age_output_loss: 1.2599 - weight_output_loss: 0.8485 - bag_output_loss: 0.7089 - footwear_output_loss: 0.7026 - pose_output_loss: 0.3807 - emotion_output_loss: 0.8139 - gender_output_acc: 0.8897 - image_quality_output_acc: 0.6019 - age_output_acc: 0.4505 - weight_output_acc: 0.6525 - bag_output_acc: 0.7078 - footwear_output_acc: 0.6907 - pose_output_acc: 0.8514 - emotion_output_acc: 0.7162 - val_loss: 6.9477 - val_gender_output_loss: 0.4280 - val_image_quality_output_loss: 0.9301 - val_age_output_loss: 1.4033 - val_weight_output_loss: 0.9619 - val_bag_output_loss: 0.8832 - val_footwear_output_loss: 0.8485 - val_pose_output_loss: 0.5838 - val_emotion_output_loss: 0.9090 - val_gender_output_acc: 0.8173 - val_image_quality_output_acc: 0.5673 - val_age_output_acc: 0.3888 - val_weight_output_acc: 0.6473 - val_bag_output_acc: 0.6295 - val_footwear_output_acc: 0.6183 - val_pose_output_acc: 0.7846 - val_emotion_output_acc: 0.7001\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 6.70074\n",
            "Epoch 113/200\n",
            "339/339 [==============================] - 175s 517ms/step - loss: 5.7890 - gender_output_loss: 0.2584 - image_quality_output_loss: 0.8422 - age_output_loss: 1.2572 - weight_output_loss: 0.8440 - bag_output_loss: 0.7010 - footwear_output_loss: 0.6938 - pose_output_loss: 0.3748 - emotion_output_loss: 0.8175 - gender_output_acc: 0.8927 - image_quality_output_acc: 0.5974 - age_output_acc: 0.4454 - weight_output_acc: 0.6578 - bag_output_acc: 0.7100 - footwear_output_acc: 0.6934 - pose_output_acc: 0.8591 - emotion_output_acc: 0.7136 - val_loss: 6.8798 - val_gender_output_loss: 0.3908 - val_image_quality_output_loss: 0.9597 - val_age_output_loss: 1.4058 - val_weight_output_loss: 0.9597 - val_bag_output_loss: 0.8765 - val_footwear_output_loss: 0.8128 - val_pose_output_loss: 0.5676 - val_emotion_output_loss: 0.9069 - val_gender_output_acc: 0.8348 - val_image_quality_output_acc: 0.5521 - val_age_output_acc: 0.3795 - val_weight_output_acc: 0.6395 - val_bag_output_acc: 0.6343 - val_footwear_output_acc: 0.6324 - val_pose_output_acc: 0.7958 - val_emotion_output_acc: 0.6979\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 6.70074\n",
            "Epoch 114/200\n",
            "339/339 [==============================] - 175s 515ms/step - loss: 5.7519 - gender_output_loss: 0.2563 - image_quality_output_loss: 0.8392 - age_output_loss: 1.2485 - weight_output_loss: 0.8358 - bag_output_loss: 0.6947 - footwear_output_loss: 0.6945 - pose_output_loss: 0.3677 - emotion_output_loss: 0.8151 - gender_output_acc: 0.8889 - image_quality_output_acc: 0.6012 - age_output_acc: 0.4537 - weight_output_acc: 0.6635 - bag_output_acc: 0.7138 - footwear_output_acc: 0.6948 - pose_output_acc: 0.8592 - emotion_output_acc: 0.7142 - val_loss: 6.8940 - val_gender_output_loss: 0.3925 - val_image_quality_output_loss: 0.9186 - val_age_output_loss: 1.4247 - val_weight_output_loss: 0.9659 - val_bag_output_loss: 0.8558 - val_footwear_output_loss: 0.8301 - val_pose_output_loss: 0.5979 - val_emotion_output_loss: 0.9085 - val_gender_output_acc: 0.8344 - val_image_quality_output_acc: 0.5658 - val_age_output_acc: 0.3865 - val_weight_output_acc: 0.6243 - val_bag_output_acc: 0.6350 - val_footwear_output_acc: 0.6246 - val_pose_output_acc: 0.7846 - val_emotion_output_acc: 0.7020\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 6.70074\n",
            "Epoch 115/200\n",
            "339/339 [==============================] - 175s 516ms/step - loss: 5.7257 - gender_output_loss: 0.2581 - image_quality_output_loss: 0.8392 - age_output_loss: 1.2410 - weight_output_loss: 0.8369 - bag_output_loss: 0.6960 - footwear_output_loss: 0.6895 - pose_output_loss: 0.3558 - emotion_output_loss: 0.8092 - gender_output_acc: 0.8902 - image_quality_output_acc: 0.5987 - age_output_acc: 0.4527 - weight_output_acc: 0.6634 - bag_output_acc: 0.7090 - footwear_output_acc: 0.6995 - pose_output_acc: 0.8647 - emotion_output_acc: 0.7159 - val_loss: 7.2725 - val_gender_output_loss: 0.4657 - val_image_quality_output_loss: 0.9240 - val_age_output_loss: 1.5420 - val_weight_output_loss: 1.0717 - val_bag_output_loss: 0.8496 - val_footwear_output_loss: 0.9169 - val_pose_output_loss: 0.5959 - val_emotion_output_loss: 0.9066 - val_gender_output_acc: 0.8244 - val_image_quality_output_acc: 0.5577 - val_age_output_acc: 0.3397 - val_weight_output_acc: 0.5554 - val_bag_output_acc: 0.6380 - val_footwear_output_acc: 0.6213 - val_pose_output_acc: 0.7958 - val_emotion_output_acc: 0.7009\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 6.70074\n",
            "Epoch 116/200\n",
            "339/339 [==============================] - 175s 516ms/step - loss: 5.6518 - gender_output_loss: 0.2486 - image_quality_output_loss: 0.8301 - age_output_loss: 1.2404 - weight_output_loss: 0.8218 - bag_output_loss: 0.6835 - footwear_output_loss: 0.6804 - pose_output_loss: 0.3392 - emotion_output_loss: 0.8078 - gender_output_acc: 0.8975 - image_quality_output_acc: 0.6024 - age_output_acc: 0.4539 - weight_output_acc: 0.6676 - bag_output_acc: 0.7213 - footwear_output_acc: 0.6976 - pose_output_acc: 0.8693 - emotion_output_acc: 0.7150 - val_loss: 7.1910 - val_gender_output_loss: 0.4455 - val_image_quality_output_loss: 0.9391 - val_age_output_loss: 1.5024 - val_weight_output_loss: 1.0451 - val_bag_output_loss: 0.8733 - val_footwear_output_loss: 0.8529 - val_pose_output_loss: 0.6145 - val_emotion_output_loss: 0.9182 - val_gender_output_acc: 0.8181 - val_image_quality_output_acc: 0.5592 - val_age_output_acc: 0.3504 - val_weight_output_acc: 0.5580 - val_bag_output_acc: 0.6417 - val_footwear_output_acc: 0.6250 - val_pose_output_acc: 0.7753 - val_emotion_output_acc: 0.7016\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 6.70074\n",
            "Epoch 117/200\n",
            "339/339 [==============================] - 176s 518ms/step - loss: 5.5429 - gender_output_loss: 0.2286 - image_quality_output_loss: 0.8184 - age_output_loss: 1.2169 - weight_output_loss: 0.8174 - bag_output_loss: 0.6661 - footwear_output_loss: 0.6691 - pose_output_loss: 0.3245 - emotion_output_loss: 0.8019 - gender_output_acc: 0.9062 - image_quality_output_acc: 0.6101 - age_output_acc: 0.4723 - weight_output_acc: 0.6704 - bag_output_acc: 0.7272 - footwear_output_acc: 0.7071 - pose_output_acc: 0.8750 - emotion_output_acc: 0.7163 - val_loss: 7.1824 - val_gender_output_loss: 0.4753 - val_image_quality_output_loss: 0.9253 - val_age_output_loss: 1.4737 - val_weight_output_loss: 1.0050 - val_bag_output_loss: 0.8686 - val_footwear_output_loss: 0.8703 - val_pose_output_loss: 0.6511 - val_emotion_output_loss: 0.9130 - val_gender_output_acc: 0.8255 - val_image_quality_output_acc: 0.5718 - val_age_output_acc: 0.3664 - val_weight_output_acc: 0.5893 - val_bag_output_acc: 0.6425 - val_footwear_output_acc: 0.6257 - val_pose_output_acc: 0.7686 - val_emotion_output_acc: 0.6994\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 6.70074\n",
            "Epoch 118/200\n",
            "339/339 [==============================] - 175s 517ms/step - loss: 5.5408 - gender_output_loss: 0.2391 - image_quality_output_loss: 0.8205 - age_output_loss: 1.2167 - weight_output_loss: 0.8074 - bag_output_loss: 0.6638 - footwear_output_loss: 0.6650 - pose_output_loss: 0.3254 - emotion_output_loss: 0.8030 - gender_output_acc: 0.8970 - image_quality_output_acc: 0.6054 - age_output_acc: 0.4666 - weight_output_acc: 0.6701 - bag_output_acc: 0.7284 - footwear_output_acc: 0.7054 - pose_output_acc: 0.8737 - emotion_output_acc: 0.7175 - val_loss: 7.1365 - val_gender_output_loss: 0.4315 - val_image_quality_output_loss: 0.9629 - val_age_output_loss: 1.4463 - val_weight_output_loss: 0.9763 - val_bag_output_loss: 0.9079 - val_footwear_output_loss: 0.8535 - val_pose_output_loss: 0.6466 - val_emotion_output_loss: 0.9115 - val_gender_output_acc: 0.8307 - val_image_quality_output_acc: 0.5394 - val_age_output_acc: 0.3724 - val_weight_output_acc: 0.6328 - val_bag_output_acc: 0.6421 - val_footwear_output_acc: 0.6298 - val_pose_output_acc: 0.7723 - val_emotion_output_acc: 0.6972\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 6.70074\n",
            "Epoch 119/200\n",
            "339/339 [==============================] - 175s 516ms/step - loss: 5.5937 - gender_output_loss: 0.2447 - image_quality_output_loss: 0.8278 - age_output_loss: 1.2203 - weight_output_loss: 0.8122 - bag_output_loss: 0.6795 - footwear_output_loss: 0.6706 - pose_output_loss: 0.3305 - emotion_output_loss: 0.8081 - gender_output_acc: 0.8965 - image_quality_output_acc: 0.6044 - age_output_acc: 0.4663 - weight_output_acc: 0.6740 - bag_output_acc: 0.7199 - footwear_output_acc: 0.7047 - pose_output_acc: 0.8710 - emotion_output_acc: 0.7148 - val_loss: 7.4103 - val_gender_output_loss: 0.6243 - val_image_quality_output_loss: 0.9352 - val_age_output_loss: 1.4936 - val_weight_output_loss: 1.0197 - val_bag_output_loss: 0.8983 - val_footwear_output_loss: 0.8738 - val_pose_output_loss: 0.6544 - val_emotion_output_loss: 0.9111 - val_gender_output_acc: 0.7560 - val_image_quality_output_acc: 0.5666 - val_age_output_acc: 0.3836 - val_weight_output_acc: 0.6425 - val_bag_output_acc: 0.6190 - val_footwear_output_acc: 0.6153 - val_pose_output_acc: 0.7552 - val_emotion_output_acc: 0.7024\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 6.70074\n",
            "Epoch 120/200\n",
            "339/339 [==============================] - 177s 523ms/step - loss: 5.5232 - gender_output_loss: 0.2338 - image_quality_output_loss: 0.8123 - age_output_loss: 1.2077 - weight_output_loss: 0.8077 - bag_output_loss: 0.6709 - footwear_output_loss: 0.6597 - pose_output_loss: 0.3314 - emotion_output_loss: 0.7998 - gender_output_acc: 0.9030 - image_quality_output_acc: 0.6114 - age_output_acc: 0.4756 - weight_output_acc: 0.6756 - bag_output_acc: 0.7259 - footwear_output_acc: 0.7112 - pose_output_acc: 0.8731 - emotion_output_acc: 0.7160 - val_loss: 7.1777 - val_gender_output_loss: 0.4726 - val_image_quality_output_loss: 0.9576 - val_age_output_loss: 1.4207 - val_weight_output_loss: 0.9767 - val_bag_output_loss: 0.9263 - val_footwear_output_loss: 0.9120 - val_pose_output_loss: 0.6032 - val_emotion_output_loss: 0.9085 - val_gender_output_acc: 0.8125 - val_image_quality_output_acc: 0.5506 - val_age_output_acc: 0.3929 - val_weight_output_acc: 0.6503 - val_bag_output_acc: 0.6205 - val_footwear_output_acc: 0.5960 - val_pose_output_acc: 0.7865 - val_emotion_output_acc: 0.7001\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 6.70074\n",
            "Epoch 121/200\n",
            "339/339 [==============================] - 179s 529ms/step - loss: 5.3658 - gender_output_loss: 0.2184 - image_quality_output_loss: 0.8001 - age_output_loss: 1.1898 - weight_output_loss: 0.7848 - bag_output_loss: 0.6405 - footwear_output_loss: 0.6343 - pose_output_loss: 0.3063 - emotion_output_loss: 0.7916 - gender_output_acc: 0.9120 - image_quality_output_acc: 0.6207 - age_output_acc: 0.4803 - weight_output_acc: 0.6814 - bag_output_acc: 0.7377 - footwear_output_acc: 0.7217 - pose_output_acc: 0.8835 - emotion_output_acc: 0.7163 - val_loss: 7.0778 - val_gender_output_loss: 0.4083 - val_image_quality_output_loss: 0.9279 - val_age_output_loss: 1.4372 - val_weight_output_loss: 0.9772 - val_bag_output_loss: 0.8940 - val_footwear_output_loss: 0.8704 - val_pose_output_loss: 0.6409 - val_emotion_output_loss: 0.9219 - val_gender_output_acc: 0.8389 - val_image_quality_output_acc: 0.5677 - val_age_output_acc: 0.4003 - val_weight_output_acc: 0.6440 - val_bag_output_acc: 0.6283 - val_footwear_output_acc: 0.6205 - val_pose_output_acc: 0.7891 - val_emotion_output_acc: 0.7013\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 6.70074\n",
            "Epoch 122/200\n",
            "339/339 [==============================] - 177s 522ms/step - loss: 5.3054 - gender_output_loss: 0.2066 - image_quality_output_loss: 0.7965 - age_output_loss: 1.1735 - weight_output_loss: 0.7832 - bag_output_loss: 0.6280 - footwear_output_loss: 0.6331 - pose_output_loss: 0.2937 - emotion_output_loss: 0.7909 - gender_output_acc: 0.9153 - image_quality_output_acc: 0.6196 - age_output_acc: 0.4884 - weight_output_acc: 0.6846 - bag_output_acc: 0.7439 - footwear_output_acc: 0.7243 - pose_output_acc: 0.8857 - emotion_output_acc: 0.7173 - val_loss: 7.2109 - val_gender_output_loss: 0.4679 - val_image_quality_output_loss: 0.9704 - val_age_output_loss: 1.4583 - val_weight_output_loss: 0.9959 - val_bag_output_loss: 0.8653 - val_footwear_output_loss: 0.8859 - val_pose_output_loss: 0.6487 - val_emotion_output_loss: 0.9186 - val_gender_output_acc: 0.8218 - val_image_quality_output_acc: 0.5376 - val_age_output_acc: 0.3769 - val_weight_output_acc: 0.6045 - val_bag_output_acc: 0.6384 - val_footwear_output_acc: 0.6031 - val_pose_output_acc: 0.7742 - val_emotion_output_acc: 0.6987\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 6.70074\n",
            "Epoch 123/200\n",
            "339/339 [==============================] - 176s 520ms/step - loss: 5.1341 - gender_output_loss: 0.1963 - image_quality_output_loss: 0.7745 - age_output_loss: 1.1498 - weight_output_loss: 0.7605 - bag_output_loss: 0.6047 - footwear_output_loss: 0.6079 - pose_output_loss: 0.2707 - emotion_output_loss: 0.7697 - gender_output_acc: 0.9218 - image_quality_output_acc: 0.6348 - age_output_acc: 0.4943 - weight_output_acc: 0.6900 - bag_output_acc: 0.7560 - footwear_output_acc: 0.7349 - pose_output_acc: 0.8974 - emotion_output_acc: 0.7202 - val_loss: 7.1930 - val_gender_output_loss: 0.4058 - val_image_quality_output_loss: 0.9385 - val_age_output_loss: 1.4696 - val_weight_output_loss: 1.0150 - val_bag_output_loss: 0.8917 - val_footwear_output_loss: 0.9008 - val_pose_output_loss: 0.6373 - val_emotion_output_loss: 0.9343 - val_gender_output_acc: 0.8430 - val_image_quality_output_acc: 0.5699 - val_age_output_acc: 0.3757 - val_weight_output_acc: 0.6064 - val_bag_output_acc: 0.6388 - val_footwear_output_acc: 0.6109 - val_pose_output_acc: 0.7768 - val_emotion_output_acc: 0.6990\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 6.70074\n",
            "Epoch 124/200\n",
            "339/339 [==============================] - 176s 519ms/step - loss: 5.0296 - gender_output_loss: 0.1826 - image_quality_output_loss: 0.7669 - age_output_loss: 1.1438 - weight_output_loss: 0.7367 - bag_output_loss: 0.5886 - footwear_output_loss: 0.5905 - pose_output_loss: 0.2538 - emotion_output_loss: 0.7667 - gender_output_acc: 0.9245 - image_quality_output_acc: 0.6412 - age_output_acc: 0.4984 - weight_output_acc: 0.6987 - bag_output_acc: 0.7626 - footwear_output_acc: 0.7406 - pose_output_acc: 0.9038 - emotion_output_acc: 0.7208 - val_loss: 7.2813 - val_gender_output_loss: 0.4521 - val_image_quality_output_loss: 0.9790 - val_age_output_loss: 1.4617 - val_weight_output_loss: 1.0042 - val_bag_output_loss: 0.9053 - val_footwear_output_loss: 0.9106 - val_pose_output_loss: 0.6363 - val_emotion_output_loss: 0.9321 - val_gender_output_acc: 0.8408 - val_image_quality_output_acc: 0.5506 - val_age_output_acc: 0.3929 - val_weight_output_acc: 0.6135 - val_bag_output_acc: 0.6332 - val_footwear_output_acc: 0.6094 - val_pose_output_acc: 0.7920 - val_emotion_output_acc: 0.6953\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 6.70074\n",
            "Epoch 125/200\n",
            "339/339 [==============================] - 176s 520ms/step - loss: 4.8203 - gender_output_loss: 0.1590 - image_quality_output_loss: 0.7384 - age_output_loss: 1.1062 - weight_output_loss: 0.7188 - bag_output_loss: 0.5582 - footwear_output_loss: 0.5560 - pose_output_loss: 0.2271 - emotion_output_loss: 0.7566 - gender_output_acc: 0.9364 - image_quality_output_acc: 0.6504 - age_output_acc: 0.5167 - weight_output_acc: 0.7057 - bag_output_acc: 0.7784 - footwear_output_acc: 0.7595 - pose_output_acc: 0.9136 - emotion_output_acc: 0.7223 - val_loss: 7.3612 - val_gender_output_loss: 0.4699 - val_image_quality_output_loss: 1.0000 - val_age_output_loss: 1.4863 - val_weight_output_loss: 0.9992 - val_bag_output_loss: 0.9230 - val_footwear_output_loss: 0.9174 - val_pose_output_loss: 0.6334 - val_emotion_output_loss: 0.9320 - val_gender_output_acc: 0.8367 - val_image_quality_output_acc: 0.5391 - val_age_output_acc: 0.3862 - val_weight_output_acc: 0.6365 - val_bag_output_acc: 0.6443 - val_footwear_output_acc: 0.6231 - val_pose_output_acc: 0.7965 - val_emotion_output_acc: 0.6920\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 6.70074\n",
            "Epoch 126/200\n",
            "339/339 [==============================] - 176s 519ms/step - loss: 4.6238 - gender_output_loss: 0.1401 - image_quality_output_loss: 0.7171 - age_output_loss: 1.0764 - weight_output_loss: 0.6940 - bag_output_loss: 0.5213 - footwear_output_loss: 0.5375 - pose_output_loss: 0.1954 - emotion_output_loss: 0.7420 - gender_output_acc: 0.9427 - image_quality_output_acc: 0.6697 - age_output_acc: 0.5329 - weight_output_acc: 0.7132 - bag_output_acc: 0.7954 - footwear_output_acc: 0.7659 - pose_output_acc: 0.9273 - emotion_output_acc: 0.7274 - val_loss: 7.5454 - val_gender_output_loss: 0.4562 - val_image_quality_output_loss: 0.9903 - val_age_output_loss: 1.5181 - val_weight_output_loss: 1.0366 - val_bag_output_loss: 0.9652 - val_footwear_output_loss: 0.9645 - val_pose_output_loss: 0.6698 - val_emotion_output_loss: 0.9445 - val_gender_output_acc: 0.8445 - val_image_quality_output_acc: 0.5484 - val_age_output_acc: 0.3806 - val_weight_output_acc: 0.6075 - val_bag_output_acc: 0.6358 - val_footwear_output_acc: 0.6209 - val_pose_output_acc: 0.7865 - val_emotion_output_acc: 0.6964\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 6.70074\n",
            "Epoch 127/200\n",
            "339/339 [==============================] - 173s 511ms/step - loss: 4.7740 - gender_output_loss: 0.1601 - image_quality_output_loss: 0.7335 - age_output_loss: 1.0923 - weight_output_loss: 0.7156 - bag_output_loss: 0.5457 - footwear_output_loss: 0.5536 - pose_output_loss: 0.2253 - emotion_output_loss: 0.7478 - gender_output_acc: 0.9353 - image_quality_output_acc: 0.6569 - age_output_acc: 0.5244 - weight_output_acc: 0.7079 - bag_output_acc: 0.7837 - footwear_output_acc: 0.7565 - pose_output_acc: 0.9149 - emotion_output_acc: 0.7233 - val_loss: 7.5206 - val_gender_output_loss: 0.4581 - val_image_quality_output_loss: 1.0157 - val_age_output_loss: 1.5155 - val_weight_output_loss: 1.0262 - val_bag_output_loss: 0.9331 - val_footwear_output_loss: 0.9342 - val_pose_output_loss: 0.6998 - val_emotion_output_loss: 0.9379 - val_gender_output_acc: 0.8296 - val_image_quality_output_acc: 0.5298 - val_age_output_acc: 0.3731 - val_weight_output_acc: 0.6168 - val_bag_output_acc: 0.6295 - val_footwear_output_acc: 0.6168 - val_pose_output_acc: 0.7734 - val_emotion_output_acc: 0.6853\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 6.70074\n",
            "Epoch 128/200\n",
            "339/339 [==============================] - 171s 503ms/step - loss: 4.9054 - gender_output_loss: 0.1755 - image_quality_output_loss: 0.7458 - age_output_loss: 1.1114 - weight_output_loss: 0.7268 - bag_output_loss: 0.5681 - footwear_output_loss: 0.5733 - pose_output_loss: 0.2493 - emotion_output_loss: 0.7552 - gender_output_acc: 0.9278 - image_quality_output_acc: 0.6521 - age_output_acc: 0.5186 - weight_output_acc: 0.7029 - bag_output_acc: 0.7714 - footwear_output_acc: 0.7502 - pose_output_acc: 0.9045 - emotion_output_acc: 0.7240 - val_loss: 7.4995 - val_gender_output_loss: 0.4530 - val_image_quality_output_loss: 1.0313 - val_age_output_loss: 1.4848 - val_weight_output_loss: 1.0040 - val_bag_output_loss: 0.9351 - val_footwear_output_loss: 0.9382 - val_pose_output_loss: 0.7116 - val_emotion_output_loss: 0.9416 - val_gender_output_acc: 0.8371 - val_image_quality_output_acc: 0.5268 - val_age_output_acc: 0.3847 - val_weight_output_acc: 0.6239 - val_bag_output_acc: 0.6365 - val_footwear_output_acc: 0.6135 - val_pose_output_acc: 0.7827 - val_emotion_output_acc: 0.6827\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 6.70074\n",
            "Epoch 129/200\n",
            "339/339 [==============================] - 171s 504ms/step - loss: 4.9823 - gender_output_loss: 0.1878 - image_quality_output_loss: 0.7584 - age_output_loss: 1.1292 - weight_output_loss: 0.7259 - bag_output_loss: 0.5690 - footwear_output_loss: 0.5882 - pose_output_loss: 0.2598 - emotion_output_loss: 0.7638 - gender_output_acc: 0.9246 - image_quality_output_acc: 0.6440 - age_output_acc: 0.5088 - weight_output_acc: 0.7019 - bag_output_acc: 0.7705 - footwear_output_acc: 0.7402 - pose_output_acc: 0.8992 - emotion_output_acc: 0.7250 - val_loss: 7.4370 - val_gender_output_loss: 0.4306 - val_image_quality_output_loss: 0.9908 - val_age_output_loss: 1.5180 - val_weight_output_loss: 1.0460 - val_bag_output_loss: 0.9304 - val_footwear_output_loss: 0.9092 - val_pose_output_loss: 0.6539 - val_emotion_output_loss: 0.9582 - val_gender_output_acc: 0.8359 - val_image_quality_output_acc: 0.5465 - val_age_output_acc: 0.3947 - val_weight_output_acc: 0.6176 - val_bag_output_acc: 0.6283 - val_footwear_output_acc: 0.6224 - val_pose_output_acc: 0.7935 - val_emotion_output_acc: 0.6927\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 6.70074\n",
            "Epoch 130/200\n",
            "339/339 [==============================] - 171s 503ms/step - loss: 5.0010 - gender_output_loss: 0.1926 - image_quality_output_loss: 0.7486 - age_output_loss: 1.1280 - weight_output_loss: 0.7346 - bag_output_loss: 0.5762 - footwear_output_loss: 0.5916 - pose_output_loss: 0.2658 - emotion_output_loss: 0.7636 - gender_output_acc: 0.9218 - image_quality_output_acc: 0.6498 - age_output_acc: 0.5093 - weight_output_acc: 0.6990 - bag_output_acc: 0.7711 - footwear_output_acc: 0.7423 - pose_output_acc: 0.9006 - emotion_output_acc: 0.7230 - val_loss: 7.5765 - val_gender_output_loss: 0.5208 - val_image_quality_output_loss: 0.9736 - val_age_output_loss: 1.5118 - val_weight_output_loss: 1.0398 - val_bag_output_loss: 0.9568 - val_footwear_output_loss: 0.9450 - val_pose_output_loss: 0.6864 - val_emotion_output_loss: 0.9424 - val_gender_output_acc: 0.7924 - val_image_quality_output_acc: 0.5517 - val_age_output_acc: 0.3850 - val_weight_output_acc: 0.6321 - val_bag_output_acc: 0.6276 - val_footwear_output_acc: 0.5945 - val_pose_output_acc: 0.7723 - val_emotion_output_acc: 0.6975\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 6.70074\n",
            "Epoch 131/200\n",
            "339/339 [==============================] - 172s 506ms/step - loss: 5.0202 - gender_output_loss: 0.1917 - image_quality_output_loss: 0.7624 - age_output_loss: 1.1336 - weight_output_loss: 0.7330 - bag_output_loss: 0.5712 - footwear_output_loss: 0.5952 - pose_output_loss: 0.2710 - emotion_output_loss: 0.7622 - gender_output_acc: 0.9223 - image_quality_output_acc: 0.6461 - age_output_acc: 0.5050 - weight_output_acc: 0.6994 - bag_output_acc: 0.7724 - footwear_output_acc: 0.7402 - pose_output_acc: 0.9020 - emotion_output_acc: 0.7245 - val_loss: 7.6180 - val_gender_output_loss: 0.5055 - val_image_quality_output_loss: 1.0360 - val_age_output_loss: 1.5151 - val_weight_output_loss: 1.1067 - val_bag_output_loss: 0.9539 - val_footwear_output_loss: 0.9035 - val_pose_output_loss: 0.6536 - val_emotion_output_loss: 0.9437 - val_gender_output_acc: 0.8240 - val_image_quality_output_acc: 0.5182 - val_age_output_acc: 0.3687 - val_weight_output_acc: 0.5677 - val_bag_output_acc: 0.6365 - val_footwear_output_acc: 0.6321 - val_pose_output_acc: 0.7805 - val_emotion_output_acc: 0.6905\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 6.70074\n",
            "Epoch 132/200\n",
            "339/339 [==============================] - 173s 510ms/step - loss: 5.0248 - gender_output_loss: 0.1947 - image_quality_output_loss: 0.7505 - age_output_loss: 1.1268 - weight_output_loss: 0.7341 - bag_output_loss: 0.5784 - footwear_output_loss: 0.5977 - pose_output_loss: 0.2804 - emotion_output_loss: 0.7622 - gender_output_acc: 0.9186 - image_quality_output_acc: 0.6466 - age_output_acc: 0.5140 - weight_output_acc: 0.6986 - bag_output_acc: 0.7679 - footwear_output_acc: 0.7380 - pose_output_acc: 0.8956 - emotion_output_acc: 0.7239 - val_loss: 7.4781 - val_gender_output_loss: 0.4666 - val_image_quality_output_loss: 0.9934 - val_age_output_loss: 1.5035 - val_weight_output_loss: 1.0231 - val_bag_output_loss: 0.9397 - val_footwear_output_loss: 0.9350 - val_pose_output_loss: 0.6733 - val_emotion_output_loss: 0.9435 - val_gender_output_acc: 0.8352 - val_image_quality_output_acc: 0.5480 - val_age_output_acc: 0.3891 - val_weight_output_acc: 0.6150 - val_bag_output_acc: 0.6053 - val_footwear_output_acc: 0.6243 - val_pose_output_acc: 0.7816 - val_emotion_output_acc: 0.6968\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 6.70074\n",
            "Epoch 133/200\n",
            "339/339 [==============================] - 173s 510ms/step - loss: 4.9260 - gender_output_loss: 0.1809 - image_quality_output_loss: 0.7480 - age_output_loss: 1.1019 - weight_output_loss: 0.7250 - bag_output_loss: 0.5643 - footwear_output_loss: 0.5872 - pose_output_loss: 0.2620 - emotion_output_loss: 0.7567 - gender_output_acc: 0.9263 - image_quality_output_acc: 0.6480 - age_output_acc: 0.5180 - weight_output_acc: 0.7032 - bag_output_acc: 0.7735 - footwear_output_acc: 0.7449 - pose_output_acc: 0.9012 - emotion_output_acc: 0.7226 - val_loss: 7.6645 - val_gender_output_loss: 0.4555 - val_image_quality_output_loss: 1.1269 - val_age_output_loss: 1.5244 - val_weight_output_loss: 1.0351 - val_bag_output_loss: 0.9551 - val_footwear_output_loss: 0.9443 - val_pose_output_loss: 0.6597 - val_emotion_output_loss: 0.9634 - val_gender_output_acc: 0.8404 - val_image_quality_output_acc: 0.4840 - val_age_output_acc: 0.3557 - val_weight_output_acc: 0.6183 - val_bag_output_acc: 0.6124 - val_footwear_output_acc: 0.5882 - val_pose_output_acc: 0.7898 - val_emotion_output_acc: 0.6745\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 6.70074\n",
            "Epoch 134/200\n",
            "339/339 [==============================] - 173s 509ms/step - loss: 5.0102 - gender_output_loss: 0.2042 - image_quality_output_loss: 0.7504 - age_output_loss: 1.1254 - weight_output_loss: 0.7329 - bag_output_loss: 0.5684 - footwear_output_loss: 0.5856 - pose_output_loss: 0.2834 - emotion_output_loss: 0.7600 - gender_output_acc: 0.9166 - image_quality_output_acc: 0.6481 - age_output_acc: 0.5137 - weight_output_acc: 0.6996 - bag_output_acc: 0.7698 - footwear_output_acc: 0.7458 - pose_output_acc: 0.8928 - emotion_output_acc: 0.7209 - val_loss: 7.8337 - val_gender_output_loss: 0.4736 - val_image_quality_output_loss: 1.0269 - val_age_output_loss: 1.5334 - val_weight_output_loss: 1.0556 - val_bag_output_loss: 1.0015 - val_footwear_output_loss: 0.9375 - val_pose_output_loss: 0.8357 - val_emotion_output_loss: 0.9695 - val_gender_output_acc: 0.8177 - val_image_quality_output_acc: 0.5082 - val_age_output_acc: 0.3612 - val_weight_output_acc: 0.5778 - val_bag_output_acc: 0.6135 - val_footwear_output_acc: 0.6127 - val_pose_output_acc: 0.7113 - val_emotion_output_acc: 0.6968\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 6.70074\n",
            "Epoch 135/200\n",
            "339/339 [==============================] - 173s 509ms/step - loss: 4.9400 - gender_output_loss: 0.1901 - image_quality_output_loss: 0.7469 - age_output_loss: 1.1148 - weight_output_loss: 0.7274 - bag_output_loss: 0.5630 - footwear_output_loss: 0.5853 - pose_output_loss: 0.2646 - emotion_output_loss: 0.7479 - gender_output_acc: 0.9237 - image_quality_output_acc: 0.6538 - age_output_acc: 0.5132 - weight_output_acc: 0.7041 - bag_output_acc: 0.7730 - footwear_output_acc: 0.7441 - pose_output_acc: 0.8974 - emotion_output_acc: 0.7269 - val_loss: 7.7453 - val_gender_output_loss: 0.5137 - val_image_quality_output_loss: 1.0067 - val_age_output_loss: 1.5736 - val_weight_output_loss: 1.0422 - val_bag_output_loss: 1.0397 - val_footwear_output_loss: 0.9296 - val_pose_output_loss: 0.6822 - val_emotion_output_loss: 0.9576 - val_gender_output_acc: 0.8218 - val_image_quality_output_acc: 0.5621 - val_age_output_acc: 0.3523 - val_weight_output_acc: 0.5882 - val_bag_output_acc: 0.6179 - val_footwear_output_acc: 0.6094 - val_pose_output_acc: 0.7853 - val_emotion_output_acc: 0.6708\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 6.70074\n",
            "Epoch 136/200\n",
            "339/339 [==============================] - 173s 511ms/step - loss: 4.8855 - gender_output_loss: 0.1867 - image_quality_output_loss: 0.7350 - age_output_loss: 1.1043 - weight_output_loss: 0.7116 - bag_output_loss: 0.5609 - footwear_output_loss: 0.5749 - pose_output_loss: 0.2656 - emotion_output_loss: 0.7466 - gender_output_acc: 0.9218 - image_quality_output_acc: 0.6568 - age_output_acc: 0.5226 - weight_output_acc: 0.7073 - bag_output_acc: 0.7728 - footwear_output_acc: 0.7505 - pose_output_acc: 0.9003 - emotion_output_acc: 0.7261 - val_loss: 7.5830 - val_gender_output_loss: 0.5031 - val_image_quality_output_loss: 1.0111 - val_age_output_loss: 1.4898 - val_weight_output_loss: 1.0262 - val_bag_output_loss: 1.0208 - val_footwear_output_loss: 0.9197 - val_pose_output_loss: 0.6688 - val_emotion_output_loss: 0.9435 - val_gender_output_acc: 0.8092 - val_image_quality_output_acc: 0.5465 - val_age_output_acc: 0.3690 - val_weight_output_acc: 0.6283 - val_bag_output_acc: 0.6071 - val_footwear_output_acc: 0.6101 - val_pose_output_acc: 0.7746 - val_emotion_output_acc: 0.6842\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 6.70074\n",
            "Epoch 137/200\n",
            "339/339 [==============================] - 172s 509ms/step - loss: 4.8713 - gender_output_loss: 0.2005 - image_quality_output_loss: 0.7349 - age_output_loss: 1.0840 - weight_output_loss: 0.7191 - bag_output_loss: 0.5558 - footwear_output_loss: 0.5672 - pose_output_loss: 0.2682 - emotion_output_loss: 0.7416 - gender_output_acc: 0.9157 - image_quality_output_acc: 0.6590 - age_output_acc: 0.5343 - weight_output_acc: 0.7030 - bag_output_acc: 0.7784 - footwear_output_acc: 0.7530 - pose_output_acc: 0.8981 - emotion_output_acc: 0.7340 - val_loss: 7.9453 - val_gender_output_loss: 0.5599 - val_image_quality_output_loss: 1.0119 - val_age_output_loss: 1.5728 - val_weight_output_loss: 1.0606 - val_bag_output_loss: 1.0028 - val_footwear_output_loss: 0.9608 - val_pose_output_loss: 0.7531 - val_emotion_output_loss: 1.0233 - val_gender_output_acc: 0.7812 - val_image_quality_output_acc: 0.5409 - val_age_output_acc: 0.3873 - val_weight_output_acc: 0.6254 - val_bag_output_acc: 0.5930 - val_footwear_output_acc: 0.6328 - val_pose_output_acc: 0.7515 - val_emotion_output_acc: 0.6990\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 6.70074\n",
            "Epoch 138/200\n",
            "339/339 [==============================] - 181s 535ms/step - loss: 5.1946 - gender_output_loss: 0.2306 - image_quality_output_loss: 0.7677 - age_output_loss: 1.1435 - weight_output_loss: 0.7571 - bag_output_loss: 0.5934 - footwear_output_loss: 0.6097 - pose_output_loss: 0.3270 - emotion_output_loss: 0.7655 - gender_output_acc: 0.8989 - image_quality_output_acc: 0.6422 - age_output_acc: 0.5053 - weight_output_acc: 0.6902 - bag_output_acc: 0.7586 - footwear_output_acc: 0.7378 - pose_output_acc: 0.8749 - emotion_output_acc: 0.7263 - val_loss: 7.6992 - val_gender_output_loss: 0.4966 - val_image_quality_output_loss: 1.0027 - val_age_output_loss: 1.5201 - val_weight_output_loss: 1.0360 - val_bag_output_loss: 1.0894 - val_footwear_output_loss: 0.9139 - val_pose_output_loss: 0.7001 - val_emotion_output_loss: 0.9403 - val_gender_output_acc: 0.7965 - val_image_quality_output_acc: 0.5350 - val_age_output_acc: 0.3519 - val_weight_output_acc: 0.5949 - val_bag_output_acc: 0.5934 - val_footwear_output_acc: 0.6164 - val_pose_output_acc: 0.7604 - val_emotion_output_acc: 0.6990\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 6.70074\n",
            "Epoch 139/200\n",
            "339/339 [==============================] - 184s 542ms/step - loss: 5.1112 - gender_output_loss: 0.2304 - image_quality_output_loss: 0.7628 - age_output_loss: 1.1165 - weight_output_loss: 0.7417 - bag_output_loss: 0.5866 - footwear_output_loss: 0.6089 - pose_output_loss: 0.3064 - emotion_output_loss: 0.7580 - gender_output_acc: 0.8920 - image_quality_output_acc: 0.6452 - age_output_acc: 0.5105 - weight_output_acc: 0.6975 - bag_output_acc: 0.7564 - footwear_output_acc: 0.7377 - pose_output_acc: 0.8832 - emotion_output_acc: 0.7254 - val_loss: 7.5644 - val_gender_output_loss: 0.4747 - val_image_quality_output_loss: 1.0111 - val_age_output_loss: 1.5630 - val_weight_output_loss: 1.0544 - val_bag_output_loss: 0.9429 - val_footwear_output_loss: 0.8955 - val_pose_output_loss: 0.6654 - val_emotion_output_loss: 0.9574 - val_gender_output_acc: 0.8084 - val_image_quality_output_acc: 0.5513 - val_age_output_acc: 0.3795 - val_weight_output_acc: 0.6187 - val_bag_output_acc: 0.6150 - val_footwear_output_acc: 0.6083 - val_pose_output_acc: 0.7701 - val_emotion_output_acc: 0.6834\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 6.70074\n",
            "Epoch 140/200\n",
            "339/339 [==============================] - 177s 521ms/step - loss: 4.8541 - gender_output_loss: 0.1963 - image_quality_output_loss: 0.7332 - age_output_loss: 1.0871 - weight_output_loss: 0.7039 - bag_output_loss: 0.5416 - footwear_output_loss: 0.5708 - pose_output_loss: 0.2746 - emotion_output_loss: 0.7466 - gender_output_acc: 0.9129 - image_quality_output_acc: 0.6604 - age_output_acc: 0.5293 - weight_output_acc: 0.7090 - bag_output_acc: 0.7813 - footwear_output_acc: 0.7539 - pose_output_acc: 0.8977 - emotion_output_acc: 0.7282 - val_loss: 7.7155 - val_gender_output_loss: 0.4697 - val_image_quality_output_loss: 1.0233 - val_age_output_loss: 1.5666 - val_weight_output_loss: 1.0750 - val_bag_output_loss: 1.0061 - val_footwear_output_loss: 0.9462 - val_pose_output_loss: 0.6660 - val_emotion_output_loss: 0.9626 - val_gender_output_acc: 0.8077 - val_image_quality_output_acc: 0.5547 - val_age_output_acc: 0.3828 - val_weight_output_acc: 0.6336 - val_bag_output_acc: 0.6060 - val_footwear_output_acc: 0.6071 - val_pose_output_acc: 0.7608 - val_emotion_output_acc: 0.6871\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 6.70074\n",
            "Epoch 141/200\n",
            "339/339 [==============================] - 173s 510ms/step - loss: 4.8048 - gender_output_loss: 0.1964 - image_quality_output_loss: 0.7263 - age_output_loss: 1.0763 - weight_output_loss: 0.6950 - bag_output_loss: 0.5409 - footwear_output_loss: 0.5747 - pose_output_loss: 0.2626 - emotion_output_loss: 0.7327 - gender_output_acc: 0.9130 - image_quality_output_acc: 0.6682 - age_output_acc: 0.5355 - weight_output_acc: 0.7109 - bag_output_acc: 0.7829 - footwear_output_acc: 0.7519 - pose_output_acc: 0.8993 - emotion_output_acc: 0.7319 - val_loss: 8.6656 - val_gender_output_loss: 0.8205 - val_image_quality_output_loss: 1.0468 - val_age_output_loss: 1.5979 - val_weight_output_loss: 1.0720 - val_bag_output_loss: 1.0292 - val_footwear_output_loss: 1.1767 - val_pose_output_loss: 0.9087 - val_emotion_output_loss: 1.0139 - val_gender_output_acc: 0.6417 - val_image_quality_output_acc: 0.5286 - val_age_output_acc: 0.3783 - val_weight_output_acc: 0.6228 - val_bag_output_acc: 0.5573 - val_footwear_output_acc: 0.4613 - val_pose_output_acc: 0.6618 - val_emotion_output_acc: 0.6845\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 6.70074\n",
            "Epoch 142/200\n",
            "339/339 [==============================] - 172s 508ms/step - loss: 4.9057 - gender_output_loss: 0.2229 - image_quality_output_loss: 0.7325 - age_output_loss: 1.0890 - weight_output_loss: 0.7189 - bag_output_loss: 0.5438 - footwear_output_loss: 0.5805 - pose_output_loss: 0.2808 - emotion_output_loss: 0.7373 - gender_output_acc: 0.9057 - image_quality_output_acc: 0.6554 - age_output_acc: 0.5322 - weight_output_acc: 0.7051 - bag_output_acc: 0.7818 - footwear_output_acc: 0.7489 - pose_output_acc: 0.8953 - emotion_output_acc: 0.7307 - val_loss: 7.7762 - val_gender_output_loss: 0.4515 - val_image_quality_output_loss: 1.0821 - val_age_output_loss: 1.5473 - val_weight_output_loss: 1.0568 - val_bag_output_loss: 1.0088 - val_footwear_output_loss: 0.9677 - val_pose_output_loss: 0.6848 - val_emotion_output_loss: 0.9773 - val_gender_output_acc: 0.8237 - val_image_quality_output_acc: 0.5167 - val_age_output_acc: 0.3642 - val_weight_output_acc: 0.6202 - val_bag_output_acc: 0.5945 - val_footwear_output_acc: 0.6060 - val_pose_output_acc: 0.7775 - val_emotion_output_acc: 0.6689\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 6.70074\n",
            "Epoch 143/200\n",
            "339/339 [==============================] - 174s 513ms/step - loss: 4.8243 - gender_output_loss: 0.2093 - image_quality_output_loss: 0.7242 - age_output_loss: 1.0732 - weight_output_loss: 0.7024 - bag_output_loss: 0.5349 - footwear_output_loss: 0.5706 - pose_output_loss: 0.2761 - emotion_output_loss: 0.7335 - gender_output_acc: 0.9125 - image_quality_output_acc: 0.6658 - age_output_acc: 0.5360 - weight_output_acc: 0.7129 - bag_output_acc: 0.7853 - footwear_output_acc: 0.7538 - pose_output_acc: 0.8918 - emotion_output_acc: 0.7313 - val_loss: 7.9001 - val_gender_output_loss: 0.4383 - val_image_quality_output_loss: 1.0944 - val_age_output_loss: 1.5576 - val_weight_output_loss: 1.0535 - val_bag_output_loss: 0.9886 - val_footwear_output_loss: 0.9896 - val_pose_output_loss: 0.7973 - val_emotion_output_loss: 0.9807 - val_gender_output_acc: 0.8356 - val_image_quality_output_acc: 0.5160 - val_age_output_acc: 0.3884 - val_weight_output_acc: 0.6202 - val_bag_output_acc: 0.6105 - val_footwear_output_acc: 0.5878 - val_pose_output_acc: 0.7400 - val_emotion_output_acc: 0.6633\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 6.70074\n",
            "Epoch 144/200\n",
            "339/339 [==============================] - 173s 510ms/step - loss: 4.9070 - gender_output_loss: 0.2174 - image_quality_output_loss: 0.7279 - age_output_loss: 1.0792 - weight_output_loss: 0.7164 - bag_output_loss: 0.5461 - footwear_output_loss: 0.5797 - pose_output_loss: 0.2992 - emotion_output_loss: 0.7412 - gender_output_acc: 0.9052 - image_quality_output_acc: 0.6693 - age_output_acc: 0.5348 - weight_output_acc: 0.7084 - bag_output_acc: 0.7831 - footwear_output_acc: 0.7495 - pose_output_acc: 0.8878 - emotion_output_acc: 0.7300 - val_loss: 7.6073 - val_gender_output_loss: 0.4583 - val_image_quality_output_loss: 1.0341 - val_age_output_loss: 1.5306 - val_weight_output_loss: 1.0291 - val_bag_output_loss: 0.9706 - val_footwear_output_loss: 0.9602 - val_pose_output_loss: 0.6654 - val_emotion_output_loss: 0.9589 - val_gender_output_acc: 0.8144 - val_image_quality_output_acc: 0.5353 - val_age_output_acc: 0.3772 - val_weight_output_acc: 0.6440 - val_bag_output_acc: 0.6075 - val_footwear_output_acc: 0.5949 - val_pose_output_acc: 0.7839 - val_emotion_output_acc: 0.6644\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 6.70074\n",
            "Epoch 145/200\n",
            "339/339 [==============================] - 174s 515ms/step - loss: 4.8487 - gender_output_loss: 0.2136 - image_quality_output_loss: 0.7292 - age_output_loss: 1.0781 - weight_output_loss: 0.6993 - bag_output_loss: 0.5336 - footwear_output_loss: 0.5731 - pose_output_loss: 0.2911 - emotion_output_loss: 0.7307 - gender_output_acc: 0.9040 - image_quality_output_acc: 0.6577 - age_output_acc: 0.5342 - weight_output_acc: 0.7157 - bag_output_acc: 0.7811 - footwear_output_acc: 0.7519 - pose_output_acc: 0.8914 - emotion_output_acc: 0.7318 - val_loss: 7.7935 - val_gender_output_loss: 0.4598 - val_image_quality_output_loss: 1.1537 - val_age_output_loss: 1.5450 - val_weight_output_loss: 1.0349 - val_bag_output_loss: 1.0204 - val_footwear_output_loss: 0.9405 - val_pose_output_loss: 0.6865 - val_emotion_output_loss: 0.9527 - val_gender_output_acc: 0.7839 - val_image_quality_output_acc: 0.4836 - val_age_output_acc: 0.3635 - val_weight_output_acc: 0.6205 - val_bag_output_acc: 0.6135 - val_footwear_output_acc: 0.5982 - val_pose_output_acc: 0.7671 - val_emotion_output_acc: 0.6871\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 6.70074\n",
            "Epoch 146/200\n",
            "339/339 [==============================] - 175s 515ms/step - loss: 4.5850 - gender_output_loss: 0.1988 - image_quality_output_loss: 0.6999 - age_output_loss: 1.0315 - weight_output_loss: 0.6676 - bag_output_loss: 0.4936 - footwear_output_loss: 0.5317 - pose_output_loss: 0.2545 - emotion_output_loss: 0.7073 - gender_output_acc: 0.9080 - image_quality_output_acc: 0.6774 - age_output_acc: 0.5599 - weight_output_acc: 0.7295 - bag_output_acc: 0.8040 - footwear_output_acc: 0.7698 - pose_output_acc: 0.9046 - emotion_output_acc: 0.7385 - val_loss: 8.3815 - val_gender_output_loss: 0.5104 - val_image_quality_output_loss: 1.1768 - val_age_output_loss: 1.6248 - val_weight_output_loss: 1.1233 - val_bag_output_loss: 1.1741 - val_footwear_output_loss: 1.0093 - val_pose_output_loss: 0.7455 - val_emotion_output_loss: 1.0173 - val_gender_output_acc: 0.8199 - val_image_quality_output_acc: 0.4892 - val_age_output_acc: 0.3638 - val_weight_output_acc: 0.6235 - val_bag_output_acc: 0.5863 - val_footwear_output_acc: 0.6109 - val_pose_output_acc: 0.7545 - val_emotion_output_acc: 0.6838\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 6.70074\n",
            "Epoch 147/200\n",
            "339/339 [==============================] - 175s 518ms/step - loss: 4.3422 - gender_output_loss: 0.1727 - image_quality_output_loss: 0.6590 - age_output_loss: 0.9958 - weight_output_loss: 0.6412 - bag_output_loss: 0.4554 - footwear_output_loss: 0.5009 - pose_output_loss: 0.2330 - emotion_output_loss: 0.6842 - gender_output_acc: 0.9207 - image_quality_output_acc: 0.7024 - age_output_acc: 0.5785 - weight_output_acc: 0.7380 - bag_output_acc: 0.8200 - footwear_output_acc: 0.7865 - pose_output_acc: 0.9122 - emotion_output_acc: 0.7448 - val_loss: 8.6112 - val_gender_output_loss: 0.6221 - val_image_quality_output_loss: 1.2038 - val_age_output_loss: 1.6599 - val_weight_output_loss: 1.1827 - val_bag_output_loss: 1.0941 - val_footwear_output_loss: 1.0164 - val_pose_output_loss: 0.7571 - val_emotion_output_loss: 1.0752 - val_gender_output_acc: 0.7705 - val_image_quality_output_acc: 0.4773 - val_age_output_acc: 0.3884 - val_weight_output_acc: 0.5833 - val_bag_output_acc: 0.5867 - val_footwear_output_acc: 0.5904 - val_pose_output_acc: 0.7664 - val_emotion_output_acc: 0.6708\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 6.70074\n",
            "Epoch 148/200\n",
            "339/339 [==============================] - 176s 519ms/step - loss: 4.2752 - gender_output_loss: 0.1728 - image_quality_output_loss: 0.6518 - age_output_loss: 0.9742 - weight_output_loss: 0.6262 - bag_output_loss: 0.4543 - footwear_output_loss: 0.4996 - pose_output_loss: 0.2217 - emotion_output_loss: 0.6746 - gender_output_acc: 0.9241 - image_quality_output_acc: 0.7048 - age_output_acc: 0.5821 - weight_output_acc: 0.7451 - bag_output_acc: 0.8194 - footwear_output_acc: 0.7881 - pose_output_acc: 0.9198 - emotion_output_acc: 0.7513 - val_loss: 8.1706 - val_gender_output_loss: 0.4734 - val_image_quality_output_loss: 1.1069 - val_age_output_loss: 1.6243 - val_weight_output_loss: 1.1604 - val_bag_output_loss: 1.0768 - val_footwear_output_loss: 1.0105 - val_pose_output_loss: 0.7101 - val_emotion_output_loss: 1.0082 - val_gender_output_acc: 0.8356 - val_image_quality_output_acc: 0.5149 - val_age_output_acc: 0.3769 - val_weight_output_acc: 0.6343 - val_bag_output_acc: 0.6313 - val_footwear_output_acc: 0.6049 - val_pose_output_acc: 0.7831 - val_emotion_output_acc: 0.6696\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 6.70074\n",
            "Epoch 149/200\n",
            "339/339 [==============================] - 176s 518ms/step - loss: 3.9359 - gender_output_loss: 0.1450 - image_quality_output_loss: 0.6051 - age_output_loss: 0.9195 - weight_output_loss: 0.5751 - bag_output_loss: 0.4093 - footwear_output_loss: 0.4386 - pose_output_loss: 0.1930 - emotion_output_loss: 0.6504 - gender_output_acc: 0.9405 - image_quality_output_acc: 0.7222 - age_output_acc: 0.6060 - weight_output_acc: 0.7649 - bag_output_acc: 0.8403 - footwear_output_acc: 0.8142 - pose_output_acc: 0.9286 - emotion_output_acc: 0.7600 - val_loss: 8.6622 - val_gender_output_loss: 0.5121 - val_image_quality_output_loss: 1.1773 - val_age_output_loss: 1.6986 - val_weight_output_loss: 1.1856 - val_bag_output_loss: 1.2098 - val_footwear_output_loss: 1.1155 - val_pose_output_loss: 0.7316 - val_emotion_output_loss: 1.0318 - val_gender_output_acc: 0.8397 - val_image_quality_output_acc: 0.5216 - val_age_output_acc: 0.3698 - val_weight_output_acc: 0.5952 - val_bag_output_acc: 0.5867 - val_footwear_output_acc: 0.6001 - val_pose_output_acc: 0.7868 - val_emotion_output_acc: 0.6793\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 6.70074\n",
            "Epoch 150/200\n",
            "339/339 [==============================] - 176s 518ms/step - loss: 3.6467 - gender_output_loss: 0.1248 - image_quality_output_loss: 0.5804 - age_output_loss: 0.8695 - weight_output_loss: 0.5356 - bag_output_loss: 0.3534 - footwear_output_loss: 0.4019 - pose_output_loss: 0.1653 - emotion_output_loss: 0.6159 - gender_output_acc: 0.9487 - image_quality_output_acc: 0.7421 - age_output_acc: 0.6291 - weight_output_acc: 0.7873 - bag_output_acc: 0.8640 - footwear_output_acc: 0.8325 - pose_output_acc: 0.9408 - emotion_output_acc: 0.7682 - val_loss: 8.8271 - val_gender_output_loss: 0.5321 - val_image_quality_output_loss: 1.2571 - val_age_output_loss: 1.7541 - val_weight_output_loss: 1.2331 - val_bag_output_loss: 1.1317 - val_footwear_output_loss: 1.0974 - val_pose_output_loss: 0.7619 - val_emotion_output_loss: 1.0597 - val_gender_output_acc: 0.8411 - val_image_quality_output_acc: 0.5060 - val_age_output_acc: 0.3690 - val_weight_output_acc: 0.6150 - val_bag_output_acc: 0.6224 - val_footwear_output_acc: 0.6231 - val_pose_output_acc: 0.7950 - val_emotion_output_acc: 0.6693\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 6.70074\n",
            "Epoch 151/200\n",
            "339/339 [==============================] - 175s 516ms/step - loss: 3.3491 - gender_output_loss: 0.1076 - image_quality_output_loss: 0.5243 - age_output_loss: 0.8175 - weight_output_loss: 0.5005 - bag_output_loss: 0.3048 - footwear_output_loss: 0.3595 - pose_output_loss: 0.1454 - emotion_output_loss: 0.5895 - gender_output_acc: 0.9533 - image_quality_output_acc: 0.7709 - age_output_acc: 0.6532 - weight_output_acc: 0.7986 - bag_output_acc: 0.8805 - footwear_output_acc: 0.8482 - pose_output_acc: 0.9464 - emotion_output_acc: 0.7791 - val_loss: 9.0578 - val_gender_output_loss: 0.5355 - val_image_quality_output_loss: 1.2834 - val_age_output_loss: 1.7877 - val_weight_output_loss: 1.2331 - val_bag_output_loss: 1.1886 - val_footwear_output_loss: 1.1558 - val_pose_output_loss: 0.8116 - val_emotion_output_loss: 1.0621 - val_gender_output_acc: 0.8382 - val_image_quality_output_acc: 0.4892 - val_age_output_acc: 0.3597 - val_weight_output_acc: 0.6031 - val_bag_output_acc: 0.6075 - val_footwear_output_acc: 0.5952 - val_pose_output_acc: 0.7742 - val_emotion_output_acc: 0.6600\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 6.70074\n",
            "Epoch 152/200\n",
            "162/339 [=============>................] - ETA: 1:25 - loss: 3.5742 - gender_output_loss: 0.1203 - image_quality_output_loss: 0.5662 - age_output_loss: 0.8522 - weight_output_loss: 0.5223 - bag_output_loss: 0.3428 - footwear_output_loss: 0.4094 - pose_output_loss: 0.1617 - emotion_output_loss: 0.5993 - gender_output_acc: 0.9535 - image_quality_output_acc: 0.7521 - age_output_acc: 0.6468 - weight_output_acc: 0.7890 - bag_output_acc: 0.8657 - footwear_output_acc: 0.8258 - pose_output_acc: 0.9408 - emotion_output_acc: 0.7724"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}